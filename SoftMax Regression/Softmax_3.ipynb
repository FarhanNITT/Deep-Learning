{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09104bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f56d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.reshape(np.load(\"fashion_mnist_train_images.npy\"), (-1, 28*28))\n",
    "training_labels = np.load(\"fashion_mnist_train_labels.npy\")\n",
    "testing_data = np.reshape(np.load(\"fashion_mnist_test_images.npy\"), (-1, 28*28))\n",
    "testing_labels= np.load(\"fashion_mnist_test_labels.npy\")\n",
    "\n",
    "\n",
    "num_datapoints = training_data.shape[0]\n",
    "\n",
    "split_index = int(0.8*num_datapoints)\n",
    "\n",
    "indices = np.arange(num_datapoints)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "X_train, X_val = training_data[train_indices], training_data[val_indices]   \n",
    "y_train, y_val = training_labels[train_indices], training_labels[val_indices]\n",
    "\n",
    "\n",
    "# based on Hint1 \n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "\n",
    "\n",
    "input_size = 28*28\n",
    "output_size = 10 # num_classes\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 100 \n",
    "\n",
    "alpha = 0.01 # L2 regularization constant \n",
    "\n",
    "\n",
    "# initilize weights and bias\n",
    "\n",
    "W = np.random.randn(input_size,output_size) * 0.01  # to avoid large initializations as its random  # for each image pixel spanning across 10 classes\n",
    "B = np.zeros((1,output_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df734c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # to avoid large exponent values, we will use the deviation idealogy of subtracting each value with the max value , thereby keeping the order preserved and since it will be normalised , result wont matter\n",
    "    \n",
    "    exponent_z = np.exp(Z - np.max(Z,axis=1,keepdims=True))\n",
    "    \n",
    "    prediction = exponent_z/(np.sum(exponent_z,axis=1,keepdims=True))\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93f91c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_label,y_pred,W,alpha):\n",
    "    \n",
    "    batch_s = y_label .shape[0]  # to divide for average loss over batch\n",
    "    \n",
    "    prob = -np.log(y_pred[range(batch_s),y_label])  # for each sample we source the true label from y_label and compute the log of corresponding label value from y_pred\n",
    "    \n",
    "    loss = np.sum(prob) / batch_s\n",
    "    \n",
    "    reg_loss = alpha/2 * np.sum(np.square(W))\n",
    "    \n",
    "    batch_loss = loss + reg_loss\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21b483c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X_batch,Y_batch,W,alpha,pred,B):\n",
    "    \n",
    "    batch_s = X_batch.shape[0]  # here its 64\n",
    "    \n",
    "    predi = pred\n",
    "    \n",
    "    predi[range(batch_s),Y_batch] -=1 # subtract each predicted true class label probability from 1 to compute the loss\n",
    "    \n",
    "    predi /= batch_s    # we compute the average loss per sample\n",
    "    \n",
    "    weight_grad = np.dot(X_batch.T,predi) + alpha * W\n",
    "    bias_grad = np.sum(predi, axis = 0, keepdims=True)\n",
    "    \n",
    "                \n",
    "    # update weights and bias using gradient descent\n",
    "    W -= learning_rate * weight_grad \n",
    "    B -= learning_rate * bias_grad\n",
    "    \n",
    "    \n",
    "    return W, B\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e243bd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6539022268250121\n",
      "Epoch 2/100, Loss: 0.7195798985618261\n",
      "Epoch 3/100, Loss: 0.9633944997076571\n",
      "Epoch 4/100, Loss: 0.5716255219046278\n",
      "Epoch 5/100, Loss: 0.5592579224515526\n",
      "Epoch 6/100, Loss: 0.6598484429075889\n",
      "Epoch 7/100, Loss: 0.6834800613072634\n",
      "Epoch 8/100, Loss: 0.6370966309160908\n",
      "Epoch 9/100, Loss: 0.645701555701902\n",
      "Epoch 10/100, Loss: 0.7080406831022498\n",
      "Epoch 11/100, Loss: 0.6796974140350367\n",
      "Epoch 12/100, Loss: 0.5443103011057169\n",
      "Epoch 13/100, Loss: 0.6970288322048521\n",
      "Epoch 14/100, Loss: 0.44092821811655897\n",
      "Epoch 15/100, Loss: 0.540842229206005\n",
      "Epoch 16/100, Loss: 0.5796934316961819\n",
      "Epoch 17/100, Loss: 0.5890085334414075\n",
      "Epoch 18/100, Loss: 0.712712722026385\n",
      "Epoch 19/100, Loss: 0.6385448612507405\n",
      "Epoch 20/100, Loss: 0.5707933004843105\n",
      "Epoch 21/100, Loss: 0.5716491410255831\n",
      "Epoch 22/100, Loss: 0.6622467640862832\n",
      "Epoch 23/100, Loss: 0.6753373165466905\n",
      "Epoch 24/100, Loss: 0.6554451161741273\n",
      "Epoch 25/100, Loss: 0.8090530123159718\n",
      "Epoch 26/100, Loss: 0.590373118747474\n",
      "Epoch 27/100, Loss: 0.6257901314561669\n",
      "Epoch 28/100, Loss: 0.6848057512569657\n",
      "Epoch 29/100, Loss: 0.6023355835889737\n",
      "Epoch 30/100, Loss: 0.5555700375840362\n",
      "Epoch 31/100, Loss: 0.7528902002932241\n",
      "Epoch 32/100, Loss: 0.5486494349589347\n",
      "Epoch 33/100, Loss: 0.6311731241946541\n",
      "Epoch 34/100, Loss: 0.539619778216552\n",
      "Epoch 35/100, Loss: 0.6600899027999727\n",
      "Epoch 36/100, Loss: 0.6579141070098556\n",
      "Epoch 37/100, Loss: 0.6308848650237054\n",
      "Epoch 38/100, Loss: 0.7163827391768296\n",
      "Epoch 39/100, Loss: 0.6526580724310261\n",
      "Epoch 40/100, Loss: 0.559546064588686\n",
      "Epoch 41/100, Loss: 0.5356502689870672\n",
      "Epoch 42/100, Loss: 0.6462162932262896\n",
      "Epoch 43/100, Loss: 0.6535816400361806\n",
      "Epoch 44/100, Loss: 0.5621877523711718\n",
      "Epoch 45/100, Loss: 0.571984852977276\n",
      "Epoch 46/100, Loss: 0.7139530620711907\n",
      "Epoch 47/100, Loss: 0.8363718775972638\n",
      "Epoch 48/100, Loss: 0.5493088754244083\n",
      "Epoch 49/100, Loss: 0.7718798892481594\n",
      "Epoch 50/100, Loss: 0.8196972749084376\n",
      "Epoch 51/100, Loss: 0.8206347807842084\n",
      "Epoch 52/100, Loss: 0.6400638882475383\n",
      "Epoch 53/100, Loss: 0.6508860773557\n",
      "Epoch 54/100, Loss: 0.6288212678470696\n",
      "Epoch 55/100, Loss: 0.5769495763834135\n",
      "Epoch 56/100, Loss: 0.6645489414491704\n",
      "Epoch 57/100, Loss: 0.6843504766244881\n",
      "Epoch 58/100, Loss: 0.591396013393116\n",
      "Epoch 59/100, Loss: 0.45242026129898694\n",
      "Epoch 60/100, Loss: 0.6560193060400668\n",
      "Epoch 61/100, Loss: 0.6046350632407294\n",
      "Epoch 62/100, Loss: 0.6555713338969498\n",
      "Epoch 63/100, Loss: 0.6170034041562278\n",
      "Epoch 64/100, Loss: 0.5621416248307575\n",
      "Epoch 65/100, Loss: 0.5561340796157191\n",
      "Epoch 66/100, Loss: 0.7072624774191345\n",
      "Epoch 67/100, Loss: 0.6446746363499105\n",
      "Epoch 68/100, Loss: 0.6060376461757278\n",
      "Epoch 69/100, Loss: 0.8318199098082176\n",
      "Epoch 70/100, Loss: 0.5160494701724102\n",
      "Epoch 71/100, Loss: 0.5215201959483484\n",
      "Epoch 72/100, Loss: 0.46629260723445987\n",
      "Epoch 73/100, Loss: 0.5976001850422561\n",
      "Epoch 74/100, Loss: 0.5412897348833117\n",
      "Epoch 75/100, Loss: 0.5435318631605996\n",
      "Epoch 76/100, Loss: 0.5948092161422024\n",
      "Epoch 77/100, Loss: 0.7493465529471162\n",
      "Epoch 78/100, Loss: 0.5645909069817758\n",
      "Epoch 79/100, Loss: 0.5302808067853364\n",
      "Epoch 80/100, Loss: 0.697385921082143\n",
      "Epoch 81/100, Loss: 0.6261308756569941\n",
      "Epoch 82/100, Loss: 0.6086198888058327\n",
      "Epoch 83/100, Loss: 0.652090429857376\n",
      "Epoch 84/100, Loss: 0.6524661072518676\n",
      "Epoch 85/100, Loss: 0.482999888430227\n",
      "Epoch 86/100, Loss: 0.6066516351612425\n",
      "Epoch 87/100, Loss: 0.5201112884538186\n",
      "Epoch 88/100, Loss: 0.6868367722343084\n",
      "Epoch 89/100, Loss: 0.6623364688138947\n",
      "Epoch 90/100, Loss: 0.6249114335907516\n",
      "Epoch 91/100, Loss: 0.6009174874193246\n",
      "Epoch 92/100, Loss: 0.5312119609783872\n",
      "Epoch 93/100, Loss: 0.7146927023671333\n",
      "Epoch 94/100, Loss: 0.515177339568058\n",
      "Epoch 95/100, Loss: 0.5740201807930816\n",
      "Epoch 96/100, Loss: 0.48339375026077513\n",
      "Epoch 97/100, Loss: 0.6977683221204449\n",
      "Epoch 98/100, Loss: 0.5464533965692016\n",
      "Epoch 99/100, Loss: 0.5766658780354013\n",
      "Epoch 100/100, Loss: 0.6184854144839419\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_tr_samples = X_train.shape[0] \n",
    "tr_indices = np.arange(num_tr_samples)\n",
    "# np.random.shuffle(tr_indices)\n",
    "# batch_index = tr_indices[0: 0 + batch_size]\n",
    "\n",
    "            \n",
    "# x_batch = X_train[batch_index]\n",
    "#y_batch = y_train[batch_index]\n",
    "\n",
    "#  Z = np.dot(x_batch,W) + B\n",
    "# exponent_z = np.exp(Z - np.max(Z,axis=1,keepdims=True))\n",
    "\n",
    "# prediction = exponent_z/(np.sum(exponent_z,axis=1,keepdims=True))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(tr_indices)\n",
    "    \n",
    "    for num in range(0,num_tr_samples,batch_size):\n",
    "        \n",
    "            batch_index = tr_indices[num: num + batch_size]\n",
    "            \n",
    "            \n",
    "            x_batch = X_train[batch_index]\n",
    "            y_batch = y_train[batch_index]\n",
    "            \n",
    "            Z = np.dot(x_batch,W) + B   # batcsizex10\n",
    "            \n",
    "            pred = softmax(Z)\n",
    "            \n",
    "            batch_loss = loss(y_batch,pred,W,alpha)\n",
    "            \n",
    "            # next we will update the weights and bias\n",
    "            \n",
    "            W,B = gradient(x_batch,y_batch,W,alpha,pred,B)\n",
    "            \n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {batch_loss}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e43f8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 82.03%\n"
     ]
    }
   ],
   "source": [
    "def test(X):\n",
    "    Z = np.dot(X, W) + B\n",
    "    A = softmax(Z)\n",
    "    return np.argmax(A, axis=1)\n",
    "\n",
    "X_test = testing_data / 255.0\n",
    "y_test = testing_labels\n",
    "y_pred = test(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bac23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751967cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006712e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4730c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6370ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.reshape(np.load(\"fashion_mnist_train_images.npy\"), (-1, 28*28))\n",
    "training_labels = np.load(\"fashion_mnist_train_labels.npy\")\n",
    "testing_data = np.reshape(np.load(\"fashion_mnist_test_images.npy\"), (-1, 28*28))\n",
    "testing_labels= np.load(\"fashion_mnist_test_labels.npy\")\n",
    "\n",
    "\n",
    "num_datapoints = training_data.shape[0]\n",
    "\n",
    "split_index = int(0.8*num_datapoints)\n",
    "\n",
    "indices = np.arange(num_datapoints)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "X_train, X_val = training_data[train_indices], training_data[val_indices]   \n",
    "y_train, y_val = training_labels[train_indices], training_labels[val_indices]\n",
    "\n",
    "\n",
    "# based on Hint1 \n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "\n",
    "\n",
    "input_size = 28*28\n",
    "output_size = 10 # num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9846d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # to avoid large exponent values, we will use the deviation idealogy of subtracting each value with the max value , thereby keeping the order preserved and since it will be normalised , result wont matter\n",
    "    \n",
    "    exponent_z = np.exp(Z - np.max(Z,axis=1,keepdims=True))\n",
    "    \n",
    "    prediction = exponent_z/(np.sum(exponent_z,axis=1,keepdims=True))\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48beb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_label,y_pred,W,alpha):\n",
    "    \n",
    "    batch_s = y_label .shape[0]  # to divide for average loss over batch\n",
    "    \n",
    "    prob = -np.log(y_pred[range(batch_s),y_label])  # for each sample we source the true label from y_label and compute the log of corresponding label value from y_pred\n",
    "    \n",
    "    loss = np.sum(prob) / batch_s\n",
    "    \n",
    "    reg_loss = alpha/2 * np.sum(np.square(W))\n",
    "    \n",
    "    batch_loss = loss + reg_loss\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e04c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X_batch,Y_batch,W,alpha,pred,B,learning_rate):\n",
    "    \n",
    "    batch_s = X_batch.shape[0]  # here its 64\n",
    "    \n",
    "    predi = pred\n",
    "    \n",
    "    predi[range(batch_s),Y_batch] -=1 # subtract each predicted true class label probability from 1 to compute the loss\n",
    "    \n",
    "    predi /= batch_s    # we compute the average loss per sample\n",
    "    \n",
    "    weight_grad = np.dot(X_batch.T,predi) + alpha * W\n",
    "    bias_grad = np.sum(predi, axis = 0, keepdims=True)\n",
    "    \n",
    "                \n",
    "    # update weights and bias using gradient descent\n",
    "    W -= learning_rate * weight_grad \n",
    "    B -= learning_rate * bias_grad\n",
    "    \n",
    "    \n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02de2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax(X_train,y_train,num_epochs,batch_size,learning_rate,alpha):\n",
    "    \n",
    "    num_tr_samples = X_train.shape[0] \n",
    "    tr_indices = np.arange(num_tr_samples)\n",
    "    \n",
    "    # initialize weight\n",
    "    W = np.random.randn(input_size,output_size) * 0.01  # to avoid large initializations as its random  # for each image pixel spanning across 10 classes\n",
    "    B = np.zeros((1,output_size))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(tr_indices)\n",
    "\n",
    "        for num in range(0,num_tr_samples,batch_size):\n",
    "\n",
    "                batch_index = tr_indices[num: num + batch_size]\n",
    "\n",
    "\n",
    "                x_batch = X_train[batch_index]\n",
    "                y_batch = y_train[batch_index]\n",
    "\n",
    "                Z = np.dot(x_batch,W) + B   # batcsizex10\n",
    "\n",
    "                pred = softmax(Z)\n",
    "\n",
    "                batch_loss = loss(y_batch,pred,W,alpha)\n",
    "\n",
    "                # next we will update the weights and bias\n",
    "\n",
    "                W,B = gradient(x_batch,y_batch,W,alpha,pred,B,learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {batch_loss}')\n",
    "        \n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8037733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets tune our hyperparameters\n",
    "\n",
    "def validation(X_train,y_train,X_val,y_val):\n",
    "    \n",
    "    learning_rates = [1e-4,1e-3,1e-2] \n",
    "    mini_batch_sizes = [32, 64,128]\n",
    "    num_epochs_testing = [50, 100,150]\n",
    "    alpha = [1e-2,1e-1]\n",
    "    \n",
    "    best_accuracy = 0  # setting mse to positive infinity to ensure the first mse calculated becomes the default best value after first iteration and gets updated in the process\n",
    "    best_hyperparams = {}   # dictionary to store the three HP parameters\n",
    "    best_weights, best_bias = None, None\n",
    "    \n",
    "    for rate in learning_rates:\n",
    "        for a in alpha:\n",
    "            for batch in mini_batch_sizes:\n",
    "                for epoch in num_epochs_testing:\n",
    "                    \n",
    "                    weights, bias = train_softmax(X_train,y_train,epoch,batch,rate,a)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    Z = np.dot(X_val, weights) + bias\n",
    "                    A = softmax(Z)\n",
    "                    y_pred = np.argmax(A, axis=1)\n",
    "                    \n",
    "                    accuracy = np.mean(y_pred == y_val)\n",
    "                        \n",
    "                    print(f\"Num_Epoch {epoch}, Batch_size {batch}, Learning_rate {rate}, Alpha {a}, f'Test accuracy: {accuracy * 100:.2f}%'\")\n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_hyperparameters = {'num_epochs': epoch,'learning_rate': rate,'mini_batch': batch, 'Alpha': {a}}\n",
    "                        best_weights,best_bias = weights,bias\n",
    "                        \n",
    "    return best_hyperparameters,best_weights,best_bias,best_accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fed761b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.004660859740394\n",
      "Epoch 2/50, Loss: 1.8232465939046567\n",
      "Epoch 3/50, Loss: 1.7354130447149565\n",
      "Epoch 4/50, Loss: 1.3020312024863814\n",
      "Epoch 5/50, Loss: 1.6240541999793936\n",
      "Epoch 6/50, Loss: 1.3592045920722136\n",
      "Epoch 7/50, Loss: 1.2253367268953579\n",
      "Epoch 8/50, Loss: 1.3122368965764468\n",
      "Epoch 9/50, Loss: 1.1764550738078008\n",
      "Epoch 10/50, Loss: 1.2565362256827015\n",
      "Epoch 11/50, Loss: 1.1364362239765915\n",
      "Epoch 12/50, Loss: 1.2401549716261913\n",
      "Epoch 13/50, Loss: 0.9655386331215131\n",
      "Epoch 14/50, Loss: 1.0330984256061984\n",
      "Epoch 15/50, Loss: 1.042553910674316\n",
      "Epoch 16/50, Loss: 0.999487265019857\n",
      "Epoch 17/50, Loss: 0.9580736680277653\n",
      "Epoch 18/50, Loss: 1.0297377195126711\n",
      "Epoch 19/50, Loss: 0.8677689413357159\n",
      "Epoch 20/50, Loss: 0.914800491241961\n",
      "Epoch 21/50, Loss: 1.0446925040314945\n",
      "Epoch 22/50, Loss: 1.0080960464853141\n",
      "Epoch 23/50, Loss: 1.0691798981394847\n",
      "Epoch 24/50, Loss: 0.9182919224599683\n",
      "Epoch 25/50, Loss: 0.8232800714877027\n",
      "Epoch 26/50, Loss: 1.009824983772134\n",
      "Epoch 27/50, Loss: 0.9243393392024188\n",
      "Epoch 28/50, Loss: 0.9232988417157316\n",
      "Epoch 29/50, Loss: 0.6716836795478577\n",
      "Epoch 30/50, Loss: 1.1099703207385105\n",
      "Epoch 31/50, Loss: 0.9576552374744617\n",
      "Epoch 32/50, Loss: 0.8340252942652603\n",
      "Epoch 33/50, Loss: 0.8510249569399976\n",
      "Epoch 34/50, Loss: 1.0900454379767406\n",
      "Epoch 35/50, Loss: 0.9554085061802281\n",
      "Epoch 36/50, Loss: 0.7765566643568428\n",
      "Epoch 37/50, Loss: 0.9974010569390106\n",
      "Epoch 38/50, Loss: 1.0197321597038491\n",
      "Epoch 39/50, Loss: 0.9282163945658933\n",
      "Epoch 40/50, Loss: 1.0448755778496976\n",
      "Epoch 41/50, Loss: 0.7917838234042828\n",
      "Epoch 42/50, Loss: 1.0904570734145214\n",
      "Epoch 43/50, Loss: 1.122954091573092\n",
      "Epoch 44/50, Loss: 0.6504103813066813\n",
      "Epoch 45/50, Loss: 0.9721801576117067\n",
      "Epoch 46/50, Loss: 0.8543270771229184\n",
      "Epoch 47/50, Loss: 0.7023532034325586\n",
      "Epoch 48/50, Loss: 0.8095882279022342\n",
      "Epoch 49/50, Loss: 0.6939270980389214\n",
      "Epoch 50/50, Loss: 0.7329483079570726\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 76.13%'\n",
      "Epoch 1/100, Loss: 2.027436021544948\n",
      "Epoch 2/100, Loss: 1.7851403553714307\n",
      "Epoch 3/100, Loss: 1.650720311931275\n",
      "Epoch 4/100, Loss: 1.585812692144904\n",
      "Epoch 5/100, Loss: 1.5315927772550924\n",
      "Epoch 6/100, Loss: 1.3312529469930316\n",
      "Epoch 7/100, Loss: 1.281233781659233\n",
      "Epoch 8/100, Loss: 1.2937342346489682\n",
      "Epoch 9/100, Loss: 1.1042970987354312\n",
      "Epoch 10/100, Loss: 1.0826366305823774\n",
      "Epoch 11/100, Loss: 0.9648399423535651\n",
      "Epoch 12/100, Loss: 1.08526731171492\n",
      "Epoch 13/100, Loss: 0.9854789836724532\n",
      "Epoch 14/100, Loss: 1.1091296078751147\n",
      "Epoch 15/100, Loss: 0.9004916591997733\n",
      "Epoch 16/100, Loss: 0.9065052381157667\n",
      "Epoch 17/100, Loss: 0.8759892243005881\n",
      "Epoch 18/100, Loss: 0.9233646343980183\n",
      "Epoch 19/100, Loss: 0.9869401532157952\n",
      "Epoch 20/100, Loss: 0.8234657651407731\n",
      "Epoch 21/100, Loss: 0.9365979759749924\n",
      "Epoch 22/100, Loss: 1.0011410650933399\n",
      "Epoch 23/100, Loss: 0.9692601898367715\n",
      "Epoch 24/100, Loss: 0.7801367812264787\n",
      "Epoch 25/100, Loss: 0.8970094487311262\n",
      "Epoch 26/100, Loss: 0.8717540171138536\n",
      "Epoch 27/100, Loss: 0.8123329197050471\n",
      "Epoch 28/100, Loss: 0.7762744551432894\n",
      "Epoch 29/100, Loss: 0.8656361619866096\n",
      "Epoch 30/100, Loss: 0.7492082097501107\n",
      "Epoch 31/100, Loss: 0.7336127727235544\n",
      "Epoch 32/100, Loss: 0.9265344624324972\n",
      "Epoch 33/100, Loss: 1.0952073041165262\n",
      "Epoch 34/100, Loss: 0.9855665595986981\n",
      "Epoch 35/100, Loss: 0.8193092210476516\n",
      "Epoch 36/100, Loss: 0.8059001988563103\n",
      "Epoch 37/100, Loss: 0.6837884336730793\n",
      "Epoch 38/100, Loss: 0.902303711444432\n",
      "Epoch 39/100, Loss: 0.7664842948866724\n",
      "Epoch 40/100, Loss: 0.8517326830275017\n",
      "Epoch 41/100, Loss: 0.8382771823848182\n",
      "Epoch 42/100, Loss: 0.6983509151237997\n",
      "Epoch 43/100, Loss: 0.7848440745229552\n",
      "Epoch 44/100, Loss: 0.99425537589745\n",
      "Epoch 45/100, Loss: 0.8493478018678445\n",
      "Epoch 46/100, Loss: 0.7383122897930927\n",
      "Epoch 47/100, Loss: 0.8834442011969919\n",
      "Epoch 48/100, Loss: 0.9178634746142671\n",
      "Epoch 49/100, Loss: 0.6155720363138654\n",
      "Epoch 50/100, Loss: 0.7939918865828131\n",
      "Epoch 51/100, Loss: 0.6859093047470105\n",
      "Epoch 52/100, Loss: 0.7866643284804102\n",
      "Epoch 53/100, Loss: 0.9107311265540505\n",
      "Epoch 54/100, Loss: 0.8279069087976034\n",
      "Epoch 55/100, Loss: 0.7519664890192996\n",
      "Epoch 56/100, Loss: 0.7329993759316754\n",
      "Epoch 57/100, Loss: 0.9430988100517066\n",
      "Epoch 58/100, Loss: 0.5941570581541521\n",
      "Epoch 59/100, Loss: 0.7558750785409349\n",
      "Epoch 60/100, Loss: 0.7009293614454863\n",
      "Epoch 61/100, Loss: 0.6143980480505234\n",
      "Epoch 62/100, Loss: 0.7491849249051827\n",
      "Epoch 63/100, Loss: 0.6448859310553406\n",
      "Epoch 64/100, Loss: 0.676106786643661\n",
      "Epoch 65/100, Loss: 0.8725843115674423\n",
      "Epoch 66/100, Loss: 0.7098558496665774\n",
      "Epoch 67/100, Loss: 0.9986470156683219\n",
      "Epoch 68/100, Loss: 0.7954158096715802\n",
      "Epoch 69/100, Loss: 0.8783572978086083\n",
      "Epoch 70/100, Loss: 0.809675443105656\n",
      "Epoch 71/100, Loss: 0.723333608368455\n",
      "Epoch 72/100, Loss: 0.801797115320347\n",
      "Epoch 73/100, Loss: 0.9079682214652353\n",
      "Epoch 74/100, Loss: 0.7797300390126356\n",
      "Epoch 75/100, Loss: 0.5293213927814422\n",
      "Epoch 76/100, Loss: 0.664754246396774\n",
      "Epoch 77/100, Loss: 0.5562176097996183\n",
      "Epoch 78/100, Loss: 0.9352937054554881\n",
      "Epoch 79/100, Loss: 0.7139025878159969\n",
      "Epoch 80/100, Loss: 0.8204325505298865\n",
      "Epoch 81/100, Loss: 0.7203578955162624\n",
      "Epoch 82/100, Loss: 0.7808218850936697\n",
      "Epoch 83/100, Loss: 0.7696577571075557\n",
      "Epoch 84/100, Loss: 0.7977118778924086\n",
      "Epoch 85/100, Loss: 0.6629282360995865\n",
      "Epoch 86/100, Loss: 0.9320894873111186\n",
      "Epoch 87/100, Loss: 0.9293324674786981\n",
      "Epoch 88/100, Loss: 0.7398363131289192\n",
      "Epoch 89/100, Loss: 0.7980295799163675\n",
      "Epoch 90/100, Loss: 0.5851144417776499\n",
      "Epoch 91/100, Loss: 0.7406929604567462\n",
      "Epoch 92/100, Loss: 0.712945103406186\n",
      "Epoch 93/100, Loss: 0.6013638898833179\n",
      "Epoch 94/100, Loss: 0.5457431477109832\n",
      "Epoch 95/100, Loss: 0.817509985785991\n",
      "Epoch 96/100, Loss: 0.6102577446272485\n",
      "Epoch 97/100, Loss: 0.599998244677698\n",
      "Epoch 98/100, Loss: 0.8713012432708834\n",
      "Epoch 99/100, Loss: 0.7628103749503423\n",
      "Epoch 100/100, Loss: 0.6224081482798497\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 78.93%'\n",
      "Epoch 1/150, Loss: 1.9801240288998756\n",
      "Epoch 2/150, Loss: 1.744499018574855\n",
      "Epoch 3/150, Loss: 1.7235591239644021\n",
      "Epoch 4/150, Loss: 1.4231764214002203\n",
      "Epoch 5/150, Loss: 1.380176789939035\n",
      "Epoch 6/150, Loss: 1.3558957454271463\n",
      "Epoch 7/150, Loss: 1.2951610082830374\n",
      "Epoch 8/150, Loss: 1.2963774634953718\n",
      "Epoch 9/150, Loss: 1.1733465681611592\n",
      "Epoch 10/150, Loss: 1.1681386888549603\n",
      "Epoch 11/150, Loss: 1.151588828564997\n",
      "Epoch 12/150, Loss: 1.1242415731298026\n",
      "Epoch 13/150, Loss: 1.1700960132748008\n",
      "Epoch 14/150, Loss: 1.0409299174208224\n",
      "Epoch 15/150, Loss: 0.8905672927307972\n",
      "Epoch 16/150, Loss: 1.194101407970465\n",
      "Epoch 17/150, Loss: 0.8576974950173681\n",
      "Epoch 18/150, Loss: 1.095592844846903\n",
      "Epoch 19/150, Loss: 1.0288214181748845\n",
      "Epoch 20/150, Loss: 0.7827343338378339\n",
      "Epoch 21/150, Loss: 1.1283558560136253\n",
      "Epoch 22/150, Loss: 0.7487212909461326\n",
      "Epoch 23/150, Loss: 0.9809656780749134\n",
      "Epoch 24/150, Loss: 0.8708057100857856\n",
      "Epoch 25/150, Loss: 0.9429230036945673\n",
      "Epoch 26/150, Loss: 0.7956842609775174\n",
      "Epoch 27/150, Loss: 0.8192108586576766\n",
      "Epoch 28/150, Loss: 0.8949798256904999\n",
      "Epoch 29/150, Loss: 0.7304099771988477\n",
      "Epoch 30/150, Loss: 0.962505746385824\n",
      "Epoch 31/150, Loss: 0.770491854864001\n",
      "Epoch 32/150, Loss: 0.695771279281884\n",
      "Epoch 33/150, Loss: 0.8818979351615335\n",
      "Epoch 34/150, Loss: 0.7872383419830611\n",
      "Epoch 35/150, Loss: 0.8876178678191929\n",
      "Epoch 36/150, Loss: 0.8494353095933592\n",
      "Epoch 37/150, Loss: 0.646813287870923\n",
      "Epoch 38/150, Loss: 0.9624224894148882\n",
      "Epoch 39/150, Loss: 0.7937463784533406\n",
      "Epoch 40/150, Loss: 0.8447806766848965\n",
      "Epoch 41/150, Loss: 0.923624452871883\n",
      "Epoch 42/150, Loss: 0.9643139464528716\n",
      "Epoch 43/150, Loss: 1.0051203886549016\n",
      "Epoch 44/150, Loss: 0.7446081129873827\n",
      "Epoch 45/150, Loss: 0.6810733364911996\n",
      "Epoch 46/150, Loss: 0.8232034444624114\n",
      "Epoch 47/150, Loss: 0.814173531747732\n",
      "Epoch 48/150, Loss: 0.7952014511724559\n",
      "Epoch 49/150, Loss: 0.7102642669584066\n",
      "Epoch 50/150, Loss: 0.6789501803828376\n",
      "Epoch 51/150, Loss: 0.7928381022657325\n",
      "Epoch 52/150, Loss: 0.6345026959685344\n",
      "Epoch 53/150, Loss: 0.6095661008356432\n",
      "Epoch 54/150, Loss: 0.7486602063631737\n",
      "Epoch 55/150, Loss: 0.7405902117712632\n",
      "Epoch 56/150, Loss: 1.0538956707909672\n",
      "Epoch 57/150, Loss: 0.7500773763160444\n",
      "Epoch 58/150, Loss: 0.8901011150188741\n",
      "Epoch 59/150, Loss: 0.8779725966430502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150, Loss: 0.6647835209252182\n",
      "Epoch 61/150, Loss: 0.5377721048471283\n",
      "Epoch 62/150, Loss: 0.7265473962363274\n",
      "Epoch 63/150, Loss: 0.900811354778895\n",
      "Epoch 64/150, Loss: 0.7464212263178714\n",
      "Epoch 65/150, Loss: 1.0051370493285499\n",
      "Epoch 66/150, Loss: 0.8356807544930611\n",
      "Epoch 67/150, Loss: 0.7234414523163325\n",
      "Epoch 68/150, Loss: 0.7554558038999163\n",
      "Epoch 69/150, Loss: 0.6361412829548633\n",
      "Epoch 70/150, Loss: 0.910751813942538\n",
      "Epoch 71/150, Loss: 0.8998401292477098\n",
      "Epoch 72/150, Loss: 0.8819539910835594\n",
      "Epoch 73/150, Loss: 0.9534137201837614\n",
      "Epoch 74/150, Loss: 0.8662762645981557\n",
      "Epoch 75/150, Loss: 0.4807674946673667\n",
      "Epoch 76/150, Loss: 0.8976514108456259\n",
      "Epoch 77/150, Loss: 0.78753101640052\n",
      "Epoch 78/150, Loss: 0.6666018609839456\n",
      "Epoch 79/150, Loss: 0.7862112572491436\n",
      "Epoch 80/150, Loss: 0.6228269536709359\n",
      "Epoch 81/150, Loss: 0.8339884525415734\n",
      "Epoch 82/150, Loss: 0.6003338129247598\n",
      "Epoch 83/150, Loss: 0.8743878057559904\n",
      "Epoch 84/150, Loss: 0.7407106604662795\n",
      "Epoch 85/150, Loss: 0.614754181276698\n",
      "Epoch 86/150, Loss: 0.5614016421825713\n",
      "Epoch 87/150, Loss: 0.7562794044389488\n",
      "Epoch 88/150, Loss: 0.5617691691506727\n",
      "Epoch 89/150, Loss: 0.7094017891929929\n",
      "Epoch 90/150, Loss: 0.7398094554719232\n",
      "Epoch 91/150, Loss: 0.6760904908577611\n",
      "Epoch 92/150, Loss: 0.46493171767340113\n",
      "Epoch 93/150, Loss: 0.7854319769693974\n",
      "Epoch 94/150, Loss: 0.7824485433913028\n",
      "Epoch 95/150, Loss: 0.6497137021829067\n",
      "Epoch 96/150, Loss: 0.6715742502208973\n",
      "Epoch 97/150, Loss: 0.8122756393019708\n",
      "Epoch 98/150, Loss: 0.7664037324163269\n",
      "Epoch 99/150, Loss: 0.7565155141115502\n",
      "Epoch 100/150, Loss: 0.79769571771542\n",
      "Epoch 101/150, Loss: 0.44435324914314106\n",
      "Epoch 102/150, Loss: 0.597158016834956\n",
      "Epoch 103/150, Loss: 0.7821061362021869\n",
      "Epoch 104/150, Loss: 0.7528240797751155\n",
      "Epoch 105/150, Loss: 0.7192738010161002\n",
      "Epoch 106/150, Loss: 0.5455225327799224\n",
      "Epoch 107/150, Loss: 0.7466275128181626\n",
      "Epoch 108/150, Loss: 0.686378838595171\n",
      "Epoch 109/150, Loss: 0.7642415069408202\n",
      "Epoch 110/150, Loss: 0.6320172077583868\n",
      "Epoch 111/150, Loss: 0.6926175022954948\n",
      "Epoch 112/150, Loss: 0.8108889745539298\n",
      "Epoch 113/150, Loss: 0.590547956378041\n",
      "Epoch 114/150, Loss: 0.7125790459096035\n",
      "Epoch 115/150, Loss: 0.6362006787396892\n",
      "Epoch 116/150, Loss: 0.688129704678375\n",
      "Epoch 117/150, Loss: 0.7106286705182172\n",
      "Epoch 118/150, Loss: 0.7519651323574933\n",
      "Epoch 119/150, Loss: 0.6053544353741656\n",
      "Epoch 120/150, Loss: 0.8300808223230004\n",
      "Epoch 121/150, Loss: 0.5836163788563532\n",
      "Epoch 122/150, Loss: 0.5741197994197192\n",
      "Epoch 123/150, Loss: 0.5163224593063219\n",
      "Epoch 124/150, Loss: 0.8085018704230422\n",
      "Epoch 125/150, Loss: 0.66567738670475\n",
      "Epoch 126/150, Loss: 0.600391189953926\n",
      "Epoch 127/150, Loss: 0.6546594114247994\n",
      "Epoch 128/150, Loss: 0.6003067803822707\n",
      "Epoch 129/150, Loss: 0.8075875492220828\n",
      "Epoch 130/150, Loss: 0.5961273513996866\n",
      "Epoch 131/150, Loss: 0.6812686360496863\n",
      "Epoch 132/150, Loss: 0.8477554166161232\n",
      "Epoch 133/150, Loss: 0.4687091256349978\n",
      "Epoch 134/150, Loss: 0.7326520818366339\n",
      "Epoch 135/150, Loss: 0.47575927754225705\n",
      "Epoch 136/150, Loss: 0.494212346672433\n",
      "Epoch 137/150, Loss: 0.7230600344121799\n",
      "Epoch 138/150, Loss: 0.690661683219519\n",
      "Epoch 139/150, Loss: 0.7559145557502854\n",
      "Epoch 140/150, Loss: 0.591940898546451\n",
      "Epoch 141/150, Loss: 0.7070740798820165\n",
      "Epoch 142/150, Loss: 0.8118762456301135\n",
      "Epoch 143/150, Loss: 0.8207191468803308\n",
      "Epoch 144/150, Loss: 0.5247341069192062\n",
      "Epoch 145/150, Loss: 0.5088649541382906\n",
      "Epoch 146/150, Loss: 0.42234638247272865\n",
      "Epoch 147/150, Loss: 0.5476973077918127\n",
      "Epoch 148/150, Loss: 0.5638368385113223\n",
      "Epoch 149/150, Loss: 0.6427475402106763\n",
      "Epoch 150/150, Loss: 0.785492829103102\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 80.12%'\n",
      "Epoch 1/50, Loss: 2.0870909197593246\n",
      "Epoch 2/50, Loss: 1.9594368116529624\n",
      "Epoch 3/50, Loss: 1.8550275108326149\n",
      "Epoch 4/50, Loss: 1.7761764625694347\n",
      "Epoch 5/50, Loss: 1.698853604695722\n",
      "Epoch 6/50, Loss: 1.6976278605503161\n",
      "Epoch 7/50, Loss: 1.699067923335609\n",
      "Epoch 8/50, Loss: 1.4982941977218256\n",
      "Epoch 9/50, Loss: 1.4306530161061806\n",
      "Epoch 10/50, Loss: 1.396858665463953\n",
      "Epoch 11/50, Loss: 1.44936501776859\n",
      "Epoch 12/50, Loss: 1.3601353553856854\n",
      "Epoch 13/50, Loss: 1.3129435131968117\n",
      "Epoch 14/50, Loss: 1.3495789334913435\n",
      "Epoch 15/50, Loss: 1.3543478443510302\n",
      "Epoch 16/50, Loss: 1.4442155043718965\n",
      "Epoch 17/50, Loss: 1.0825124598356977\n",
      "Epoch 18/50, Loss: 1.3347362968400307\n",
      "Epoch 19/50, Loss: 1.0596326737168087\n",
      "Epoch 20/50, Loss: 1.2859949465910965\n",
      "Epoch 21/50, Loss: 1.0752213507009993\n",
      "Epoch 22/50, Loss: 1.0633628980832424\n",
      "Epoch 23/50, Loss: 1.0620902605944988\n",
      "Epoch 24/50, Loss: 1.0416201568787902\n",
      "Epoch 25/50, Loss: 0.9159332756307589\n",
      "Epoch 26/50, Loss: 1.0395346543230732\n",
      "Epoch 27/50, Loss: 1.155433920316088\n",
      "Epoch 28/50, Loss: 1.0419483295103085\n",
      "Epoch 29/50, Loss: 1.08581411200081\n",
      "Epoch 30/50, Loss: 1.0943176034021818\n",
      "Epoch 31/50, Loss: 1.075987859402466\n",
      "Epoch 32/50, Loss: 1.0281181971008868\n",
      "Epoch 33/50, Loss: 1.0876803920141263\n",
      "Epoch 34/50, Loss: 0.9086790666154668\n",
      "Epoch 35/50, Loss: 0.9497769369547707\n",
      "Epoch 36/50, Loss: 1.0369206393347885\n",
      "Epoch 37/50, Loss: 1.0088502760085465\n",
      "Epoch 38/50, Loss: 0.8677895329543373\n",
      "Epoch 39/50, Loss: 1.0500260579542136\n",
      "Epoch 40/50, Loss: 0.947389542147263\n",
      "Epoch 41/50, Loss: 1.074468979562503\n",
      "Epoch 42/50, Loss: 1.059672720710618\n",
      "Epoch 43/50, Loss: 0.9253811886634556\n",
      "Epoch 44/50, Loss: 0.9265455532659305\n",
      "Epoch 45/50, Loss: 0.7457848548939014\n",
      "Epoch 46/50, Loss: 0.8613670150724149\n",
      "Epoch 47/50, Loss: 0.934237000698166\n",
      "Epoch 48/50, Loss: 1.0046961096980278\n",
      "Epoch 49/50, Loss: 0.9111542142417931\n",
      "Epoch 50/50, Loss: 0.9375587432990722\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 72.06%'\n",
      "Epoch 1/100, Loss: 2.139037590001744\n",
      "Epoch 2/100, Loss: 1.9669604244626808\n",
      "Epoch 3/100, Loss: 1.9116583678226817\n",
      "Epoch 4/100, Loss: 1.8188051108040133\n",
      "Epoch 5/100, Loss: 1.7606763037151694\n",
      "Epoch 6/100, Loss: 1.6459134845856616\n",
      "Epoch 7/100, Loss: 1.647072136402098\n",
      "Epoch 8/100, Loss: 1.578036774628631\n",
      "Epoch 9/100, Loss: 1.4644851444307403\n",
      "Epoch 10/100, Loss: 1.4599594580903181\n",
      "Epoch 11/100, Loss: 1.4413111291255736\n",
      "Epoch 12/100, Loss: 1.4437987955136957\n",
      "Epoch 13/100, Loss: 1.3826155398432862\n",
      "Epoch 14/100, Loss: 1.2885153864223895\n",
      "Epoch 15/100, Loss: 1.3034499420192036\n",
      "Epoch 16/100, Loss: 1.2779385401874483\n",
      "Epoch 17/100, Loss: 1.1815734169765686\n",
      "Epoch 18/100, Loss: 1.261576301316796\n",
      "Epoch 19/100, Loss: 1.185390742582267\n",
      "Epoch 20/100, Loss: 1.095324846215119\n",
      "Epoch 21/100, Loss: 1.2247872720786117\n",
      "Epoch 22/100, Loss: 1.1398884650236365\n",
      "Epoch 23/100, Loss: 1.2153692782416838\n",
      "Epoch 24/100, Loss: 0.9904422812239181\n",
      "Epoch 25/100, Loss: 1.106706773723022\n",
      "Epoch 26/100, Loss: 1.1590351910737673\n",
      "Epoch 27/100, Loss: 1.083637737546378\n",
      "Epoch 28/100, Loss: 1.032289411718494\n",
      "Epoch 29/100, Loss: 1.114379327023693\n",
      "Epoch 30/100, Loss: 1.0782397418399194\n",
      "Epoch 31/100, Loss: 1.019057032606942\n",
      "Epoch 32/100, Loss: 0.99284919465247\n",
      "Epoch 33/100, Loss: 1.0106977352040163\n",
      "Epoch 34/100, Loss: 0.9225265788038901\n",
      "Epoch 35/100, Loss: 1.1877017582891363\n",
      "Epoch 36/100, Loss: 1.168854699622997\n",
      "Epoch 37/100, Loss: 0.9398130438914672\n",
      "Epoch 38/100, Loss: 1.0108466912276426\n",
      "Epoch 39/100, Loss: 0.9303549323030577\n",
      "Epoch 40/100, Loss: 0.9320646799851957\n",
      "Epoch 41/100, Loss: 1.138787937316854\n",
      "Epoch 42/100, Loss: 0.9468306841121045\n",
      "Epoch 43/100, Loss: 0.9681403304383862\n",
      "Epoch 44/100, Loss: 0.9312571945185029\n",
      "Epoch 45/100, Loss: 1.0528597026540967\n",
      "Epoch 46/100, Loss: 1.083739339649901\n",
      "Epoch 47/100, Loss: 0.9513270912989167\n",
      "Epoch 48/100, Loss: 0.9553859433865762\n",
      "Epoch 49/100, Loss: 0.97820229722957\n",
      "Epoch 50/100, Loss: 0.8266926967045343\n",
      "Epoch 51/100, Loss: 0.8193517161990289\n",
      "Epoch 52/100, Loss: 1.0462741817808736\n",
      "Epoch 53/100, Loss: 0.963821564844943\n",
      "Epoch 54/100, Loss: 0.8162867880096781\n",
      "Epoch 55/100, Loss: 0.8470158641970504\n",
      "Epoch 56/100, Loss: 0.86238691999573\n",
      "Epoch 57/100, Loss: 0.855733461491235\n",
      "Epoch 58/100, Loss: 0.9286534338294767\n",
      "Epoch 59/100, Loss: 1.0704535995131792\n",
      "Epoch 60/100, Loss: 0.7472261449945605\n",
      "Epoch 61/100, Loss: 0.8431237452025746\n",
      "Epoch 62/100, Loss: 0.8683109639797785\n",
      "Epoch 63/100, Loss: 0.9643628532820694\n",
      "Epoch 64/100, Loss: 1.0667365721456934\n",
      "Epoch 65/100, Loss: 0.9194524540301624\n",
      "Epoch 66/100, Loss: 0.8457463313274569\n",
      "Epoch 67/100, Loss: 0.9492161729420556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Loss: 0.9959812060394422\n",
      "Epoch 69/100, Loss: 0.8614727983155658\n",
      "Epoch 70/100, Loss: 0.864789055119189\n",
      "Epoch 71/100, Loss: 0.8412325214337252\n",
      "Epoch 72/100, Loss: 0.9123831369151307\n",
      "Epoch 73/100, Loss: 0.881313502781674\n",
      "Epoch 74/100, Loss: 0.8574100014387388\n",
      "Epoch 75/100, Loss: 0.8835851832154736\n",
      "Epoch 76/100, Loss: 0.9625611506777413\n",
      "Epoch 77/100, Loss: 0.9702157305345814\n",
      "Epoch 78/100, Loss: 1.0535106243457093\n",
      "Epoch 79/100, Loss: 0.7227291610859223\n",
      "Epoch 80/100, Loss: 0.9221363779407007\n",
      "Epoch 81/100, Loss: 0.7833856273448602\n",
      "Epoch 82/100, Loss: 0.8149408166676589\n",
      "Epoch 83/100, Loss: 0.7075541929092825\n",
      "Epoch 84/100, Loss: 0.8253841462777203\n",
      "Epoch 85/100, Loss: 0.8142396602834991\n",
      "Epoch 86/100, Loss: 0.9415426390928365\n",
      "Epoch 87/100, Loss: 0.8408528810675475\n",
      "Epoch 88/100, Loss: 0.9192182692642212\n",
      "Epoch 89/100, Loss: 0.9259353039303484\n",
      "Epoch 90/100, Loss: 0.6973516444602281\n",
      "Epoch 91/100, Loss: 0.7033404543863806\n",
      "Epoch 92/100, Loss: 0.8571143344066277\n",
      "Epoch 93/100, Loss: 0.8469040064866716\n",
      "Epoch 94/100, Loss: 0.8103321696947573\n",
      "Epoch 95/100, Loss: 0.8596355612422244\n",
      "Epoch 96/100, Loss: 0.8630969816781844\n",
      "Epoch 97/100, Loss: 0.9465364508556282\n",
      "Epoch 98/100, Loss: 0.7823244750583539\n",
      "Epoch 99/100, Loss: 0.7221134477229916\n",
      "Epoch 100/100, Loss: 0.8989238193732612\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 76.07%'\n",
      "Epoch 1/150, Loss: 2.1381561110716674\n",
      "Epoch 2/150, Loss: 2.0377741588332303\n",
      "Epoch 3/150, Loss: 1.9181770541350358\n",
      "Epoch 4/150, Loss: 1.7751179206950833\n",
      "Epoch 5/150, Loss: 1.6848200608953083\n",
      "Epoch 6/150, Loss: 1.5961531579307466\n",
      "Epoch 7/150, Loss: 1.5126814512841715\n",
      "Epoch 8/150, Loss: 1.5210867192638597\n",
      "Epoch 9/150, Loss: 1.5630475271943725\n",
      "Epoch 10/150, Loss: 1.4762924265795323\n",
      "Epoch 11/150, Loss: 1.4217833251267291\n",
      "Epoch 12/150, Loss: 1.4027050310049372\n",
      "Epoch 13/150, Loss: 1.3866524763553627\n",
      "Epoch 14/150, Loss: 1.2910683605726838\n",
      "Epoch 15/150, Loss: 1.2982898764008686\n",
      "Epoch 16/150, Loss: 1.2343903889806258\n",
      "Epoch 17/150, Loss: 1.2205572982148376\n",
      "Epoch 18/150, Loss: 1.1212246112971718\n",
      "Epoch 19/150, Loss: 1.1507008474912348\n",
      "Epoch 20/150, Loss: 1.199939486206842\n",
      "Epoch 21/150, Loss: 1.1729871814380757\n",
      "Epoch 22/150, Loss: 1.1535931297884168\n",
      "Epoch 23/150, Loss: 1.1358490386859317\n",
      "Epoch 24/150, Loss: 1.084704026271655\n",
      "Epoch 25/150, Loss: 1.081141298120318\n",
      "Epoch 26/150, Loss: 1.111169663446648\n",
      "Epoch 27/150, Loss: 1.0618287289622843\n",
      "Epoch 28/150, Loss: 1.17795225363276\n",
      "Epoch 29/150, Loss: 1.0397296658905646\n",
      "Epoch 30/150, Loss: 0.9994653872498673\n",
      "Epoch 31/150, Loss: 1.0394271997424573\n",
      "Epoch 32/150, Loss: 0.8651612388319483\n",
      "Epoch 33/150, Loss: 1.0874872248889615\n",
      "Epoch 34/150, Loss: 1.059657373429847\n",
      "Epoch 35/150, Loss: 1.0517492007049873\n",
      "Epoch 36/150, Loss: 0.9995132662677559\n",
      "Epoch 37/150, Loss: 0.8951600206195541\n",
      "Epoch 38/150, Loss: 1.0492862103753613\n",
      "Epoch 39/150, Loss: 1.0316074134398705\n",
      "Epoch 40/150, Loss: 0.812182420928644\n",
      "Epoch 41/150, Loss: 0.8711767508685468\n",
      "Epoch 42/150, Loss: 0.817287134827495\n",
      "Epoch 43/150, Loss: 1.0090978298143154\n",
      "Epoch 44/150, Loss: 0.9848535724453577\n",
      "Epoch 45/150, Loss: 0.8570365255060349\n",
      "Epoch 46/150, Loss: 1.0832436996624017\n",
      "Epoch 47/150, Loss: 1.095435538314589\n",
      "Epoch 48/150, Loss: 0.8694846316367023\n",
      "Epoch 49/150, Loss: 0.9672805123388091\n",
      "Epoch 50/150, Loss: 1.0026784719442263\n",
      "Epoch 51/150, Loss: 1.0504071436667572\n",
      "Epoch 52/150, Loss: 0.9793201960611623\n",
      "Epoch 53/150, Loss: 0.8486269476691813\n",
      "Epoch 54/150, Loss: 0.9150181137325543\n",
      "Epoch 55/150, Loss: 0.7992830473438967\n",
      "Epoch 56/150, Loss: 0.8876319394819515\n",
      "Epoch 57/150, Loss: 0.758053340873988\n",
      "Epoch 58/150, Loss: 0.8424457567106175\n",
      "Epoch 59/150, Loss: 0.74986667746729\n",
      "Epoch 60/150, Loss: 0.8914150925201509\n",
      "Epoch 61/150, Loss: 0.8778314376239394\n",
      "Epoch 62/150, Loss: 0.8065878352874856\n",
      "Epoch 63/150, Loss: 0.794598133923257\n",
      "Epoch 64/150, Loss: 0.8370956944671799\n",
      "Epoch 65/150, Loss: 0.9420707082086734\n",
      "Epoch 66/150, Loss: 0.8592292792157116\n",
      "Epoch 67/150, Loss: 0.8231799117179185\n",
      "Epoch 68/150, Loss: 0.9641678434564221\n",
      "Epoch 69/150, Loss: 0.8499843742186058\n",
      "Epoch 70/150, Loss: 1.0654082026975642\n",
      "Epoch 71/150, Loss: 0.804233749727858\n",
      "Epoch 72/150, Loss: 0.9102502335592161\n",
      "Epoch 73/150, Loss: 0.6993454030762112\n",
      "Epoch 74/150, Loss: 0.7399471279964914\n",
      "Epoch 75/150, Loss: 0.8472302418409822\n",
      "Epoch 76/150, Loss: 0.8064171136441102\n",
      "Epoch 77/150, Loss: 0.8672959922359085\n",
      "Epoch 78/150, Loss: 0.6960215007883338\n",
      "Epoch 79/150, Loss: 0.7326997668844465\n",
      "Epoch 80/150, Loss: 0.8424699010793415\n",
      "Epoch 81/150, Loss: 0.872813702266034\n",
      "Epoch 82/150, Loss: 0.7483911936450479\n",
      "Epoch 83/150, Loss: 0.7110442182985275\n",
      "Epoch 84/150, Loss: 0.7251339184619624\n",
      "Epoch 85/150, Loss: 0.7902030282607442\n",
      "Epoch 86/150, Loss: 0.8221834282762202\n",
      "Epoch 87/150, Loss: 0.9477410489597733\n",
      "Epoch 88/150, Loss: 0.8290811312481899\n",
      "Epoch 89/150, Loss: 0.7511761198101151\n",
      "Epoch 90/150, Loss: 0.8334616468458987\n",
      "Epoch 91/150, Loss: 0.8785817053314393\n",
      "Epoch 92/150, Loss: 0.8234842127451405\n",
      "Epoch 93/150, Loss: 0.9025643221329849\n",
      "Epoch 94/150, Loss: 0.7336628839922623\n",
      "Epoch 95/150, Loss: 0.8147482032556135\n",
      "Epoch 96/150, Loss: 0.8031680599249704\n",
      "Epoch 97/150, Loss: 0.7132863829494143\n",
      "Epoch 98/150, Loss: 0.7214389177860415\n",
      "Epoch 99/150, Loss: 0.9007998825555218\n",
      "Epoch 100/150, Loss: 0.7163944953851487\n",
      "Epoch 101/150, Loss: 0.7881566461463427\n",
      "Epoch 102/150, Loss: 0.802641368926561\n",
      "Epoch 103/150, Loss: 0.82543731592689\n",
      "Epoch 104/150, Loss: 0.7786033293708292\n",
      "Epoch 105/150, Loss: 0.7861208173784953\n",
      "Epoch 106/150, Loss: 0.8276723879452498\n",
      "Epoch 107/150, Loss: 0.8115423289141879\n",
      "Epoch 108/150, Loss: 0.8480400267937747\n",
      "Epoch 109/150, Loss: 0.8500650429888468\n",
      "Epoch 110/150, Loss: 0.8089660709257342\n",
      "Epoch 111/150, Loss: 0.7524742424249253\n",
      "Epoch 112/150, Loss: 0.8638259090949296\n",
      "Epoch 113/150, Loss: 0.7671881509247135\n",
      "Epoch 114/150, Loss: 0.7564847994500946\n",
      "Epoch 115/150, Loss: 0.8801460867851654\n",
      "Epoch 116/150, Loss: 0.6399769050997139\n",
      "Epoch 117/150, Loss: 0.7156959003866928\n",
      "Epoch 118/150, Loss: 0.8242426683168105\n",
      "Epoch 119/150, Loss: 0.7864021557558101\n",
      "Epoch 120/150, Loss: 0.8845409507290269\n",
      "Epoch 121/150, Loss: 0.7892955208005888\n",
      "Epoch 122/150, Loss: 0.8113618019766334\n",
      "Epoch 123/150, Loss: 0.9331372926337466\n",
      "Epoch 124/150, Loss: 0.6666320172999534\n",
      "Epoch 125/150, Loss: 0.7945726345533052\n",
      "Epoch 126/150, Loss: 0.732715340338883\n",
      "Epoch 127/150, Loss: 0.7584157909476836\n",
      "Epoch 128/150, Loss: 0.848166769134864\n",
      "Epoch 129/150, Loss: 0.8422405400160384\n",
      "Epoch 130/150, Loss: 0.7516234116215795\n",
      "Epoch 131/150, Loss: 0.7101358917548541\n",
      "Epoch 132/150, Loss: 0.6454146541655345\n",
      "Epoch 133/150, Loss: 0.8574853975312025\n",
      "Epoch 134/150, Loss: 0.8400509156855446\n",
      "Epoch 135/150, Loss: 0.7004745530628257\n",
      "Epoch 136/150, Loss: 0.6141364384560687\n",
      "Epoch 137/150, Loss: 0.8557023610661839\n",
      "Epoch 138/150, Loss: 0.7816683322600478\n",
      "Epoch 139/150, Loss: 0.8285343047935643\n",
      "Epoch 140/150, Loss: 0.7666575529154829\n",
      "Epoch 141/150, Loss: 0.7363037234345486\n",
      "Epoch 142/150, Loss: 0.8297306398384628\n",
      "Epoch 143/150, Loss: 0.7479061006277694\n",
      "Epoch 144/150, Loss: 0.703209745215166\n",
      "Epoch 145/150, Loss: 0.6816077354841028\n",
      "Epoch 146/150, Loss: 0.9001140838185417\n",
      "Epoch 147/150, Loss: 0.6309492014078055\n",
      "Epoch 148/150, Loss: 0.7108403747590636\n",
      "Epoch 149/150, Loss: 0.6312596195208855\n",
      "Epoch 150/150, Loss: 0.8652053253575802\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 78.09%'\n",
      "Epoch 1/50, Loss: 2.2266594742858454\n",
      "Epoch 2/50, Loss: 2.1485726711369337\n",
      "Epoch 3/50, Loss: 2.091721744066453\n",
      "Epoch 4/50, Loss: 2.0200303546653626\n",
      "Epoch 5/50, Loss: 1.9415362197244974\n",
      "Epoch 6/50, Loss: 1.9473762432862598\n",
      "Epoch 7/50, Loss: 1.8738927054506374\n",
      "Epoch 8/50, Loss: 1.8127600636707502\n",
      "Epoch 9/50, Loss: 1.8029097535772847\n",
      "Epoch 10/50, Loss: 1.7096850548795344\n",
      "Epoch 11/50, Loss: 1.6294705061578452\n",
      "Epoch 12/50, Loss: 1.6470711285641708\n",
      "Epoch 13/50, Loss: 1.5848816601720783\n",
      "Epoch 14/50, Loss: 1.5383866811483704\n",
      "Epoch 15/50, Loss: 1.5310509888725559\n",
      "Epoch 16/50, Loss: 1.472927466742524\n",
      "Epoch 17/50, Loss: 1.5081320649417265\n",
      "Epoch 18/50, Loss: 1.4699497094791738\n",
      "Epoch 19/50, Loss: 1.4226263724015138\n",
      "Epoch 20/50, Loss: 1.4709748626228567\n",
      "Epoch 21/50, Loss: 1.4644459762382493\n",
      "Epoch 22/50, Loss: 1.3578240965905064\n",
      "Epoch 23/50, Loss: 1.3426797911848356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 1.4245319626903754\n",
      "Epoch 25/50, Loss: 1.326306908895088\n",
      "Epoch 26/50, Loss: 1.3360753594819106\n",
      "Epoch 27/50, Loss: 1.3008068416893106\n",
      "Epoch 28/50, Loss: 1.2949521090587894\n",
      "Epoch 29/50, Loss: 1.3055610149000885\n",
      "Epoch 30/50, Loss: 1.2887036705067956\n",
      "Epoch 31/50, Loss: 1.181373899268807\n",
      "Epoch 32/50, Loss: 1.2458314917606104\n",
      "Epoch 33/50, Loss: 1.3124238870921563\n",
      "Epoch 34/50, Loss: 1.153537344529026\n",
      "Epoch 35/50, Loss: 1.2425518188079927\n",
      "Epoch 36/50, Loss: 1.169146140074862\n",
      "Epoch 37/50, Loss: 1.2458694233094267\n",
      "Epoch 38/50, Loss: 1.148851547141704\n",
      "Epoch 39/50, Loss: 1.180924132398852\n",
      "Epoch 40/50, Loss: 1.1677449467769143\n",
      "Epoch 41/50, Loss: 1.2132783617363152\n",
      "Epoch 42/50, Loss: 1.255527052443865\n",
      "Epoch 43/50, Loss: 1.0732177997680468\n",
      "Epoch 44/50, Loss: 1.1188621813916244\n",
      "Epoch 45/50, Loss: 1.0335652184010315\n",
      "Epoch 46/50, Loss: 1.1027616472963802\n",
      "Epoch 47/50, Loss: 1.1605353093829764\n",
      "Epoch 48/50, Loss: 1.1180050933921049\n",
      "Epoch 49/50, Loss: 1.1804877569252366\n",
      "Epoch 50/50, Loss: 1.0844313228310956\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 67.99%'\n",
      "Epoch 1/100, Loss: 2.2111071011281513\n",
      "Epoch 2/100, Loss: 2.1328480932476084\n",
      "Epoch 3/100, Loss: 2.0685645886323645\n",
      "Epoch 4/100, Loss: 2.0089357780842367\n",
      "Epoch 5/100, Loss: 1.9491270428623315\n",
      "Epoch 6/100, Loss: 1.9170217176562523\n",
      "Epoch 7/100, Loss: 1.8581017336662604\n",
      "Epoch 8/100, Loss: 1.825880494489597\n",
      "Epoch 9/100, Loss: 1.7406938803452765\n",
      "Epoch 10/100, Loss: 1.7221962720880228\n",
      "Epoch 11/100, Loss: 1.6869928565563859\n",
      "Epoch 12/100, Loss: 1.6486663795117606\n",
      "Epoch 13/100, Loss: 1.645131535917226\n",
      "Epoch 14/100, Loss: 1.6115674243764586\n",
      "Epoch 15/100, Loss: 1.6599337412253738\n",
      "Epoch 16/100, Loss: 1.5286757265707136\n",
      "Epoch 17/100, Loss: 1.469816749763915\n",
      "Epoch 18/100, Loss: 1.526795549792456\n",
      "Epoch 19/100, Loss: 1.4801504687693476\n",
      "Epoch 20/100, Loss: 1.4050557116599132\n",
      "Epoch 21/100, Loss: 1.439551212444641\n",
      "Epoch 22/100, Loss: 1.4877368584628083\n",
      "Epoch 23/100, Loss: 1.3419300380410786\n",
      "Epoch 24/100, Loss: 1.3039319036404662\n",
      "Epoch 25/100, Loss: 1.3349103741631982\n",
      "Epoch 26/100, Loss: 1.3458329646935248\n",
      "Epoch 27/100, Loss: 1.3173673646946906\n",
      "Epoch 28/100, Loss: 1.2874277653923911\n",
      "Epoch 29/100, Loss: 1.440766843184583\n",
      "Epoch 30/100, Loss: 1.2898090259278616\n",
      "Epoch 31/100, Loss: 1.2616289440843196\n",
      "Epoch 32/100, Loss: 1.2529754367496455\n",
      "Epoch 33/100, Loss: 1.1724292622795913\n",
      "Epoch 34/100, Loss: 1.1736783722250754\n",
      "Epoch 35/100, Loss: 1.1871758708390043\n",
      "Epoch 36/100, Loss: 1.135307957208888\n",
      "Epoch 37/100, Loss: 1.211869902072739\n",
      "Epoch 38/100, Loss: 1.133666875577101\n",
      "Epoch 39/100, Loss: 1.172838409753044\n",
      "Epoch 40/100, Loss: 1.1667218344596315\n",
      "Epoch 41/100, Loss: 1.129128750908549\n",
      "Epoch 42/100, Loss: 1.0409575193760479\n",
      "Epoch 43/100, Loss: 1.0974457606071546\n",
      "Epoch 44/100, Loss: 1.1249490760565921\n",
      "Epoch 45/100, Loss: 1.2528546045433\n",
      "Epoch 46/100, Loss: 1.0717555084809898\n",
      "Epoch 47/100, Loss: 1.1827132558974274\n",
      "Epoch 48/100, Loss: 1.156871720502812\n",
      "Epoch 49/100, Loss: 1.091255611529168\n",
      "Epoch 50/100, Loss: 1.1250120474278478\n",
      "Epoch 51/100, Loss: 1.1430186552908597\n",
      "Epoch 52/100, Loss: 1.0519846720109272\n",
      "Epoch 53/100, Loss: 1.1793587192185118\n",
      "Epoch 54/100, Loss: 1.0406843852584975\n",
      "Epoch 55/100, Loss: 0.9982807634687572\n",
      "Epoch 56/100, Loss: 1.0544336429940513\n",
      "Epoch 57/100, Loss: 0.9665870222266455\n",
      "Epoch 58/100, Loss: 1.1208217902148792\n",
      "Epoch 59/100, Loss: 1.031501221361513\n",
      "Epoch 60/100, Loss: 1.0862118418054487\n",
      "Epoch 61/100, Loss: 1.1239186974950919\n",
      "Epoch 62/100, Loss: 1.0656666850114456\n",
      "Epoch 63/100, Loss: 0.886950752298007\n",
      "Epoch 64/100, Loss: 0.97608135934293\n",
      "Epoch 65/100, Loss: 1.0223746231115105\n",
      "Epoch 66/100, Loss: 1.039514345891075\n",
      "Epoch 67/100, Loss: 1.047602692485357\n",
      "Epoch 68/100, Loss: 0.9744895445712557\n",
      "Epoch 69/100, Loss: 0.969615171899016\n",
      "Epoch 70/100, Loss: 1.1023639390844076\n",
      "Epoch 71/100, Loss: 1.0009446032711962\n",
      "Epoch 72/100, Loss: 1.008590166634335\n",
      "Epoch 73/100, Loss: 0.9248846430844178\n",
      "Epoch 74/100, Loss: 1.0450352562403382\n",
      "Epoch 75/100, Loss: 0.9459164303323284\n",
      "Epoch 76/100, Loss: 0.9962630073802444\n",
      "Epoch 77/100, Loss: 1.0497779028284582\n",
      "Epoch 78/100, Loss: 1.0420029299224123\n",
      "Epoch 79/100, Loss: 0.9890811251556412\n",
      "Epoch 80/100, Loss: 0.9609454519704588\n",
      "Epoch 81/100, Loss: 0.8568460259051323\n",
      "Epoch 82/100, Loss: 0.9550540039973824\n",
      "Epoch 83/100, Loss: 0.846867672134502\n",
      "Epoch 84/100, Loss: 0.9366719423605743\n",
      "Epoch 85/100, Loss: 0.9545548450868656\n",
      "Epoch 86/100, Loss: 0.8969538558197068\n",
      "Epoch 87/100, Loss: 0.9085400980629728\n",
      "Epoch 88/100, Loss: 0.952867928844796\n",
      "Epoch 89/100, Loss: 0.8806865919404772\n",
      "Epoch 90/100, Loss: 0.9427360950923808\n",
      "Epoch 91/100, Loss: 0.9259898489953969\n",
      "Epoch 92/100, Loss: 0.9069398560535864\n",
      "Epoch 93/100, Loss: 0.961948550193469\n",
      "Epoch 94/100, Loss: 0.9821767713790277\n",
      "Epoch 95/100, Loss: 1.022356421078829\n",
      "Epoch 96/100, Loss: 0.9223144713618082\n",
      "Epoch 97/100, Loss: 0.8854073895821412\n",
      "Epoch 98/100, Loss: 0.878305154958897\n",
      "Epoch 99/100, Loss: 1.0646326458929731\n",
      "Epoch 100/100, Loss: 0.9529059156510908\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 71.83%'\n",
      "Epoch 1/150, Loss: 2.2079831531046517\n",
      "Epoch 2/150, Loss: 2.127906290059203\n",
      "Epoch 3/150, Loss: 2.067930546828718\n",
      "Epoch 4/150, Loss: 2.035915659573744\n",
      "Epoch 5/150, Loss: 1.9386088878974612\n",
      "Epoch 6/150, Loss: 1.878469890916265\n",
      "Epoch 7/150, Loss: 1.8380928750559733\n",
      "Epoch 8/150, Loss: 1.851609403102803\n",
      "Epoch 9/150, Loss: 1.7447201607439968\n",
      "Epoch 10/150, Loss: 1.7137234641261618\n",
      "Epoch 11/150, Loss: 1.6690451854267985\n",
      "Epoch 12/150, Loss: 1.671800615727789\n",
      "Epoch 13/150, Loss: 1.608171563692577\n",
      "Epoch 14/150, Loss: 1.5579352049693695\n",
      "Epoch 15/150, Loss: 1.5645037012108831\n",
      "Epoch 16/150, Loss: 1.4393516598868223\n",
      "Epoch 17/150, Loss: 1.5006281013279072\n",
      "Epoch 18/150, Loss: 1.4743544553547712\n",
      "Epoch 19/150, Loss: 1.480065320666331\n",
      "Epoch 20/150, Loss: 1.4058387201805058\n",
      "Epoch 21/150, Loss: 1.453035733515686\n",
      "Epoch 22/150, Loss: 1.3713406606172476\n",
      "Epoch 23/150, Loss: 1.441649899228199\n",
      "Epoch 24/150, Loss: 1.3682239434966676\n",
      "Epoch 25/150, Loss: 1.443018573841106\n",
      "Epoch 26/150, Loss: 1.4121520708489632\n",
      "Epoch 27/150, Loss: 1.2812542293557496\n",
      "Epoch 28/150, Loss: 1.3373257790496618\n",
      "Epoch 29/150, Loss: 1.2789434381796385\n",
      "Epoch 30/150, Loss: 1.3218432453763793\n",
      "Epoch 31/150, Loss: 1.107929476302085\n",
      "Epoch 32/150, Loss: 1.1447042657768083\n",
      "Epoch 33/150, Loss: 1.1859883192163483\n",
      "Epoch 34/150, Loss: 1.1813141226840056\n",
      "Epoch 35/150, Loss: 1.1769021487426734\n",
      "Epoch 36/150, Loss: 1.1316362530921371\n",
      "Epoch 37/150, Loss: 1.2521051061476645\n",
      "Epoch 38/150, Loss: 1.179367889591747\n",
      "Epoch 39/150, Loss: 1.069171302108125\n",
      "Epoch 40/150, Loss: 1.121656562109224\n",
      "Epoch 41/150, Loss: 1.206487100793165\n",
      "Epoch 42/150, Loss: 1.2254154835565003\n",
      "Epoch 43/150, Loss: 1.1634795847260129\n",
      "Epoch 44/150, Loss: 1.2119205933657868\n",
      "Epoch 45/150, Loss: 1.220319209120701\n",
      "Epoch 46/150, Loss: 1.213026416115253\n",
      "Epoch 47/150, Loss: 1.0983602516050783\n",
      "Epoch 48/150, Loss: 1.1806853478522945\n",
      "Epoch 49/150, Loss: 1.0251608224776116\n",
      "Epoch 50/150, Loss: 1.046304881698777\n",
      "Epoch 51/150, Loss: 1.0399726031146237\n",
      "Epoch 52/150, Loss: 1.0351321238481321\n",
      "Epoch 53/150, Loss: 1.1757368542738822\n",
      "Epoch 54/150, Loss: 1.1035547915070159\n",
      "Epoch 55/150, Loss: 1.0057864785303863\n",
      "Epoch 56/150, Loss: 1.056790036769043\n",
      "Epoch 57/150, Loss: 1.040053400506766\n",
      "Epoch 58/150, Loss: 1.0830566747932204\n",
      "Epoch 59/150, Loss: 0.947685721168222\n",
      "Epoch 60/150, Loss: 1.046265373057729\n",
      "Epoch 61/150, Loss: 0.9615679545412367\n",
      "Epoch 62/150, Loss: 1.0513249638420108\n",
      "Epoch 63/150, Loss: 1.03304579331756\n",
      "Epoch 64/150, Loss: 1.089507660599289\n",
      "Epoch 65/150, Loss: 0.9678218686303097\n",
      "Epoch 66/150, Loss: 0.9512435055297247\n",
      "Epoch 67/150, Loss: 1.0093923755093084\n",
      "Epoch 68/150, Loss: 0.96735152706482\n",
      "Epoch 69/150, Loss: 0.9660606100911081\n",
      "Epoch 70/150, Loss: 1.0038564265078198\n",
      "Epoch 71/150, Loss: 1.0053268707096121\n",
      "Epoch 72/150, Loss: 1.1096964719394795\n",
      "Epoch 73/150, Loss: 1.0421511936568568\n",
      "Epoch 74/150, Loss: 1.0657408312378547\n",
      "Epoch 75/150, Loss: 0.8957403252951294\n",
      "Epoch 76/150, Loss: 0.9253202511709282\n",
      "Epoch 77/150, Loss: 0.9451028656334507\n",
      "Epoch 78/150, Loss: 0.972212772262933\n",
      "Epoch 79/150, Loss: 0.9840013490283747\n",
      "Epoch 80/150, Loss: 0.9942947463388098\n",
      "Epoch 81/150, Loss: 0.974852008986105\n",
      "Epoch 82/150, Loss: 0.9831723852276241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150, Loss: 0.9633968795422929\n",
      "Epoch 84/150, Loss: 0.9911038418717344\n",
      "Epoch 85/150, Loss: 0.8128777781384635\n",
      "Epoch 86/150, Loss: 0.8631802008553833\n",
      "Epoch 87/150, Loss: 0.9534418920574037\n",
      "Epoch 88/150, Loss: 1.0045179257077574\n",
      "Epoch 89/150, Loss: 0.9861611659972337\n",
      "Epoch 90/150, Loss: 0.8860591262327165\n",
      "Epoch 91/150, Loss: 1.0057370285540685\n",
      "Epoch 92/150, Loss: 0.9980173572610119\n",
      "Epoch 93/150, Loss: 0.8595340214309597\n",
      "Epoch 94/150, Loss: 0.9955365868697246\n",
      "Epoch 95/150, Loss: 0.9313014918371101\n",
      "Epoch 96/150, Loss: 0.845073698691864\n",
      "Epoch 97/150, Loss: 1.0635200808508853\n",
      "Epoch 98/150, Loss: 0.9013255277034543\n",
      "Epoch 99/150, Loss: 0.8799647581263813\n",
      "Epoch 100/150, Loss: 0.8996957301243808\n",
      "Epoch 101/150, Loss: 1.0052970377381052\n",
      "Epoch 102/150, Loss: 0.8912944411550306\n",
      "Epoch 103/150, Loss: 0.9782504791426138\n",
      "Epoch 104/150, Loss: 0.9117106285108626\n",
      "Epoch 105/150, Loss: 0.9171271303606197\n",
      "Epoch 106/150, Loss: 0.8960058300600799\n",
      "Epoch 107/150, Loss: 0.9039890247942609\n",
      "Epoch 108/150, Loss: 0.8159360818351143\n",
      "Epoch 109/150, Loss: 0.9662255858133028\n",
      "Epoch 110/150, Loss: 0.8777831842962625\n",
      "Epoch 111/150, Loss: 0.8571967775725968\n",
      "Epoch 112/150, Loss: 0.8553171942709535\n",
      "Epoch 113/150, Loss: 0.9047152399246292\n",
      "Epoch 114/150, Loss: 0.9120130770981264\n",
      "Epoch 115/150, Loss: 0.9417787201528988\n",
      "Epoch 116/150, Loss: 0.8368383338677344\n",
      "Epoch 117/150, Loss: 0.9595497754589329\n",
      "Epoch 118/150, Loss: 0.9691310543831763\n",
      "Epoch 119/150, Loss: 0.9003239127951866\n",
      "Epoch 120/150, Loss: 0.8468283212293382\n",
      "Epoch 121/150, Loss: 0.9238037109586685\n",
      "Epoch 122/150, Loss: 0.7379604914455734\n",
      "Epoch 123/150, Loss: 0.8661875135291384\n",
      "Epoch 124/150, Loss: 0.9343806490070184\n",
      "Epoch 125/150, Loss: 0.8617729359980443\n",
      "Epoch 126/150, Loss: 0.9269210417153753\n",
      "Epoch 127/150, Loss: 0.8830711115442191\n",
      "Epoch 128/150, Loss: 0.8134753660589693\n",
      "Epoch 129/150, Loss: 0.7714860829344576\n",
      "Epoch 130/150, Loss: 0.8806138729159687\n",
      "Epoch 131/150, Loss: 0.8603757634856586\n",
      "Epoch 132/150, Loss: 0.9001679592443788\n",
      "Epoch 133/150, Loss: 0.9326809516681507\n",
      "Epoch 134/150, Loss: 0.8338759919955219\n",
      "Epoch 135/150, Loss: 0.8943968996604291\n",
      "Epoch 136/150, Loss: 0.9457080863071619\n",
      "Epoch 137/150, Loss: 0.9391993562377041\n",
      "Epoch 138/150, Loss: 0.7300218317826096\n",
      "Epoch 139/150, Loss: 0.9027895536058539\n",
      "Epoch 140/150, Loss: 0.8873964011022237\n",
      "Epoch 141/150, Loss: 0.8119075235890206\n",
      "Epoch 142/150, Loss: 0.9295309025581779\n",
      "Epoch 143/150, Loss: 0.8407650027108761\n",
      "Epoch 144/150, Loss: 0.8644030949974019\n",
      "Epoch 145/150, Loss: 0.7894444785230471\n",
      "Epoch 146/150, Loss: 0.7553065786865065\n",
      "Epoch 147/150, Loss: 0.8148730372159115\n",
      "Epoch 148/150, Loss: 0.769552393591292\n",
      "Epoch 149/150, Loss: 0.8131948788311887\n",
      "Epoch 150/150, Loss: 0.8175715881862162\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.0001, Alpha 0.01, f'Test accuracy: 74.39%'\n",
      "Epoch 1/50, Loss: 2.059010953717701\n",
      "Epoch 2/50, Loss: 1.8446132859975393\n",
      "Epoch 3/50, Loss: 1.835479608085316\n",
      "Epoch 4/50, Loss: 1.5704740782835076\n",
      "Epoch 5/50, Loss: 1.5464676163023543\n",
      "Epoch 6/50, Loss: 1.3922601809187456\n",
      "Epoch 7/50, Loss: 1.4504649843136412\n",
      "Epoch 8/50, Loss: 1.3164642426727633\n",
      "Epoch 9/50, Loss: 1.4231415574279866\n",
      "Epoch 10/50, Loss: 1.2453577487520602\n",
      "Epoch 11/50, Loss: 1.1917177321084387\n",
      "Epoch 12/50, Loss: 1.21820318096209\n",
      "Epoch 13/50, Loss: 1.1415743379180956\n",
      "Epoch 14/50, Loss: 1.4250252264088583\n",
      "Epoch 15/50, Loss: 1.2668151345843928\n",
      "Epoch 16/50, Loss: 1.1274878592273694\n",
      "Epoch 17/50, Loss: 1.0195879954006004\n",
      "Epoch 18/50, Loss: 1.130641526468319\n",
      "Epoch 19/50, Loss: 1.1080650580286961\n",
      "Epoch 20/50, Loss: 1.3204858391848326\n",
      "Epoch 21/50, Loss: 1.1656573881583054\n",
      "Epoch 22/50, Loss: 1.2340357298469127\n",
      "Epoch 23/50, Loss: 1.003169858067649\n",
      "Epoch 24/50, Loss: 1.0290387834964028\n",
      "Epoch 25/50, Loss: 1.1298465376357774\n",
      "Epoch 26/50, Loss: 0.9610281877953224\n",
      "Epoch 27/50, Loss: 1.1925476098948966\n",
      "Epoch 28/50, Loss: 1.233677685333082\n",
      "Epoch 29/50, Loss: 1.1941201783044977\n",
      "Epoch 30/50, Loss: 1.0158231780830993\n",
      "Epoch 31/50, Loss: 1.0111915788102102\n",
      "Epoch 32/50, Loss: 1.031738903600584\n",
      "Epoch 33/50, Loss: 1.0976176026481337\n",
      "Epoch 34/50, Loss: 1.0334668927139483\n",
      "Epoch 35/50, Loss: 1.049414360255106\n",
      "Epoch 36/50, Loss: 0.9279665268139221\n",
      "Epoch 37/50, Loss: 0.9648708154887058\n",
      "Epoch 38/50, Loss: 1.2170171988371183\n",
      "Epoch 39/50, Loss: 1.020800336078345\n",
      "Epoch 40/50, Loss: 1.1500869056321419\n",
      "Epoch 41/50, Loss: 1.0445287696516556\n",
      "Epoch 42/50, Loss: 0.92558114323952\n",
      "Epoch 43/50, Loss: 1.0318346997009424\n",
      "Epoch 44/50, Loss: 0.9114684502192649\n",
      "Epoch 45/50, Loss: 1.078817647649994\n",
      "Epoch 46/50, Loss: 0.8995290594346662\n",
      "Epoch 47/50, Loss: 1.1981621267866243\n",
      "Epoch 48/50, Loss: 1.1781118219474425\n",
      "Epoch 49/50, Loss: 0.9710465848194086\n",
      "Epoch 50/50, Loss: 1.1454785636642193\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 74.72%'\n",
      "Epoch 1/100, Loss: 2.0598228307627773\n",
      "Epoch 2/100, Loss: 1.8602797345124933\n",
      "Epoch 3/100, Loss: 1.7036628174110133\n",
      "Epoch 4/100, Loss: 1.5942948089258084\n",
      "Epoch 5/100, Loss: 1.4209868914905324\n",
      "Epoch 6/100, Loss: 1.4216960490645847\n",
      "Epoch 7/100, Loss: 1.2137543327246059\n",
      "Epoch 8/100, Loss: 1.4117058060725873\n",
      "Epoch 9/100, Loss: 1.4219870175291456\n",
      "Epoch 10/100, Loss: 1.445249754527297\n",
      "Epoch 11/100, Loss: 1.2650583305533276\n",
      "Epoch 12/100, Loss: 1.143719226484523\n",
      "Epoch 13/100, Loss: 1.3917627362732896\n",
      "Epoch 14/100, Loss: 1.120617978746238\n",
      "Epoch 15/100, Loss: 1.334826279589909\n",
      "Epoch 16/100, Loss: 1.1380770227409682\n",
      "Epoch 17/100, Loss: 1.0546810479672828\n",
      "Epoch 18/100, Loss: 1.146612442529213\n",
      "Epoch 19/100, Loss: 1.2812668302742982\n",
      "Epoch 20/100, Loss: 1.2425313441691133\n",
      "Epoch 21/100, Loss: 1.03153951482743\n",
      "Epoch 22/100, Loss: 1.0724505012014283\n",
      "Epoch 23/100, Loss: 0.9441635453734697\n",
      "Epoch 24/100, Loss: 1.1388870277606684\n",
      "Epoch 25/100, Loss: 1.0293898264469121\n",
      "Epoch 26/100, Loss: 1.0898848365532927\n",
      "Epoch 27/100, Loss: 1.271871658508946\n",
      "Epoch 28/100, Loss: 1.1374728728689218\n",
      "Epoch 29/100, Loss: 1.0619050138376258\n",
      "Epoch 30/100, Loss: 1.2093440811988292\n",
      "Epoch 31/100, Loss: 1.0838981488937838\n",
      "Epoch 32/100, Loss: 1.2014244959719504\n",
      "Epoch 33/100, Loss: 1.0702798533264408\n",
      "Epoch 34/100, Loss: 0.9043139379869028\n",
      "Epoch 35/100, Loss: 0.9635839262266652\n",
      "Epoch 36/100, Loss: 0.9453350550255255\n",
      "Epoch 37/100, Loss: 1.1567429674861898\n",
      "Epoch 38/100, Loss: 1.021548678096068\n",
      "Epoch 39/100, Loss: 0.9744265191671009\n",
      "Epoch 40/100, Loss: 1.0128595872625112\n",
      "Epoch 41/100, Loss: 1.079642173729052\n",
      "Epoch 42/100, Loss: 0.971817084635649\n",
      "Epoch 43/100, Loss: 1.0338461315874552\n",
      "Epoch 44/100, Loss: 1.0513010301272887\n",
      "Epoch 45/100, Loss: 1.045068635600509\n",
      "Epoch 46/100, Loss: 1.112955691334768\n",
      "Epoch 47/100, Loss: 1.0067423717463089\n",
      "Epoch 48/100, Loss: 1.1060847208796685\n",
      "Epoch 49/100, Loss: 1.0075175705453\n",
      "Epoch 50/100, Loss: 0.9915750082971097\n",
      "Epoch 51/100, Loss: 1.1329841856129064\n",
      "Epoch 52/100, Loss: 1.0338194692171836\n",
      "Epoch 53/100, Loss: 1.2481165837969592\n",
      "Epoch 54/100, Loss: 0.8758157204913494\n",
      "Epoch 55/100, Loss: 1.1924851334501525\n",
      "Epoch 56/100, Loss: 1.0795930388722033\n",
      "Epoch 57/100, Loss: 1.0940364249866448\n",
      "Epoch 58/100, Loss: 0.9895848575644451\n",
      "Epoch 59/100, Loss: 1.2108005340824393\n",
      "Epoch 60/100, Loss: 1.0458955841358977\n",
      "Epoch 61/100, Loss: 0.8883379101444323\n",
      "Epoch 62/100, Loss: 1.1127812778971828\n",
      "Epoch 63/100, Loss: 0.919447081525751\n",
      "Epoch 64/100, Loss: 1.0797325302126795\n",
      "Epoch 65/100, Loss: 1.0605775893294864\n",
      "Epoch 66/100, Loss: 0.8953170729402378\n",
      "Epoch 67/100, Loss: 1.1343649876620312\n",
      "Epoch 68/100, Loss: 1.0756517742532887\n",
      "Epoch 69/100, Loss: 0.999710928036135\n",
      "Epoch 70/100, Loss: 1.1109072749482507\n",
      "Epoch 71/100, Loss: 1.1591794657327894\n",
      "Epoch 72/100, Loss: 1.128836413539151\n",
      "Epoch 73/100, Loss: 0.9840881745162067\n",
      "Epoch 74/100, Loss: 0.8923033738212052\n",
      "Epoch 75/100, Loss: 1.046865685069466\n",
      "Epoch 76/100, Loss: 1.0524127818436662\n",
      "Epoch 77/100, Loss: 1.2870703403444095\n",
      "Epoch 78/100, Loss: 0.9511754310813483\n",
      "Epoch 79/100, Loss: 1.1310749601229206\n",
      "Epoch 80/100, Loss: 0.9837260658144447\n",
      "Epoch 81/100, Loss: 0.885426280832784\n",
      "Epoch 82/100, Loss: 1.0558009493546496\n",
      "Epoch 83/100, Loss: 0.9214156015541476\n",
      "Epoch 84/100, Loss: 1.1346226693815455\n",
      "Epoch 85/100, Loss: 1.2136139472563867\n",
      "Epoch 86/100, Loss: 0.8939565197959007\n",
      "Epoch 87/100, Loss: 1.3528483773157332\n",
      "Epoch 88/100, Loss: 1.002918711369532\n",
      "Epoch 89/100, Loss: 0.942442121639947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.8822829376902751\n",
      "Epoch 91/100, Loss: 1.1099564265280026\n",
      "Epoch 92/100, Loss: 0.9503292022072137\n",
      "Epoch 93/100, Loss: 1.0533725940174872\n",
      "Epoch 94/100, Loss: 1.0643975324275747\n",
      "Epoch 95/100, Loss: 1.1346290249585254\n",
      "Epoch 96/100, Loss: 1.0641782239450976\n",
      "Epoch 97/100, Loss: 0.9604797324784784\n",
      "Epoch 98/100, Loss: 1.112442326205779\n",
      "Epoch 99/100, Loss: 1.0680568590759745\n",
      "Epoch 100/100, Loss: 1.12799761660406\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 77.23%'\n",
      "Epoch 1/150, Loss: 2.0754538480046785\n",
      "Epoch 2/150, Loss: 1.852003642745152\n",
      "Epoch 3/150, Loss: 1.6903008296419701\n",
      "Epoch 4/150, Loss: 1.6666357515518913\n",
      "Epoch 5/150, Loss: 1.4489311753799827\n",
      "Epoch 6/150, Loss: 1.5748413599067221\n",
      "Epoch 7/150, Loss: 1.2541388434584992\n",
      "Epoch 8/150, Loss: 1.3598143394852653\n",
      "Epoch 9/150, Loss: 1.265557024201948\n",
      "Epoch 10/150, Loss: 1.2291563174431448\n",
      "Epoch 11/150, Loss: 1.3116376367735496\n",
      "Epoch 12/150, Loss: 1.4103319294246335\n",
      "Epoch 13/150, Loss: 1.3090934126031077\n",
      "Epoch 14/150, Loss: 1.235326148655604\n",
      "Epoch 15/150, Loss: 1.2669355095994168\n",
      "Epoch 16/150, Loss: 1.174484342841494\n",
      "Epoch 17/150, Loss: 1.0631904801827075\n",
      "Epoch 18/150, Loss: 1.0516285376739567\n",
      "Epoch 19/150, Loss: 0.9596573142896049\n",
      "Epoch 20/150, Loss: 1.2172867359253967\n",
      "Epoch 21/150, Loss: 0.8604690827086867\n",
      "Epoch 22/150, Loss: 1.1455029818061215\n",
      "Epoch 23/150, Loss: 1.2227992287896436\n",
      "Epoch 24/150, Loss: 1.0919150342770918\n",
      "Epoch 25/150, Loss: 1.1197317413545316\n",
      "Epoch 26/150, Loss: 1.1373193787063858\n",
      "Epoch 27/150, Loss: 0.9831669645649906\n",
      "Epoch 28/150, Loss: 1.1479901997035378\n",
      "Epoch 29/150, Loss: 0.8002499773230903\n",
      "Epoch 30/150, Loss: 1.0032082810187073\n",
      "Epoch 31/150, Loss: 1.0272592873774737\n",
      "Epoch 32/150, Loss: 1.1562929025620305\n",
      "Epoch 33/150, Loss: 1.1182580549987144\n",
      "Epoch 34/150, Loss: 1.1885561323762652\n",
      "Epoch 35/150, Loss: 1.1583639046668592\n",
      "Epoch 36/150, Loss: 1.3566146229618778\n",
      "Epoch 37/150, Loss: 1.1329441080282465\n",
      "Epoch 38/150, Loss: 1.069637447668729\n",
      "Epoch 39/150, Loss: 1.0419427573929534\n",
      "Epoch 40/150, Loss: 1.0602930517120457\n",
      "Epoch 41/150, Loss: 1.015004895717404\n",
      "Epoch 42/150, Loss: 1.0992693158126507\n",
      "Epoch 43/150, Loss: 1.3155792374704727\n",
      "Epoch 44/150, Loss: 1.113960741072356\n",
      "Epoch 45/150, Loss: 0.9776755316708272\n",
      "Epoch 46/150, Loss: 1.2024252755678342\n",
      "Epoch 47/150, Loss: 1.116660122299814\n",
      "Epoch 48/150, Loss: 1.1402917132762769\n",
      "Epoch 49/150, Loss: 1.0166177175501456\n",
      "Epoch 50/150, Loss: 1.0787272481875299\n",
      "Epoch 51/150, Loss: 1.1764260903922132\n",
      "Epoch 52/150, Loss: 1.171403146585243\n",
      "Epoch 53/150, Loss: 0.8803207788337413\n",
      "Epoch 54/150, Loss: 0.9454956826575812\n",
      "Epoch 55/150, Loss: 1.0223133048393371\n",
      "Epoch 56/150, Loss: 0.9975136827605604\n",
      "Epoch 57/150, Loss: 1.0226764777800026\n",
      "Epoch 58/150, Loss: 1.0021110102964883\n",
      "Epoch 59/150, Loss: 1.1489625954671439\n",
      "Epoch 60/150, Loss: 1.104753871024025\n",
      "Epoch 61/150, Loss: 0.8838325977637888\n",
      "Epoch 62/150, Loss: 1.1320535529150026\n",
      "Epoch 63/150, Loss: 1.1349802879767497\n",
      "Epoch 64/150, Loss: 1.0639239676772145\n",
      "Epoch 65/150, Loss: 1.0286936976069228\n",
      "Epoch 66/150, Loss: 0.9373376033949545\n",
      "Epoch 67/150, Loss: 1.0460476863359376\n",
      "Epoch 68/150, Loss: 1.0026053143886882\n",
      "Epoch 69/150, Loss: 0.957889046313064\n",
      "Epoch 70/150, Loss: 0.9972338934609701\n",
      "Epoch 71/150, Loss: 1.2296447389142646\n",
      "Epoch 72/150, Loss: 0.9440236045023295\n",
      "Epoch 73/150, Loss: 1.1472591759905377\n",
      "Epoch 74/150, Loss: 1.1827140430166372\n",
      "Epoch 75/150, Loss: 1.0921522879592975\n",
      "Epoch 76/150, Loss: 0.8812599485107726\n",
      "Epoch 77/150, Loss: 1.1515182631171026\n",
      "Epoch 78/150, Loss: 0.9043298778856125\n",
      "Epoch 79/150, Loss: 1.0114755416173713\n",
      "Epoch 80/150, Loss: 1.1760808874280526\n",
      "Epoch 81/150, Loss: 1.1318362617216442\n",
      "Epoch 82/150, Loss: 0.9467259778657162\n",
      "Epoch 83/150, Loss: 1.0544101711373166\n",
      "Epoch 84/150, Loss: 1.1953965629623058\n",
      "Epoch 85/150, Loss: 1.0390695303949988\n",
      "Epoch 86/150, Loss: 0.9204313040939901\n",
      "Epoch 87/150, Loss: 1.010420864612929\n",
      "Epoch 88/150, Loss: 0.9120266946388942\n",
      "Epoch 89/150, Loss: 1.0421608049503759\n",
      "Epoch 90/150, Loss: 1.0270659777593285\n",
      "Epoch 91/150, Loss: 1.160850033729206\n",
      "Epoch 92/150, Loss: 1.0143485603780957\n",
      "Epoch 93/150, Loss: 1.0510311622896755\n",
      "Epoch 94/150, Loss: 1.0930388352934648\n",
      "Epoch 95/150, Loss: 1.0785343958347766\n",
      "Epoch 96/150, Loss: 0.9662577604994705\n",
      "Epoch 97/150, Loss: 0.8828352579405646\n",
      "Epoch 98/150, Loss: 1.1532395686219243\n",
      "Epoch 99/150, Loss: 0.9307113025522589\n",
      "Epoch 100/150, Loss: 0.9361523485320614\n",
      "Epoch 101/150, Loss: 0.9577428307470044\n",
      "Epoch 102/150, Loss: 1.0602512755382247\n",
      "Epoch 103/150, Loss: 0.9455383947440538\n",
      "Epoch 104/150, Loss: 0.9325268322693865\n",
      "Epoch 105/150, Loss: 1.09483274415494\n",
      "Epoch 106/150, Loss: 0.8678674167372481\n",
      "Epoch 107/150, Loss: 1.216586146050893\n",
      "Epoch 108/150, Loss: 1.0815706848866378\n",
      "Epoch 109/150, Loss: 0.9617030965544685\n",
      "Epoch 110/150, Loss: 0.9228616184375559\n",
      "Epoch 111/150, Loss: 0.9399548059374527\n",
      "Epoch 112/150, Loss: 0.9584303395761266\n",
      "Epoch 113/150, Loss: 1.2677672577287655\n",
      "Epoch 114/150, Loss: 1.1001142890071913\n",
      "Epoch 115/150, Loss: 0.8586414791792254\n",
      "Epoch 116/150, Loss: 0.9754831576322945\n",
      "Epoch 117/150, Loss: 1.1164856654739905\n",
      "Epoch 118/150, Loss: 1.014307595462106\n",
      "Epoch 119/150, Loss: 0.9889634469293517\n",
      "Epoch 120/150, Loss: 1.0039027316830007\n",
      "Epoch 121/150, Loss: 1.0297752416100525\n",
      "Epoch 122/150, Loss: 0.9978839773360605\n",
      "Epoch 123/150, Loss: 1.0380909046924764\n",
      "Epoch 124/150, Loss: 0.8905942375008702\n",
      "Epoch 125/150, Loss: 1.0400740633807382\n",
      "Epoch 126/150, Loss: 0.9226360009605951\n",
      "Epoch 127/150, Loss: 1.277888845948716\n",
      "Epoch 128/150, Loss: 0.9323158272221541\n",
      "Epoch 129/150, Loss: 0.9255844795441642\n",
      "Epoch 130/150, Loss: 0.8811427109263686\n",
      "Epoch 131/150, Loss: 1.1214473605661568\n",
      "Epoch 132/150, Loss: 1.1308918489936124\n",
      "Epoch 133/150, Loss: 0.9460888171745927\n",
      "Epoch 134/150, Loss: 1.0367509635222132\n",
      "Epoch 135/150, Loss: 1.0608273201489982\n",
      "Epoch 136/150, Loss: 1.1632942825158885\n",
      "Epoch 137/150, Loss: 0.997062869140932\n",
      "Epoch 138/150, Loss: 1.0559113168378018\n",
      "Epoch 139/150, Loss: 0.9011694888332972\n",
      "Epoch 140/150, Loss: 1.0118865857379973\n",
      "Epoch 141/150, Loss: 1.0668060848522758\n",
      "Epoch 142/150, Loss: 1.034451372281892\n",
      "Epoch 143/150, Loss: 0.9903264545100474\n",
      "Epoch 144/150, Loss: 1.113056932041879\n",
      "Epoch 145/150, Loss: 1.1610900954099421\n",
      "Epoch 146/150, Loss: 1.0108778225537556\n",
      "Epoch 147/150, Loss: 0.9858447622764908\n",
      "Epoch 148/150, Loss: 0.892074441588051\n",
      "Epoch 149/150, Loss: 1.1846764005213193\n",
      "Epoch 150/150, Loss: 1.1800035255539032\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 78.01%'\n",
      "Epoch 1/50, Loss: 2.198780601888907\n",
      "Epoch 2/50, Loss: 2.0079611157384645\n",
      "Epoch 3/50, Loss: 1.9534445683324442\n",
      "Epoch 4/50, Loss: 1.8290017088114514\n",
      "Epoch 5/50, Loss: 1.7918879967486534\n",
      "Epoch 6/50, Loss: 1.757908172002191\n",
      "Epoch 7/50, Loss: 1.6479828502732452\n",
      "Epoch 8/50, Loss: 1.5852975568599663\n",
      "Epoch 9/50, Loss: 1.4693354639499034\n",
      "Epoch 10/50, Loss: 1.6042492995063065\n",
      "Epoch 11/50, Loss: 1.496251644012148\n",
      "Epoch 12/50, Loss: 1.533172691046066\n",
      "Epoch 13/50, Loss: 1.467457908883838\n",
      "Epoch 14/50, Loss: 1.4131110213509057\n",
      "Epoch 15/50, Loss: 1.4772204663640869\n",
      "Epoch 16/50, Loss: 1.2599865284763796\n",
      "Epoch 17/50, Loss: 1.2159290561220162\n",
      "Epoch 18/50, Loss: 1.3696108367501196\n",
      "Epoch 19/50, Loss: 1.3554920161378359\n",
      "Epoch 20/50, Loss: 1.3676184623629828\n",
      "Epoch 21/50, Loss: 1.3822105720113873\n",
      "Epoch 22/50, Loss: 1.2287957718147022\n",
      "Epoch 23/50, Loss: 1.1972552524873765\n",
      "Epoch 24/50, Loss: 1.320466619058662\n",
      "Epoch 25/50, Loss: 1.2188476763210436\n",
      "Epoch 26/50, Loss: 1.2284070022743543\n",
      "Epoch 27/50, Loss: 1.3858564330206402\n",
      "Epoch 28/50, Loss: 1.2024220522481444\n",
      "Epoch 29/50, Loss: 1.2211856972986026\n",
      "Epoch 30/50, Loss: 1.2200962398234458\n",
      "Epoch 31/50, Loss: 1.1185560680446345\n",
      "Epoch 32/50, Loss: 1.1759360402511463\n",
      "Epoch 33/50, Loss: 1.2197903549832039\n",
      "Epoch 34/50, Loss: 1.0782922712813163\n",
      "Epoch 35/50, Loss: 1.1678295701886734\n",
      "Epoch 36/50, Loss: 1.1647023685066549\n",
      "Epoch 37/50, Loss: 1.1468557859977953\n",
      "Epoch 38/50, Loss: 1.2812373540352062\n",
      "Epoch 39/50, Loss: 1.1988589389221131\n",
      "Epoch 40/50, Loss: 1.1386849024605659\n",
      "Epoch 41/50, Loss: 1.0748741191934215\n",
      "Epoch 42/50, Loss: 1.1055095419956351\n",
      "Epoch 43/50, Loss: 1.1348050538700118\n",
      "Epoch 44/50, Loss: 1.0672565071530542\n",
      "Epoch 45/50, Loss: 1.2026374773199604\n",
      "Epoch 46/50, Loss: 1.0610556949772991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 1.1377748167804096\n",
      "Epoch 48/50, Loss: 1.044359431276454\n",
      "Epoch 49/50, Loss: 1.25579289921966\n",
      "Epoch 50/50, Loss: 1.1274876622897145\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 71.03%'\n",
      "Epoch 1/100, Loss: 2.16415178047911\n",
      "Epoch 2/100, Loss: 2.0702410208336017\n",
      "Epoch 3/100, Loss: 1.9421583526765371\n",
      "Epoch 4/100, Loss: 1.8459633890906724\n",
      "Epoch 5/100, Loss: 1.7468697231074213\n",
      "Epoch 6/100, Loss: 1.7212325609312207\n",
      "Epoch 7/100, Loss: 1.6428978325201602\n",
      "Epoch 8/100, Loss: 1.5396816174662467\n",
      "Epoch 9/100, Loss: 1.5518152758236645\n",
      "Epoch 10/100, Loss: 1.5556807288002374\n",
      "Epoch 11/100, Loss: 1.509142881817773\n",
      "Epoch 12/100, Loss: 1.4332874754024854\n",
      "Epoch 13/100, Loss: 1.4157051470798172\n",
      "Epoch 14/100, Loss: 1.4126898843355529\n",
      "Epoch 15/100, Loss: 1.3048222426106446\n",
      "Epoch 16/100, Loss: 1.417763178078032\n",
      "Epoch 17/100, Loss: 1.4285900908519982\n",
      "Epoch 18/100, Loss: 1.2740687463160172\n",
      "Epoch 19/100, Loss: 1.4590025335470687\n",
      "Epoch 20/100, Loss: 1.3187599299578703\n",
      "Epoch 21/100, Loss: 1.3142668614616846\n",
      "Epoch 22/100, Loss: 1.2642403886716989\n",
      "Epoch 23/100, Loss: 1.3268550968365236\n",
      "Epoch 24/100, Loss: 1.1495688594017202\n",
      "Epoch 25/100, Loss: 1.3233610278614676\n",
      "Epoch 26/100, Loss: 1.2722578339591286\n",
      "Epoch 27/100, Loss: 1.3461396327364428\n",
      "Epoch 28/100, Loss: 1.1463901788176318\n",
      "Epoch 29/100, Loss: 1.1136624644195108\n",
      "Epoch 30/100, Loss: 1.1873890300973922\n",
      "Epoch 31/100, Loss: 1.118420851029678\n",
      "Epoch 32/100, Loss: 1.1954224630739303\n",
      "Epoch 33/100, Loss: 1.1702564559466746\n",
      "Epoch 34/100, Loss: 1.1966865833442102\n",
      "Epoch 35/100, Loss: 1.115587717888897\n",
      "Epoch 36/100, Loss: 1.139830133354875\n",
      "Epoch 37/100, Loss: 1.084932399376396\n",
      "Epoch 38/100, Loss: 1.0059780514045444\n",
      "Epoch 39/100, Loss: 1.1555322439259759\n",
      "Epoch 40/100, Loss: 1.2907294160211626\n",
      "Epoch 41/100, Loss: 1.0780717896413035\n",
      "Epoch 42/100, Loss: 1.2128721109347669\n",
      "Epoch 43/100, Loss: 1.1527477371382626\n",
      "Epoch 44/100, Loss: 1.1846126962371124\n",
      "Epoch 45/100, Loss: 1.1585591007949787\n",
      "Epoch 46/100, Loss: 1.1868491445473057\n",
      "Epoch 47/100, Loss: 1.1574746126034299\n",
      "Epoch 48/100, Loss: 1.0159482792399581\n",
      "Epoch 49/100, Loss: 1.0322996917571907\n",
      "Epoch 50/100, Loss: 1.1524571624076785\n",
      "Epoch 51/100, Loss: 1.0574084826204255\n",
      "Epoch 52/100, Loss: 1.0098674609274814\n",
      "Epoch 53/100, Loss: 1.0267528257837948\n",
      "Epoch 54/100, Loss: 1.0999880499913284\n",
      "Epoch 55/100, Loss: 1.2360392158004212\n",
      "Epoch 56/100, Loss: 1.087805904207297\n",
      "Epoch 57/100, Loss: 1.1414287810514796\n",
      "Epoch 58/100, Loss: 1.1646555939193106\n",
      "Epoch 59/100, Loss: 1.1986854890941225\n",
      "Epoch 60/100, Loss: 1.1484257401149291\n",
      "Epoch 61/100, Loss: 0.9921464498132108\n",
      "Epoch 62/100, Loss: 1.0181232335987165\n",
      "Epoch 63/100, Loss: 1.2103097963361837\n",
      "Epoch 64/100, Loss: 1.1290439258366762\n",
      "Epoch 65/100, Loss: 1.2790417470836202\n",
      "Epoch 66/100, Loss: 1.131723687991419\n",
      "Epoch 67/100, Loss: 1.0845295874206882\n",
      "Epoch 68/100, Loss: 1.2742889460319387\n",
      "Epoch 69/100, Loss: 1.1088162597086448\n",
      "Epoch 70/100, Loss: 1.1549928723871776\n",
      "Epoch 71/100, Loss: 1.085755479262153\n",
      "Epoch 72/100, Loss: 1.204661309784989\n",
      "Epoch 73/100, Loss: 1.0560981219496826\n",
      "Epoch 74/100, Loss: 0.99013398707108\n",
      "Epoch 75/100, Loss: 1.16719753757379\n",
      "Epoch 76/100, Loss: 0.9931096608836794\n",
      "Epoch 77/100, Loss: 1.0483629049918401\n",
      "Epoch 78/100, Loss: 1.0307980467157\n",
      "Epoch 79/100, Loss: 1.216494394845728\n",
      "Epoch 80/100, Loss: 1.0681380074547353\n",
      "Epoch 81/100, Loss: 1.016739000881675\n",
      "Epoch 82/100, Loss: 1.0662259475082325\n",
      "Epoch 83/100, Loss: 1.0510997424062998\n",
      "Epoch 84/100, Loss: 0.9695341732638556\n",
      "Epoch 85/100, Loss: 1.1075093002429608\n",
      "Epoch 86/100, Loss: 1.0232331561136876\n",
      "Epoch 87/100, Loss: 1.1213072332283704\n",
      "Epoch 88/100, Loss: 1.2529894761884375\n",
      "Epoch 89/100, Loss: 0.9645316798354453\n",
      "Epoch 90/100, Loss: 1.1192719880668003\n",
      "Epoch 91/100, Loss: 1.196467972172937\n",
      "Epoch 92/100, Loss: 1.0047147427610001\n",
      "Epoch 93/100, Loss: 0.9950163210749194\n",
      "Epoch 94/100, Loss: 0.9973895214474522\n",
      "Epoch 95/100, Loss: 1.1438728754954166\n",
      "Epoch 96/100, Loss: 1.0853082754220136\n",
      "Epoch 97/100, Loss: 1.0135241410344364\n",
      "Epoch 98/100, Loss: 1.1360775485715746\n",
      "Epoch 99/100, Loss: 0.9640928847809218\n",
      "Epoch 100/100, Loss: 1.0652067404346819\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 74.83%'\n",
      "Epoch 1/150, Loss: 2.157588543363004\n",
      "Epoch 2/150, Loss: 2.111096407459344\n",
      "Epoch 3/150, Loss: 1.927455037066914\n",
      "Epoch 4/150, Loss: 1.9178540393876409\n",
      "Epoch 5/150, Loss: 1.7387622584678983\n",
      "Epoch 6/150, Loss: 1.7402004788058048\n",
      "Epoch 7/150, Loss: 1.6855955791025228\n",
      "Epoch 8/150, Loss: 1.603103970698124\n",
      "Epoch 9/150, Loss: 1.6070441755060028\n",
      "Epoch 10/150, Loss: 1.5776806722189676\n",
      "Epoch 11/150, Loss: 1.4043169210519655\n",
      "Epoch 12/150, Loss: 1.3788986650355628\n",
      "Epoch 13/150, Loss: 1.479312057858172\n",
      "Epoch 14/150, Loss: 1.3666036555997763\n",
      "Epoch 15/150, Loss: 1.4195822513240723\n",
      "Epoch 16/150, Loss: 1.3801698720002866\n",
      "Epoch 17/150, Loss: 1.317389488685105\n",
      "Epoch 18/150, Loss: 1.340273705540252\n",
      "Epoch 19/150, Loss: 1.2744032178647184\n",
      "Epoch 20/150, Loss: 1.349817552542176\n",
      "Epoch 21/150, Loss: 1.3688253555472598\n",
      "Epoch 22/150, Loss: 1.3311778218197419\n",
      "Epoch 23/150, Loss: 1.1231189951305607\n",
      "Epoch 24/150, Loss: 1.4114318816239222\n",
      "Epoch 25/150, Loss: 1.2188838040314263\n",
      "Epoch 26/150, Loss: 1.2246381821365218\n",
      "Epoch 27/150, Loss: 1.2439556557037952\n",
      "Epoch 28/150, Loss: 1.3214611028805334\n",
      "Epoch 29/150, Loss: 1.237052150573659\n",
      "Epoch 30/150, Loss: 1.2037157683416941\n",
      "Epoch 31/150, Loss: 1.2295044637643056\n",
      "Epoch 32/150, Loss: 1.1169867599547019\n",
      "Epoch 33/150, Loss: 1.220204691110623\n",
      "Epoch 34/150, Loss: 1.276485337955937\n",
      "Epoch 35/150, Loss: 1.3380582055500556\n",
      "Epoch 36/150, Loss: 1.2054896236778732\n",
      "Epoch 37/150, Loss: 1.1326741825057676\n",
      "Epoch 38/150, Loss: 0.9906889643755492\n",
      "Epoch 39/150, Loss: 1.1720349354731656\n",
      "Epoch 40/150, Loss: 1.1019283846107633\n",
      "Epoch 41/150, Loss: 1.1986852659007987\n",
      "Epoch 42/150, Loss: 1.1106881662663861\n",
      "Epoch 43/150, Loss: 1.208484531873447\n",
      "Epoch 44/150, Loss: 1.0682333159256256\n",
      "Epoch 45/150, Loss: 1.116654486749752\n",
      "Epoch 46/150, Loss: 1.0330737197618394\n",
      "Epoch 47/150, Loss: 1.2185090765952997\n",
      "Epoch 48/150, Loss: 1.140969502637481\n",
      "Epoch 49/150, Loss: 1.150832454248702\n",
      "Epoch 50/150, Loss: 1.0670886249873455\n",
      "Epoch 51/150, Loss: 1.1663730478737881\n",
      "Epoch 52/150, Loss: 1.203100641016057\n",
      "Epoch 53/150, Loss: 1.159571852242411\n",
      "Epoch 54/150, Loss: 1.2561435493697082\n",
      "Epoch 55/150, Loss: 1.1846604231452238\n",
      "Epoch 56/150, Loss: 1.0585706946284583\n",
      "Epoch 57/150, Loss: 1.238389294524597\n",
      "Epoch 58/150, Loss: 1.0675904545432466\n",
      "Epoch 59/150, Loss: 1.134614995655338\n",
      "Epoch 60/150, Loss: 1.1288533118233326\n",
      "Epoch 61/150, Loss: 0.9823063407637176\n",
      "Epoch 62/150, Loss: 1.2065922847304016\n",
      "Epoch 63/150, Loss: 1.024366158027862\n",
      "Epoch 64/150, Loss: 0.9403617066797078\n",
      "Epoch 65/150, Loss: 1.1500076562757942\n",
      "Epoch 66/150, Loss: 0.9760950331264568\n",
      "Epoch 67/150, Loss: 1.0875461217253035\n",
      "Epoch 68/150, Loss: 1.040800248054241\n",
      "Epoch 69/150, Loss: 1.2367083718885752\n",
      "Epoch 70/150, Loss: 1.06717452577836\n",
      "Epoch 71/150, Loss: 1.2505777329013597\n",
      "Epoch 72/150, Loss: 1.0905001216207024\n",
      "Epoch 73/150, Loss: 1.1604346036952062\n",
      "Epoch 74/150, Loss: 1.0162288724000959\n",
      "Epoch 75/150, Loss: 1.2215500532501888\n",
      "Epoch 76/150, Loss: 1.0411931213495804\n",
      "Epoch 77/150, Loss: 1.0657893611847191\n",
      "Epoch 78/150, Loss: 0.9429762511368347\n",
      "Epoch 79/150, Loss: 0.982606027690509\n",
      "Epoch 80/150, Loss: 1.0454368974436186\n",
      "Epoch 81/150, Loss: 1.010775133969344\n",
      "Epoch 82/150, Loss: 1.0818606812076457\n",
      "Epoch 83/150, Loss: 1.0056782952713625\n",
      "Epoch 84/150, Loss: 1.062137978487319\n",
      "Epoch 85/150, Loss: 1.043345684765257\n",
      "Epoch 86/150, Loss: 1.027261239318922\n",
      "Epoch 87/150, Loss: 0.9964975650446023\n",
      "Epoch 88/150, Loss: 1.0697769142876716\n",
      "Epoch 89/150, Loss: 1.0449629465215196\n",
      "Epoch 90/150, Loss: 1.1386196785820872\n",
      "Epoch 91/150, Loss: 1.0085408741212283\n",
      "Epoch 92/150, Loss: 1.145650114815491\n",
      "Epoch 93/150, Loss: 0.9307947121836115\n",
      "Epoch 94/150, Loss: 1.1331821790164707\n",
      "Epoch 95/150, Loss: 0.973594081540072\n",
      "Epoch 96/150, Loss: 1.0516349546171115\n",
      "Epoch 97/150, Loss: 0.9702302637715402\n",
      "Epoch 98/150, Loss: 1.200929781738322\n",
      "Epoch 99/150, Loss: 1.0715404773343415\n",
      "Epoch 100/150, Loss: 1.0896619539068082\n",
      "Epoch 101/150, Loss: 1.1710486973846386\n",
      "Epoch 102/150, Loss: 1.04790925899797\n",
      "Epoch 103/150, Loss: 1.0415287815538705\n",
      "Epoch 104/150, Loss: 1.1038111042662901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150, Loss: 1.1856161559585747\n",
      "Epoch 106/150, Loss: 1.0444719348549352\n",
      "Epoch 107/150, Loss: 1.0879143116591232\n",
      "Epoch 108/150, Loss: 0.9169532836821548\n",
      "Epoch 109/150, Loss: 1.0040748306170018\n",
      "Epoch 110/150, Loss: 1.1168709735923923\n",
      "Epoch 111/150, Loss: 1.0368802166731468\n",
      "Epoch 112/150, Loss: 1.0951709665640257\n",
      "Epoch 113/150, Loss: 1.06874613206972\n",
      "Epoch 114/150, Loss: 1.0081903962647485\n",
      "Epoch 115/150, Loss: 1.017432832857531\n",
      "Epoch 116/150, Loss: 1.175252384774922\n",
      "Epoch 117/150, Loss: 1.1587636546333901\n",
      "Epoch 118/150, Loss: 1.0595223765971213\n",
      "Epoch 119/150, Loss: 1.0437061654003192\n",
      "Epoch 120/150, Loss: 1.0007070800852627\n",
      "Epoch 121/150, Loss: 1.057077397271665\n",
      "Epoch 122/150, Loss: 1.211347097949395\n",
      "Epoch 123/150, Loss: 0.9568036016458783\n",
      "Epoch 124/150, Loss: 0.9863934099790985\n",
      "Epoch 125/150, Loss: 1.0173748236625284\n",
      "Epoch 126/150, Loss: 0.9213252532174695\n",
      "Epoch 127/150, Loss: 1.0048895608580815\n",
      "Epoch 128/150, Loss: 1.1793484203990754\n",
      "Epoch 129/150, Loss: 0.9098458335581372\n",
      "Epoch 130/150, Loss: 1.0728025659646727\n",
      "Epoch 131/150, Loss: 0.9878267073544272\n",
      "Epoch 132/150, Loss: 1.1087236113802834\n",
      "Epoch 133/150, Loss: 1.0834023485401374\n",
      "Epoch 134/150, Loss: 1.0456989107276349\n",
      "Epoch 135/150, Loss: 1.1084891564831958\n",
      "Epoch 136/150, Loss: 1.1798058876826552\n",
      "Epoch 137/150, Loss: 1.1272610318795264\n",
      "Epoch 138/150, Loss: 1.0953572604172592\n",
      "Epoch 139/150, Loss: 0.8725862809929574\n",
      "Epoch 140/150, Loss: 0.9140653434125734\n",
      "Epoch 141/150, Loss: 1.0727787306267953\n",
      "Epoch 142/150, Loss: 1.1246482445761896\n",
      "Epoch 143/150, Loss: 1.0309138498189991\n",
      "Epoch 144/150, Loss: 1.079629605894805\n",
      "Epoch 145/150, Loss: 1.1142987474873067\n",
      "Epoch 146/150, Loss: 1.2091324152526373\n",
      "Epoch 147/150, Loss: 1.0577615096736714\n",
      "Epoch 148/150, Loss: 1.1383718041637159\n",
      "Epoch 149/150, Loss: 1.0460952537793602\n",
      "Epoch 150/150, Loss: 1.1383588650861574\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 76.49%'\n",
      "Epoch 1/50, Loss: 2.238428229066268\n",
      "Epoch 2/50, Loss: 2.180490831835187\n",
      "Epoch 3/50, Loss: 2.101292000397303\n",
      "Epoch 4/50, Loss: 2.05027694176628\n",
      "Epoch 5/50, Loss: 1.9863470291325243\n",
      "Epoch 6/50, Loss: 1.9478737397250339\n",
      "Epoch 7/50, Loss: 1.9251508830697928\n",
      "Epoch 8/50, Loss: 1.847649346056112\n",
      "Epoch 9/50, Loss: 1.8336687467172086\n",
      "Epoch 10/50, Loss: 1.7631867208844374\n",
      "Epoch 11/50, Loss: 1.6731358677421915\n",
      "Epoch 12/50, Loss: 1.6833134499870432\n",
      "Epoch 13/50, Loss: 1.6735899102790175\n",
      "Epoch 14/50, Loss: 1.6826705461619327\n",
      "Epoch 15/50, Loss: 1.6397238294519703\n",
      "Epoch 16/50, Loss: 1.5257341843328214\n",
      "Epoch 17/50, Loss: 1.6689396455522456\n",
      "Epoch 18/50, Loss: 1.559273160870985\n",
      "Epoch 19/50, Loss: 1.5051624792544482\n",
      "Epoch 20/50, Loss: 1.4265327876729472\n",
      "Epoch 21/50, Loss: 1.5368830839629706\n",
      "Epoch 22/50, Loss: 1.4579348093070204\n",
      "Epoch 23/50, Loss: 1.4557300606762524\n",
      "Epoch 24/50, Loss: 1.4417119996315102\n",
      "Epoch 25/50, Loss: 1.4785538032378827\n",
      "Epoch 26/50, Loss: 1.4424666582624506\n",
      "Epoch 27/50, Loss: 1.3693044672749506\n",
      "Epoch 28/50, Loss: 1.403697899052484\n",
      "Epoch 29/50, Loss: 1.3817259616786015\n",
      "Epoch 30/50, Loss: 1.4119903469340014\n",
      "Epoch 31/50, Loss: 1.3039351395249752\n",
      "Epoch 32/50, Loss: 1.4156686708323023\n",
      "Epoch 33/50, Loss: 1.3109656179487108\n",
      "Epoch 34/50, Loss: 1.245060525271052\n",
      "Epoch 35/50, Loss: 1.333035258174389\n",
      "Epoch 36/50, Loss: 1.3405686217325856\n",
      "Epoch 37/50, Loss: 1.2648916373955077\n",
      "Epoch 38/50, Loss: 1.3250260815461259\n",
      "Epoch 39/50, Loss: 1.2789591391582986\n",
      "Epoch 40/50, Loss: 1.376152745951709\n",
      "Epoch 41/50, Loss: 1.2956731809627642\n",
      "Epoch 42/50, Loss: 1.2247121982225915\n",
      "Epoch 43/50, Loss: 1.251658872884442\n",
      "Epoch 44/50, Loss: 1.367213625894178\n",
      "Epoch 45/50, Loss: 1.1689255769277151\n",
      "Epoch 46/50, Loss: 1.2399385766531776\n",
      "Epoch 47/50, Loss: 1.2707376386476585\n",
      "Epoch 48/50, Loss: 1.3059245673309647\n",
      "Epoch 49/50, Loss: 1.2639075927434462\n",
      "Epoch 50/50, Loss: 1.1709583475787562\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 67.77%'\n",
      "Epoch 1/100, Loss: 2.2879967885424586\n",
      "Epoch 2/100, Loss: 2.1833097786800053\n",
      "Epoch 3/100, Loss: 2.127714631242409\n",
      "Epoch 4/100, Loss: 2.0736099293311545\n",
      "Epoch 5/100, Loss: 1.993643492601208\n",
      "Epoch 6/100, Loss: 1.9287360116021435\n",
      "Epoch 7/100, Loss: 1.9099022512687704\n",
      "Epoch 8/100, Loss: 1.8384436464317901\n",
      "Epoch 9/100, Loss: 1.867112108102636\n",
      "Epoch 10/100, Loss: 1.7504155982880247\n",
      "Epoch 11/100, Loss: 1.7279789585516196\n",
      "Epoch 12/100, Loss: 1.7229223120885635\n",
      "Epoch 13/100, Loss: 1.6884866995472356\n",
      "Epoch 14/100, Loss: 1.6683716650802005\n",
      "Epoch 15/100, Loss: 1.6840468784782296\n",
      "Epoch 16/100, Loss: 1.5925729292766158\n",
      "Epoch 17/100, Loss: 1.5932368609541032\n",
      "Epoch 18/100, Loss: 1.6045196474236458\n",
      "Epoch 19/100, Loss: 1.6313278860294644\n",
      "Epoch 20/100, Loss: 1.5882487273609156\n",
      "Epoch 21/100, Loss: 1.523917562622378\n",
      "Epoch 22/100, Loss: 1.4334188661297866\n",
      "Epoch 23/100, Loss: 1.5426040252646116\n",
      "Epoch 24/100, Loss: 1.3826928860794876\n",
      "Epoch 25/100, Loss: 1.3894638587525345\n",
      "Epoch 26/100, Loss: 1.462354866859723\n",
      "Epoch 27/100, Loss: 1.4997709817085396\n",
      "Epoch 28/100, Loss: 1.3756600322133927\n",
      "Epoch 29/100, Loss: 1.4141668005886288\n",
      "Epoch 30/100, Loss: 1.3516734785460254\n",
      "Epoch 31/100, Loss: 1.3559218935656514\n",
      "Epoch 32/100, Loss: 1.3813228468975332\n",
      "Epoch 33/100, Loss: 1.3550571890245462\n",
      "Epoch 34/100, Loss: 1.3386724854682337\n",
      "Epoch 35/100, Loss: 1.3291527992026504\n",
      "Epoch 36/100, Loss: 1.3762224619396854\n",
      "Epoch 37/100, Loss: 1.37216766851425\n",
      "Epoch 38/100, Loss: 1.3063974033155155\n",
      "Epoch 39/100, Loss: 1.2225976444255702\n",
      "Epoch 40/100, Loss: 1.2680424424358052\n",
      "Epoch 41/100, Loss: 1.298236675902992\n",
      "Epoch 42/100, Loss: 1.2114857520161748\n",
      "Epoch 43/100, Loss: 1.3009630500734946\n",
      "Epoch 44/100, Loss: 1.2888614442976642\n",
      "Epoch 45/100, Loss: 1.3049871774522275\n",
      "Epoch 46/100, Loss: 1.2522000657766397\n",
      "Epoch 47/100, Loss: 1.1895562622347853\n",
      "Epoch 48/100, Loss: 1.1375619403036588\n",
      "Epoch 49/100, Loss: 1.2045218716301176\n",
      "Epoch 50/100, Loss: 1.2438992110652398\n",
      "Epoch 51/100, Loss: 1.2860962360787185\n",
      "Epoch 52/100, Loss: 1.3042756931723347\n",
      "Epoch 53/100, Loss: 1.1964695116481372\n",
      "Epoch 54/100, Loss: 1.1878216583174086\n",
      "Epoch 55/100, Loss: 1.2579289666782933\n",
      "Epoch 56/100, Loss: 1.1942249538271805\n",
      "Epoch 57/100, Loss: 1.1746484312686778\n",
      "Epoch 58/100, Loss: 1.1654795325143839\n",
      "Epoch 59/100, Loss: 1.211410681746975\n",
      "Epoch 60/100, Loss: 1.2012995024113806\n",
      "Epoch 61/100, Loss: 1.276643378969957\n",
      "Epoch 62/100, Loss: 1.2460064763459788\n",
      "Epoch 63/100, Loss: 1.2288601237227168\n",
      "Epoch 64/100, Loss: 1.1719322117924889\n",
      "Epoch 65/100, Loss: 1.1928008594988795\n",
      "Epoch 66/100, Loss: 1.2271964084646523\n",
      "Epoch 67/100, Loss: 1.109527168407106\n",
      "Epoch 68/100, Loss: 1.1553064629713272\n",
      "Epoch 69/100, Loss: 1.1509678524245321\n",
      "Epoch 70/100, Loss: 1.1316706197429103\n",
      "Epoch 71/100, Loss: 1.1854729861434714\n",
      "Epoch 72/100, Loss: 1.0937863663725764\n",
      "Epoch 73/100, Loss: 1.1300184003954619\n",
      "Epoch 74/100, Loss: 1.2027745225497979\n",
      "Epoch 75/100, Loss: 1.1926877961131546\n",
      "Epoch 76/100, Loss: 1.1508233909680206\n",
      "Epoch 77/100, Loss: 1.1220919717568782\n",
      "Epoch 78/100, Loss: 1.1611060803308846\n",
      "Epoch 79/100, Loss: 1.1019510989784411\n",
      "Epoch 80/100, Loss: 1.134553893471848\n",
      "Epoch 81/100, Loss: 1.1582044784789602\n",
      "Epoch 82/100, Loss: 1.0636787730563821\n",
      "Epoch 83/100, Loss: 1.102911855929737\n",
      "Epoch 84/100, Loss: 1.0911288016316154\n",
      "Epoch 85/100, Loss: 1.2335900016301906\n",
      "Epoch 86/100, Loss: 1.1800629383302803\n",
      "Epoch 87/100, Loss: 1.135192355990965\n",
      "Epoch 88/100, Loss: 1.058872443723811\n",
      "Epoch 89/100, Loss: 1.1090749428099316\n",
      "Epoch 90/100, Loss: 1.1371905541735716\n",
      "Epoch 91/100, Loss: 1.1173221716821398\n",
      "Epoch 92/100, Loss: 1.0895903543628926\n",
      "Epoch 93/100, Loss: 1.0588513918944589\n",
      "Epoch 94/100, Loss: 1.2293251102235294\n",
      "Epoch 95/100, Loss: 1.0801144706540482\n",
      "Epoch 96/100, Loss: 1.1427040787062328\n",
      "Epoch 97/100, Loss: 1.0962741547262875\n",
      "Epoch 98/100, Loss: 1.1234126998120038\n",
      "Epoch 99/100, Loss: 1.1664578661836977\n",
      "Epoch 100/100, Loss: 1.1872403758824015\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 71.27%'\n",
      "Epoch 1/150, Loss: 2.2548456506292793\n",
      "Epoch 2/150, Loss: 2.1602177828683797\n",
      "Epoch 3/150, Loss: 2.1007833837593144\n",
      "Epoch 4/150, Loss: 2.087011771255917\n",
      "Epoch 5/150, Loss: 1.9961215236222127\n",
      "Epoch 6/150, Loss: 1.9166480540261743\n",
      "Epoch 7/150, Loss: 1.8899139845555721\n",
      "Epoch 8/150, Loss: 1.887695460305352\n",
      "Epoch 9/150, Loss: 1.8544720578051448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Loss: 1.7713411094078706\n",
      "Epoch 11/150, Loss: 1.7327822381754912\n",
      "Epoch 12/150, Loss: 1.6608147928824857\n",
      "Epoch 13/150, Loss: 1.6560143600825175\n",
      "Epoch 14/150, Loss: 1.629986589106847\n",
      "Epoch 15/150, Loss: 1.6927764601549877\n",
      "Epoch 16/150, Loss: 1.5839010851898245\n",
      "Epoch 17/150, Loss: 1.5225080487999076\n",
      "Epoch 18/150, Loss: 1.5391951117018396\n",
      "Epoch 19/150, Loss: 1.5155620421934335\n",
      "Epoch 20/150, Loss: 1.4549624684524418\n",
      "Epoch 21/150, Loss: 1.449453231531278\n",
      "Epoch 22/150, Loss: 1.5283869004057031\n",
      "Epoch 23/150, Loss: 1.5102360039836387\n",
      "Epoch 24/150, Loss: 1.3956885060877722\n",
      "Epoch 25/150, Loss: 1.4402276671352692\n",
      "Epoch 26/150, Loss: 1.3393366991606943\n",
      "Epoch 27/150, Loss: 1.387259952472863\n",
      "Epoch 28/150, Loss: 1.3634730095722778\n",
      "Epoch 29/150, Loss: 1.3380763112650451\n",
      "Epoch 30/150, Loss: 1.337054641007815\n",
      "Epoch 31/150, Loss: 1.3966868354233848\n",
      "Epoch 32/150, Loss: 1.3502556497187668\n",
      "Epoch 33/150, Loss: 1.4001090519428796\n",
      "Epoch 34/150, Loss: 1.357902076645131\n",
      "Epoch 35/150, Loss: 1.324375308289237\n",
      "Epoch 36/150, Loss: 1.366295490033097\n",
      "Epoch 37/150, Loss: 1.3931788016147373\n",
      "Epoch 38/150, Loss: 1.2601929832543342\n",
      "Epoch 39/150, Loss: 1.287697524512302\n",
      "Epoch 40/150, Loss: 1.2513777567486817\n",
      "Epoch 41/150, Loss: 1.3104282154240496\n",
      "Epoch 42/150, Loss: 1.2803189493307399\n",
      "Epoch 43/150, Loss: 1.267885506157835\n",
      "Epoch 44/150, Loss: 1.2538289897868895\n",
      "Epoch 45/150, Loss: 1.2175125045465827\n",
      "Epoch 46/150, Loss: 1.324856564005096\n",
      "Epoch 47/150, Loss: 1.2827175308824046\n",
      "Epoch 48/150, Loss: 1.2367593413293778\n",
      "Epoch 49/150, Loss: 1.2708661157852552\n",
      "Epoch 50/150, Loss: 1.2629257732096009\n",
      "Epoch 51/150, Loss: 1.1844856784598963\n",
      "Epoch 52/150, Loss: 1.1960212263593721\n",
      "Epoch 53/150, Loss: 1.1347701176319551\n",
      "Epoch 54/150, Loss: 1.3218265388597954\n",
      "Epoch 55/150, Loss: 1.2887501894472098\n",
      "Epoch 56/150, Loss: 1.2358231492275196\n",
      "Epoch 57/150, Loss: 1.3175180593957332\n",
      "Epoch 58/150, Loss: 1.1475296225992042\n",
      "Epoch 59/150, Loss: 1.2027714586665117\n",
      "Epoch 60/150, Loss: 1.3007522552042996\n",
      "Epoch 61/150, Loss: 1.1432532597495026\n",
      "Epoch 62/150, Loss: 1.2305147974107125\n",
      "Epoch 63/150, Loss: 1.217918048680835\n",
      "Epoch 64/150, Loss: 1.0984727110186239\n",
      "Epoch 65/150, Loss: 1.2231975041793821\n",
      "Epoch 66/150, Loss: 1.2373141989415812\n",
      "Epoch 67/150, Loss: 1.2226559807107564\n",
      "Epoch 68/150, Loss: 1.1740881500947618\n",
      "Epoch 69/150, Loss: 1.2049530705645553\n",
      "Epoch 70/150, Loss: 1.044322332742479\n",
      "Epoch 71/150, Loss: 1.2048392372805803\n",
      "Epoch 72/150, Loss: 1.0791560406360237\n",
      "Epoch 73/150, Loss: 1.1309372744130486\n",
      "Epoch 74/150, Loss: 1.1838131463977957\n",
      "Epoch 75/150, Loss: 1.2058256437423656\n",
      "Epoch 76/150, Loss: 1.3097340316385317\n",
      "Epoch 77/150, Loss: 1.2076902505081903\n",
      "Epoch 78/150, Loss: 1.1589286197716697\n",
      "Epoch 79/150, Loss: 1.1073517040284684\n",
      "Epoch 80/150, Loss: 1.194501225136608\n",
      "Epoch 81/150, Loss: 1.121505172189472\n",
      "Epoch 82/150, Loss: 1.2106970105721815\n",
      "Epoch 83/150, Loss: 1.1771985235254738\n",
      "Epoch 84/150, Loss: 1.1874043539873118\n",
      "Epoch 85/150, Loss: 1.1321555685229543\n",
      "Epoch 86/150, Loss: 1.117789920114562\n",
      "Epoch 87/150, Loss: 1.1284630368610826\n",
      "Epoch 88/150, Loss: 1.0956824818898214\n",
      "Epoch 89/150, Loss: 1.1401291611221205\n",
      "Epoch 90/150, Loss: 1.155602508461104\n",
      "Epoch 91/150, Loss: 1.1571416470595048\n",
      "Epoch 92/150, Loss: 1.0871562088541016\n",
      "Epoch 93/150, Loss: 1.1700109500690512\n",
      "Epoch 94/150, Loss: 1.1273217996822287\n",
      "Epoch 95/150, Loss: 1.0940010693972075\n",
      "Epoch 96/150, Loss: 1.1172454524162392\n",
      "Epoch 97/150, Loss: 1.1426148188151288\n",
      "Epoch 98/150, Loss: 1.0097568652644833\n",
      "Epoch 99/150, Loss: 1.0890853570863426\n",
      "Epoch 100/150, Loss: 1.1243179423407064\n",
      "Epoch 101/150, Loss: 1.052708051526382\n",
      "Epoch 102/150, Loss: 1.1293174708041045\n",
      "Epoch 103/150, Loss: 1.1230891513531216\n",
      "Epoch 104/150, Loss: 1.1254416845820028\n",
      "Epoch 105/150, Loss: 1.0721166539062061\n",
      "Epoch 106/150, Loss: 1.0796741799673957\n",
      "Epoch 107/150, Loss: 1.2525899282087112\n",
      "Epoch 108/150, Loss: 1.0784546016678782\n",
      "Epoch 109/150, Loss: 0.8983185205140458\n",
      "Epoch 110/150, Loss: 1.0997213800198076\n",
      "Epoch 111/150, Loss: 1.0599374377876287\n",
      "Epoch 112/150, Loss: 1.087994410982203\n",
      "Epoch 113/150, Loss: 1.0831034125757912\n",
      "Epoch 114/150, Loss: 1.0639629699523625\n",
      "Epoch 115/150, Loss: 1.1459694923888897\n",
      "Epoch 116/150, Loss: 1.1203754971917974\n",
      "Epoch 117/150, Loss: 1.0648694009907052\n",
      "Epoch 118/150, Loss: 1.1243985626364155\n",
      "Epoch 119/150, Loss: 1.1601264561239648\n",
      "Epoch 120/150, Loss: 1.0133594891904434\n",
      "Epoch 121/150, Loss: 1.1237016541933058\n",
      "Epoch 122/150, Loss: 1.071960732892998\n",
      "Epoch 123/150, Loss: 1.042320136451703\n",
      "Epoch 124/150, Loss: 1.009259745672891\n",
      "Epoch 125/150, Loss: 1.067095647302344\n",
      "Epoch 126/150, Loss: 1.1436852632179142\n",
      "Epoch 127/150, Loss: 1.1390009828735068\n",
      "Epoch 128/150, Loss: 1.1561932303685558\n",
      "Epoch 129/150, Loss: 1.1854612636732074\n",
      "Epoch 130/150, Loss: 1.090296028293018\n",
      "Epoch 131/150, Loss: 1.0312731686988983\n",
      "Epoch 132/150, Loss: 1.0293252804903172\n",
      "Epoch 133/150, Loss: 1.0784910037789635\n",
      "Epoch 134/150, Loss: 1.125790318267914\n",
      "Epoch 135/150, Loss: 1.0806533721879839\n",
      "Epoch 136/150, Loss: 1.2390545537584985\n",
      "Epoch 137/150, Loss: 1.1535933712429023\n",
      "Epoch 138/150, Loss: 1.0784675335251293\n",
      "Epoch 139/150, Loss: 1.0376249263964823\n",
      "Epoch 140/150, Loss: 1.1337629439810022\n",
      "Epoch 141/150, Loss: 1.2286602474163022\n",
      "Epoch 142/150, Loss: 1.161301149361479\n",
      "Epoch 143/150, Loss: 1.1225687499585626\n",
      "Epoch 144/150, Loss: 1.0785251421669149\n",
      "Epoch 145/150, Loss: 1.0364018096528151\n",
      "Epoch 146/150, Loss: 1.0549110757375972\n",
      "Epoch 147/150, Loss: 1.0783577112062144\n",
      "Epoch 148/150, Loss: 1.0625419361127535\n",
      "Epoch 149/150, Loss: 1.0950971498769975\n",
      "Epoch 150/150, Loss: 1.0841160376864531\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.0001, Alpha 0.1, f'Test accuracy: 73.52%'\n",
      "Epoch 1/50, Loss: 1.0882697387679945\n",
      "Epoch 2/50, Loss: 1.1345219408947929\n",
      "Epoch 3/50, Loss: 0.746887846832656\n",
      "Epoch 4/50, Loss: 0.7712725509351596\n",
      "Epoch 5/50, Loss: 0.626409285459255\n",
      "Epoch 6/50, Loss: 1.0981328900016654\n",
      "Epoch 7/50, Loss: 0.7918290616898158\n",
      "Epoch 8/50, Loss: 0.8311063936894236\n",
      "Epoch 9/50, Loss: 0.8296720314964404\n",
      "Epoch 10/50, Loss: 0.5939962935204053\n",
      "Epoch 11/50, Loss: 0.733812541533216\n",
      "Epoch 12/50, Loss: 0.8282188322300947\n",
      "Epoch 13/50, Loss: 0.6474628800242422\n",
      "Epoch 14/50, Loss: 0.8103030642860474\n",
      "Epoch 15/50, Loss: 0.861826533102415\n",
      "Epoch 16/50, Loss: 0.4700606625667477\n",
      "Epoch 17/50, Loss: 0.6531030543163605\n",
      "Epoch 18/50, Loss: 0.609225024291821\n",
      "Epoch 19/50, Loss: 0.9388073759679414\n",
      "Epoch 20/50, Loss: 0.9132597478591454\n",
      "Epoch 21/50, Loss: 0.6989113520321705\n",
      "Epoch 22/50, Loss: 0.6442662302024242\n",
      "Epoch 23/50, Loss: 0.9582111511016801\n",
      "Epoch 24/50, Loss: 1.039646522186422\n",
      "Epoch 25/50, Loss: 0.2807886193867757\n",
      "Epoch 26/50, Loss: 0.6503483639347996\n",
      "Epoch 27/50, Loss: 0.6139694494080532\n",
      "Epoch 28/50, Loss: 0.40853830989954376\n",
      "Epoch 29/50, Loss: 0.8981530360829625\n",
      "Epoch 30/50, Loss: 0.8334346543540603\n",
      "Epoch 31/50, Loss: 0.49452231343762426\n",
      "Epoch 32/50, Loss: 0.6411756904099244\n",
      "Epoch 33/50, Loss: 0.5366276414732905\n",
      "Epoch 34/50, Loss: 0.44438035194299824\n",
      "Epoch 35/50, Loss: 0.6127476314463878\n",
      "Epoch 36/50, Loss: 0.39012674588558494\n",
      "Epoch 37/50, Loss: 0.7227048148793979\n",
      "Epoch 38/50, Loss: 0.7051257224250749\n",
      "Epoch 39/50, Loss: 0.5310532618726352\n",
      "Epoch 40/50, Loss: 0.6084916830951669\n",
      "Epoch 41/50, Loss: 0.6857608911423932\n",
      "Epoch 42/50, Loss: 0.7249270896703405\n",
      "Epoch 43/50, Loss: 0.6421007146456232\n",
      "Epoch 44/50, Loss: 0.7053769572514189\n",
      "Epoch 45/50, Loss: 0.9765413530767917\n",
      "Epoch 46/50, Loss: 0.6446505297688997\n",
      "Epoch 47/50, Loss: 0.7321625224126054\n",
      "Epoch 48/50, Loss: 0.6671303999692041\n",
      "Epoch 49/50, Loss: 0.6673864704557907\n",
      "Epoch 50/50, Loss: 0.7124578559831027\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 82.49%'\n",
      "Epoch 1/100, Loss: 1.2098638199698994\n",
      "Epoch 2/100, Loss: 1.0294641751566744\n",
      "Epoch 3/100, Loss: 0.836404810259358\n",
      "Epoch 4/100, Loss: 0.8237379578935927\n",
      "Epoch 5/100, Loss: 1.0004250001630244\n",
      "Epoch 6/100, Loss: 0.834361538130804\n",
      "Epoch 7/100, Loss: 0.6140956996707625\n",
      "Epoch 8/100, Loss: 0.7021912701602198\n",
      "Epoch 9/100, Loss: 0.7870452215978083\n",
      "Epoch 10/100, Loss: 0.7586259040171339\n",
      "Epoch 11/100, Loss: 0.6880130252352494\n",
      "Epoch 12/100, Loss: 0.5960913798943811\n",
      "Epoch 13/100, Loss: 0.5462203343651068\n",
      "Epoch 14/100, Loss: 0.6291027920232054\n",
      "Epoch 15/100, Loss: 0.7662761861078251\n",
      "Epoch 16/100, Loss: 0.6750561164196586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Loss: 0.48555347695501544\n",
      "Epoch 18/100, Loss: 0.7849975070955272\n",
      "Epoch 19/100, Loss: 0.5922586237767661\n",
      "Epoch 20/100, Loss: 0.6608473046633637\n",
      "Epoch 21/100, Loss: 0.6966649884880894\n",
      "Epoch 22/100, Loss: 0.8216470708707729\n",
      "Epoch 23/100, Loss: 0.5473285238809537\n",
      "Epoch 24/100, Loss: 0.6760259488083666\n",
      "Epoch 25/100, Loss: 0.5199420894335459\n",
      "Epoch 26/100, Loss: 0.5729223465342199\n",
      "Epoch 27/100, Loss: 0.8057917309233577\n",
      "Epoch 28/100, Loss: 0.4784968031834695\n",
      "Epoch 29/100, Loss: 0.8223390501754558\n",
      "Epoch 30/100, Loss: 0.6374520131791543\n",
      "Epoch 31/100, Loss: 0.4505828648315218\n",
      "Epoch 32/100, Loss: 0.9581941321739137\n",
      "Epoch 33/100, Loss: 0.6954779594306346\n",
      "Epoch 34/100, Loss: 0.5679343898186683\n",
      "Epoch 35/100, Loss: 0.6644504514033198\n",
      "Epoch 36/100, Loss: 0.52437992115811\n",
      "Epoch 37/100, Loss: 0.6464833311245824\n",
      "Epoch 38/100, Loss: 0.5841876744201251\n",
      "Epoch 39/100, Loss: 0.5226591126125675\n",
      "Epoch 40/100, Loss: 0.5587613718428388\n",
      "Epoch 41/100, Loss: 0.6393167330052414\n",
      "Epoch 42/100, Loss: 0.8384224882413124\n",
      "Epoch 43/100, Loss: 0.5680097193515998\n",
      "Epoch 44/100, Loss: 0.6180286908289095\n",
      "Epoch 45/100, Loss: 0.570644475752589\n",
      "Epoch 46/100, Loss: 0.6425850978624771\n",
      "Epoch 47/100, Loss: 0.5792576930410451\n",
      "Epoch 48/100, Loss: 1.152525375677312\n",
      "Epoch 49/100, Loss: 0.6216206222848686\n",
      "Epoch 50/100, Loss: 0.6477157346182186\n",
      "Epoch 51/100, Loss: 0.35819582428813945\n",
      "Epoch 52/100, Loss: 0.5365731941193351\n",
      "Epoch 53/100, Loss: 0.48768609643724603\n",
      "Epoch 54/100, Loss: 0.5112689698151329\n",
      "Epoch 55/100, Loss: 0.6746785237665891\n",
      "Epoch 56/100, Loss: 0.7376339894901941\n",
      "Epoch 57/100, Loss: 0.5817616301998418\n",
      "Epoch 58/100, Loss: 0.6047350210128247\n",
      "Epoch 59/100, Loss: 0.5369432089991476\n",
      "Epoch 60/100, Loss: 0.5194025541150815\n",
      "Epoch 61/100, Loss: 0.7213732197660285\n",
      "Epoch 62/100, Loss: 0.6919602124849359\n",
      "Epoch 63/100, Loss: 0.6762453522801833\n",
      "Epoch 64/100, Loss: 0.5258223543341436\n",
      "Epoch 65/100, Loss: 0.608231646363286\n",
      "Epoch 66/100, Loss: 0.6916079620029846\n",
      "Epoch 67/100, Loss: 0.7605723371338674\n",
      "Epoch 68/100, Loss: 0.5861599837555311\n",
      "Epoch 69/100, Loss: 0.6059971717813974\n",
      "Epoch 70/100, Loss: 0.6636023659019608\n",
      "Epoch 71/100, Loss: 0.6080027623746463\n",
      "Epoch 72/100, Loss: 0.4432604059375445\n",
      "Epoch 73/100, Loss: 0.8238481290958257\n",
      "Epoch 74/100, Loss: 0.6819483403274595\n",
      "Epoch 75/100, Loss: 0.5417796738686593\n",
      "Epoch 76/100, Loss: 0.49582960879888066\n",
      "Epoch 77/100, Loss: 0.6776787231930286\n",
      "Epoch 78/100, Loss: 0.6508447896853047\n",
      "Epoch 79/100, Loss: 0.6876896022428884\n",
      "Epoch 80/100, Loss: 0.6372709891421933\n",
      "Epoch 81/100, Loss: 0.46222163043210696\n",
      "Epoch 82/100, Loss: 0.5070271243936573\n",
      "Epoch 83/100, Loss: 0.4091380467297166\n",
      "Epoch 84/100, Loss: 0.47767234281159054\n",
      "Epoch 85/100, Loss: 0.727438712552495\n",
      "Epoch 86/100, Loss: 0.5575862597516242\n",
      "Epoch 87/100, Loss: 0.5557895150963925\n",
      "Epoch 88/100, Loss: 0.6304882111693055\n",
      "Epoch 89/100, Loss: 0.5615014274211845\n",
      "Epoch 90/100, Loss: 0.5830219945008074\n",
      "Epoch 91/100, Loss: 0.5874960417935816\n",
      "Epoch 92/100, Loss: 0.7197131570235833\n",
      "Epoch 93/100, Loss: 0.7842255970545152\n",
      "Epoch 94/100, Loss: 0.7003361918090992\n",
      "Epoch 95/100, Loss: 0.738530377357381\n",
      "Epoch 96/100, Loss: 0.537457970811417\n",
      "Epoch 97/100, Loss: 0.5678463389376178\n",
      "Epoch 98/100, Loss: 0.6663947201005108\n",
      "Epoch 99/100, Loss: 0.978409829651632\n",
      "Epoch 100/100, Loss: 0.5788697170480998\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 83.11%'\n",
      "Epoch 1/150, Loss: 1.3365736602459537\n",
      "Epoch 2/150, Loss: 1.218372856383713\n",
      "Epoch 3/150, Loss: 1.1448339096112556\n",
      "Epoch 4/150, Loss: 0.8045507934606655\n",
      "Epoch 5/150, Loss: 0.8577586652842157\n",
      "Epoch 6/150, Loss: 0.8704937680225324\n",
      "Epoch 7/150, Loss: 0.6209326781032218\n",
      "Epoch 8/150, Loss: 0.8940130577014385\n",
      "Epoch 9/150, Loss: 0.635034692911506\n",
      "Epoch 10/150, Loss: 0.7999569576373473\n",
      "Epoch 11/150, Loss: 0.47353665632594255\n",
      "Epoch 12/150, Loss: 0.7231043373179422\n",
      "Epoch 13/150, Loss: 0.7327604554450375\n",
      "Epoch 14/150, Loss: 0.7094612021162726\n",
      "Epoch 15/150, Loss: 0.5714392276230014\n",
      "Epoch 16/150, Loss: 0.6630201834895229\n",
      "Epoch 17/150, Loss: 0.7267356088992971\n",
      "Epoch 18/150, Loss: 0.7830710686929546\n",
      "Epoch 19/150, Loss: 0.6882457974967342\n",
      "Epoch 20/150, Loss: 0.5507011594751008\n",
      "Epoch 21/150, Loss: 0.6899978797630649\n",
      "Epoch 22/150, Loss: 0.6481151044471081\n",
      "Epoch 23/150, Loss: 0.5537308006368186\n",
      "Epoch 24/150, Loss: 0.6594158607920099\n",
      "Epoch 25/150, Loss: 0.44853745021761326\n",
      "Epoch 26/150, Loss: 0.46057643924857217\n",
      "Epoch 27/150, Loss: 0.6478162801539965\n",
      "Epoch 28/150, Loss: 0.5073813793509635\n",
      "Epoch 29/150, Loss: 0.555692097398689\n",
      "Epoch 30/150, Loss: 0.811591828837129\n",
      "Epoch 31/150, Loss: 0.7431756794900289\n",
      "Epoch 32/150, Loss: 0.6741791606282432\n",
      "Epoch 33/150, Loss: 0.5279595898629728\n",
      "Epoch 34/150, Loss: 0.5090913614142956\n",
      "Epoch 35/150, Loss: 0.711273778942451\n",
      "Epoch 36/150, Loss: 0.48275851801127195\n",
      "Epoch 37/150, Loss: 0.8285808604354387\n",
      "Epoch 38/150, Loss: 0.6388141290224477\n",
      "Epoch 39/150, Loss: 0.8014579363636108\n",
      "Epoch 40/150, Loss: 0.616681047085123\n",
      "Epoch 41/150, Loss: 0.8108790225774198\n",
      "Epoch 42/150, Loss: 0.6813510229736024\n",
      "Epoch 43/150, Loss: 1.0215164354789783\n",
      "Epoch 44/150, Loss: 0.6273966507986726\n",
      "Epoch 45/150, Loss: 0.5083633422262782\n",
      "Epoch 46/150, Loss: 0.6874201914864664\n",
      "Epoch 47/150, Loss: 0.6372421565003498\n",
      "Epoch 48/150, Loss: 0.7054103838361084\n",
      "Epoch 49/150, Loss: 0.6345109385565137\n",
      "Epoch 50/150, Loss: 0.715271767862519\n",
      "Epoch 51/150, Loss: 0.6123799347696884\n",
      "Epoch 52/150, Loss: 0.6432776975813866\n",
      "Epoch 53/150, Loss: 0.5872706254447947\n",
      "Epoch 54/150, Loss: 0.5188637483676288\n",
      "Epoch 55/150, Loss: 0.5727758606707223\n",
      "Epoch 56/150, Loss: 0.7389967690242604\n",
      "Epoch 57/150, Loss: 0.5134736237756229\n",
      "Epoch 58/150, Loss: 0.5804148109609617\n",
      "Epoch 59/150, Loss: 0.8144564587271661\n",
      "Epoch 60/150, Loss: 0.5895809556356897\n",
      "Epoch 61/150, Loss: 0.6076536928242191\n",
      "Epoch 62/150, Loss: 0.7848127805629371\n",
      "Epoch 63/150, Loss: 0.6178531368672834\n",
      "Epoch 64/150, Loss: 0.6418230143312593\n",
      "Epoch 65/150, Loss: 0.515382688233617\n",
      "Epoch 66/150, Loss: 0.6245716173020256\n",
      "Epoch 67/150, Loss: 0.424541209217276\n",
      "Epoch 68/150, Loss: 0.7357681978890631\n",
      "Epoch 69/150, Loss: 0.5609979240765025\n",
      "Epoch 70/150, Loss: 0.5580084527717801\n",
      "Epoch 71/150, Loss: 0.7508669623441324\n",
      "Epoch 72/150, Loss: 0.5961609082989475\n",
      "Epoch 73/150, Loss: 0.5837261963885336\n",
      "Epoch 74/150, Loss: 0.7272063375205753\n",
      "Epoch 75/150, Loss: 0.5117881665544264\n",
      "Epoch 76/150, Loss: 0.5502811209292102\n",
      "Epoch 77/150, Loss: 0.7089843805048086\n",
      "Epoch 78/150, Loss: 0.6855817858382134\n",
      "Epoch 79/150, Loss: 0.6552350267059107\n",
      "Epoch 80/150, Loss: 0.5827808446311405\n",
      "Epoch 81/150, Loss: 0.6260833570712347\n",
      "Epoch 82/150, Loss: 0.8338184816625411\n",
      "Epoch 83/150, Loss: 0.7513971793475556\n",
      "Epoch 84/150, Loss: 0.6942755517174148\n",
      "Epoch 85/150, Loss: 0.7312247763779725\n",
      "Epoch 86/150, Loss: 0.5543184999770676\n",
      "Epoch 87/150, Loss: 0.3332124438892994\n",
      "Epoch 88/150, Loss: 0.8427208586639946\n",
      "Epoch 89/150, Loss: 0.5220121541527383\n",
      "Epoch 90/150, Loss: 0.6528493487031454\n",
      "Epoch 91/150, Loss: 0.6914522052394781\n",
      "Epoch 92/150, Loss: 0.5009476704064666\n",
      "Epoch 93/150, Loss: 0.47785512870370805\n",
      "Epoch 94/150, Loss: 0.6297403581377419\n",
      "Epoch 95/150, Loss: 0.5633953813215418\n",
      "Epoch 96/150, Loss: 0.5749236158102259\n",
      "Epoch 97/150, Loss: 0.570606701690097\n",
      "Epoch 98/150, Loss: 0.38199264404918953\n",
      "Epoch 99/150, Loss: 0.6792948833684332\n",
      "Epoch 100/150, Loss: 0.6500717230401877\n",
      "Epoch 101/150, Loss: 0.6129298970865854\n",
      "Epoch 102/150, Loss: 0.6438409054515389\n",
      "Epoch 103/150, Loss: 0.5931134518757772\n",
      "Epoch 104/150, Loss: 0.6320663675346029\n",
      "Epoch 105/150, Loss: 0.7101882571910639\n",
      "Epoch 106/150, Loss: 1.02585788278052\n",
      "Epoch 107/150, Loss: 0.4745276128611223\n",
      "Epoch 108/150, Loss: 0.7267712555675928\n",
      "Epoch 109/150, Loss: 0.6326428777416038\n",
      "Epoch 110/150, Loss: 0.8296239547561348\n",
      "Epoch 111/150, Loss: 0.737031984891907\n",
      "Epoch 112/150, Loss: 0.5369651674240257\n",
      "Epoch 113/150, Loss: 0.5722615949247893\n",
      "Epoch 114/150, Loss: 0.7256324119478345\n",
      "Epoch 115/150, Loss: 0.5628787539871505\n",
      "Epoch 116/150, Loss: 0.6512224120645209\n",
      "Epoch 117/150, Loss: 0.8207372335059042\n",
      "Epoch 118/150, Loss: 0.6149776393874282\n",
      "Epoch 119/150, Loss: 0.6675588910829744\n",
      "Epoch 120/150, Loss: 0.6738057897265898\n",
      "Epoch 121/150, Loss: 0.6093674503142706\n",
      "Epoch 122/150, Loss: 0.7446872643163748\n",
      "Epoch 123/150, Loss: 0.5322308275087168\n",
      "Epoch 124/150, Loss: 0.9629588677156906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150, Loss: 0.5932402682413204\n",
      "Epoch 126/150, Loss: 0.5501719631728001\n",
      "Epoch 127/150, Loss: 0.653549419836586\n",
      "Epoch 128/150, Loss: 0.7521131611446182\n",
      "Epoch 129/150, Loss: 0.8144066524330277\n",
      "Epoch 130/150, Loss: 0.7598584140179748\n",
      "Epoch 131/150, Loss: 0.664877519954457\n",
      "Epoch 132/150, Loss: 0.7514387756469133\n",
      "Epoch 133/150, Loss: 0.5573788794353418\n",
      "Epoch 134/150, Loss: 0.607489557956897\n",
      "Epoch 135/150, Loss: 0.9282793536522566\n",
      "Epoch 136/150, Loss: 0.6558120724843953\n",
      "Epoch 137/150, Loss: 0.42733163202552754\n",
      "Epoch 138/150, Loss: 0.5451875768034821\n",
      "Epoch 139/150, Loss: 0.6837829337422141\n",
      "Epoch 140/150, Loss: 0.7459809711440242\n",
      "Epoch 141/150, Loss: 0.44120795316412903\n",
      "Epoch 142/150, Loss: 0.8765883619307131\n",
      "Epoch 143/150, Loss: 0.7289718370593377\n",
      "Epoch 144/150, Loss: 0.5506112111813448\n",
      "Epoch 145/150, Loss: 0.7405015002645622\n",
      "Epoch 146/150, Loss: 0.44741813075125264\n",
      "Epoch 147/150, Loss: 0.4466298860913436\n",
      "Epoch 148/150, Loss: 0.6922654409426563\n",
      "Epoch 149/150, Loss: 0.5949167487820922\n",
      "Epoch 150/150, Loss: 0.6324605245779503\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 83.18%'\n",
      "Epoch 1/50, Loss: 1.3602716110268744\n",
      "Epoch 2/50, Loss: 1.0767122867434342\n",
      "Epoch 3/50, Loss: 1.048611085892932\n",
      "Epoch 4/50, Loss: 0.9137027466417192\n",
      "Epoch 5/50, Loss: 0.8690231236241742\n",
      "Epoch 6/50, Loss: 0.7983682842474249\n",
      "Epoch 7/50, Loss: 0.8760749210832772\n",
      "Epoch 8/50, Loss: 0.9154170861673109\n",
      "Epoch 9/50, Loss: 0.7254729776680574\n",
      "Epoch 10/50, Loss: 0.6838352455418787\n",
      "Epoch 11/50, Loss: 0.7296093697115209\n",
      "Epoch 12/50, Loss: 0.850292433082303\n",
      "Epoch 13/50, Loss: 0.7283355728860557\n",
      "Epoch 14/50, Loss: 0.8328791201708053\n",
      "Epoch 15/50, Loss: 0.952205481735055\n",
      "Epoch 16/50, Loss: 0.7412832954833948\n",
      "Epoch 17/50, Loss: 0.7093409842043941\n",
      "Epoch 18/50, Loss: 0.770453146122731\n",
      "Epoch 19/50, Loss: 0.7309086283262635\n",
      "Epoch 20/50, Loss: 0.628682592380513\n",
      "Epoch 21/50, Loss: 0.8531260552804277\n",
      "Epoch 22/50, Loss: 0.7551868972169075\n",
      "Epoch 23/50, Loss: 0.7561644730605419\n",
      "Epoch 24/50, Loss: 0.7250582499762397\n",
      "Epoch 25/50, Loss: 0.5904575822233394\n",
      "Epoch 26/50, Loss: 0.8684787277545353\n",
      "Epoch 27/50, Loss: 0.7367959983955064\n",
      "Epoch 28/50, Loss: 0.6256602290989363\n",
      "Epoch 29/50, Loss: 0.7799730701685984\n",
      "Epoch 30/50, Loss: 0.5895728652569662\n",
      "Epoch 31/50, Loss: 0.7127401308372168\n",
      "Epoch 32/50, Loss: 0.5671557411066753\n",
      "Epoch 33/50, Loss: 0.7456481691053709\n",
      "Epoch 34/50, Loss: 0.5133713622882987\n",
      "Epoch 35/50, Loss: 0.6844859330682587\n",
      "Epoch 36/50, Loss: 0.6510001870321963\n",
      "Epoch 37/50, Loss: 0.7030504631400808\n",
      "Epoch 38/50, Loss: 0.6100830738748961\n",
      "Epoch 39/50, Loss: 0.7908490677355201\n",
      "Epoch 40/50, Loss: 0.7235738553787878\n",
      "Epoch 41/50, Loss: 0.638681622431942\n",
      "Epoch 42/50, Loss: 0.755540535098411\n",
      "Epoch 43/50, Loss: 0.5718701603113132\n",
      "Epoch 44/50, Loss: 0.7617777109034297\n",
      "Epoch 45/50, Loss: 0.6937296132289396\n",
      "Epoch 46/50, Loss: 0.6269649367271669\n",
      "Epoch 47/50, Loss: 0.7999664514483514\n",
      "Epoch 48/50, Loss: 0.8046382608441293\n",
      "Epoch 49/50, Loss: 0.682236692889601\n",
      "Epoch 50/50, Loss: 0.6592538528972733\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 81.25%'\n",
      "Epoch 1/100, Loss: 1.5461483339955528\n",
      "Epoch 2/100, Loss: 1.2154957298163165\n",
      "Epoch 3/100, Loss: 0.9281078374517114\n",
      "Epoch 4/100, Loss: 1.022413382431283\n",
      "Epoch 5/100, Loss: 0.9545502913917603\n",
      "Epoch 6/100, Loss: 0.8064366521583121\n",
      "Epoch 7/100, Loss: 0.6803311344110251\n",
      "Epoch 8/100, Loss: 0.7924307517898846\n",
      "Epoch 9/100, Loss: 0.9034198343567116\n",
      "Epoch 10/100, Loss: 0.7347882061711387\n",
      "Epoch 11/100, Loss: 0.8158971194110748\n",
      "Epoch 12/100, Loss: 0.8075608898862069\n",
      "Epoch 13/100, Loss: 0.8749593631717794\n",
      "Epoch 14/100, Loss: 0.6592683239762694\n",
      "Epoch 15/100, Loss: 0.8028524077409825\n",
      "Epoch 16/100, Loss: 0.6458829537864142\n",
      "Epoch 17/100, Loss: 0.7567631592060836\n",
      "Epoch 18/100, Loss: 0.9390678233667984\n",
      "Epoch 19/100, Loss: 0.8211629881571854\n",
      "Epoch 20/100, Loss: 0.7271139220071206\n",
      "Epoch 21/100, Loss: 0.6470562159243116\n",
      "Epoch 22/100, Loss: 0.5289960394610413\n",
      "Epoch 23/100, Loss: 0.716183640372611\n",
      "Epoch 24/100, Loss: 0.6397010568850878\n",
      "Epoch 25/100, Loss: 0.7403384754653868\n",
      "Epoch 26/100, Loss: 0.7282948542881988\n",
      "Epoch 27/100, Loss: 0.6320640694603271\n",
      "Epoch 28/100, Loss: 0.6675697017545016\n",
      "Epoch 29/100, Loss: 0.6502599316567919\n",
      "Epoch 30/100, Loss: 0.7794281527556496\n",
      "Epoch 31/100, Loss: 0.6507116748093391\n",
      "Epoch 32/100, Loss: 0.7541578700293969\n",
      "Epoch 33/100, Loss: 0.9186053123187037\n",
      "Epoch 34/100, Loss: 0.5966123477285705\n",
      "Epoch 35/100, Loss: 0.6722490373674924\n",
      "Epoch 36/100, Loss: 0.5929011279293726\n",
      "Epoch 37/100, Loss: 0.6508476718358267\n",
      "Epoch 38/100, Loss: 0.6664965156887503\n",
      "Epoch 39/100, Loss: 0.800322107722608\n",
      "Epoch 40/100, Loss: 0.5095649609336784\n",
      "Epoch 41/100, Loss: 0.6112228474271149\n",
      "Epoch 42/100, Loss: 0.4898257977129859\n",
      "Epoch 43/100, Loss: 0.7513129320184925\n",
      "Epoch 44/100, Loss: 0.623770309537029\n",
      "Epoch 45/100, Loss: 0.6816999473053261\n",
      "Epoch 46/100, Loss: 0.6598339575990781\n",
      "Epoch 47/100, Loss: 0.6676857030178763\n",
      "Epoch 48/100, Loss: 0.6815080422463801\n",
      "Epoch 49/100, Loss: 0.5214976585035297\n",
      "Epoch 50/100, Loss: 0.8174523838889691\n",
      "Epoch 51/100, Loss: 0.7481719716103881\n",
      "Epoch 52/100, Loss: 0.7350075189089335\n",
      "Epoch 53/100, Loss: 0.7658838705582253\n",
      "Epoch 54/100, Loss: 0.5953721736143119\n",
      "Epoch 55/100, Loss: 0.4842236148484151\n",
      "Epoch 56/100, Loss: 0.6276807037928707\n",
      "Epoch 57/100, Loss: 0.632925081722163\n",
      "Epoch 58/100, Loss: 0.5719074338183681\n",
      "Epoch 59/100, Loss: 0.6872639838427573\n",
      "Epoch 60/100, Loss: 0.8170995926838912\n",
      "Epoch 61/100, Loss: 0.5196216871043383\n",
      "Epoch 62/100, Loss: 0.7550914945345995\n",
      "Epoch 63/100, Loss: 0.5796963567044843\n",
      "Epoch 64/100, Loss: 0.7439780775954214\n",
      "Epoch 65/100, Loss: 0.5782220312813258\n",
      "Epoch 66/100, Loss: 0.7423481764828449\n",
      "Epoch 67/100, Loss: 0.7253910672209648\n",
      "Epoch 68/100, Loss: 0.6677380766862604\n",
      "Epoch 69/100, Loss: 0.6936349168551348\n",
      "Epoch 70/100, Loss: 0.6033409981988479\n",
      "Epoch 71/100, Loss: 0.6199079544239098\n",
      "Epoch 72/100, Loss: 0.5329836673570967\n",
      "Epoch 73/100, Loss: 0.6413273024306021\n",
      "Epoch 74/100, Loss: 0.5939635249691781\n",
      "Epoch 75/100, Loss: 0.7068813999791089\n",
      "Epoch 76/100, Loss: 0.7080182038044958\n",
      "Epoch 77/100, Loss: 0.7047279452271114\n",
      "Epoch 78/100, Loss: 0.559539823526524\n",
      "Epoch 79/100, Loss: 0.7176952089152285\n",
      "Epoch 80/100, Loss: 0.5761009723523204\n",
      "Epoch 81/100, Loss: 0.5759337502921804\n",
      "Epoch 82/100, Loss: 0.5759180867020136\n",
      "Epoch 83/100, Loss: 0.6592215175204337\n",
      "Epoch 84/100, Loss: 0.5898251395997086\n",
      "Epoch 85/100, Loss: 0.5174331368848972\n",
      "Epoch 86/100, Loss: 0.8220099500762897\n",
      "Epoch 87/100, Loss: 0.47597029992797635\n",
      "Epoch 88/100, Loss: 0.633268461315015\n",
      "Epoch 89/100, Loss: 0.5754342337616679\n",
      "Epoch 90/100, Loss: 0.5174364890351602\n",
      "Epoch 91/100, Loss: 0.570442485523198\n",
      "Epoch 92/100, Loss: 0.6785856701239046\n",
      "Epoch 93/100, Loss: 0.623775867419789\n",
      "Epoch 94/100, Loss: 0.6961954259876357\n",
      "Epoch 95/100, Loss: 0.6205182217015639\n",
      "Epoch 96/100, Loss: 0.39531044463027754\n",
      "Epoch 97/100, Loss: 0.6823170405471246\n",
      "Epoch 98/100, Loss: 0.6236085946407701\n",
      "Epoch 99/100, Loss: 0.5241654535074562\n",
      "Epoch 100/100, Loss: 0.6932447879226011\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 82.49%'\n",
      "Epoch 1/150, Loss: 1.4732828845652448\n",
      "Epoch 2/150, Loss: 1.132298758010972\n",
      "Epoch 3/150, Loss: 1.035757865215982\n",
      "Epoch 4/150, Loss: 0.9465896502404074\n",
      "Epoch 5/150, Loss: 0.8717506851749816\n",
      "Epoch 6/150, Loss: 0.8746008887729495\n",
      "Epoch 7/150, Loss: 0.7547248649305434\n",
      "Epoch 8/150, Loss: 0.867189339746258\n",
      "Epoch 9/150, Loss: 0.7435936144910141\n",
      "Epoch 10/150, Loss: 0.7948238855060079\n",
      "Epoch 11/150, Loss: 0.8052714217746323\n",
      "Epoch 12/150, Loss: 0.7468061393945614\n",
      "Epoch 13/150, Loss: 1.0114115479795471\n",
      "Epoch 14/150, Loss: 0.7662434919151959\n",
      "Epoch 15/150, Loss: 0.7292505306750323\n",
      "Epoch 16/150, Loss: 0.5608400565403363\n",
      "Epoch 17/150, Loss: 0.7071766174478284\n",
      "Epoch 18/150, Loss: 0.8674539558070428\n",
      "Epoch 19/150, Loss: 0.721546391145642\n",
      "Epoch 20/150, Loss: 0.8665531020875498\n",
      "Epoch 21/150, Loss: 0.6342793828996898\n",
      "Epoch 22/150, Loss: 0.5958024081681988\n",
      "Epoch 23/150, Loss: 0.6508206890017564\n",
      "Epoch 24/150, Loss: 0.5835980615122353\n",
      "Epoch 25/150, Loss: 0.6351181313072061\n",
      "Epoch 26/150, Loss: 0.6450347792523357\n",
      "Epoch 27/150, Loss: 0.7403245747268893\n",
      "Epoch 28/150, Loss: 0.6266828371854922\n",
      "Epoch 29/150, Loss: 0.6028269171857348\n",
      "Epoch 30/150, Loss: 0.767201547190246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150, Loss: 0.745941377819627\n",
      "Epoch 32/150, Loss: 0.6069919221248607\n",
      "Epoch 33/150, Loss: 0.6752847019516874\n",
      "Epoch 34/150, Loss: 0.6204566431566692\n",
      "Epoch 35/150, Loss: 0.6000596299973007\n",
      "Epoch 36/150, Loss: 0.47836674753236746\n",
      "Epoch 37/150, Loss: 0.8743613056958706\n",
      "Epoch 38/150, Loss: 0.7753282881965416\n",
      "Epoch 39/150, Loss: 0.6125676990151704\n",
      "Epoch 40/150, Loss: 0.6826476695685243\n",
      "Epoch 41/150, Loss: 0.6261911953907704\n",
      "Epoch 42/150, Loss: 0.7279019183970699\n",
      "Epoch 43/150, Loss: 0.7128987909731421\n",
      "Epoch 44/150, Loss: 0.6805610538991939\n",
      "Epoch 45/150, Loss: 0.5763944046763405\n",
      "Epoch 46/150, Loss: 0.5405193775595968\n",
      "Epoch 47/150, Loss: 0.6448822723631116\n",
      "Epoch 48/150, Loss: 0.6605269086231126\n",
      "Epoch 49/150, Loss: 0.5091038025913307\n",
      "Epoch 50/150, Loss: 0.6652442242299896\n",
      "Epoch 51/150, Loss: 0.6160790193619828\n",
      "Epoch 52/150, Loss: 0.49973388824696063\n",
      "Epoch 53/150, Loss: 0.6472776674170875\n",
      "Epoch 54/150, Loss: 0.6284724518024473\n",
      "Epoch 55/150, Loss: 0.6682730840081242\n",
      "Epoch 56/150, Loss: 0.6439175460216376\n",
      "Epoch 57/150, Loss: 0.6670129682440458\n",
      "Epoch 58/150, Loss: 0.7781906135673861\n",
      "Epoch 59/150, Loss: 0.6371325832778593\n",
      "Epoch 60/150, Loss: 0.7128254121598708\n",
      "Epoch 61/150, Loss: 0.6588034452823858\n",
      "Epoch 62/150, Loss: 0.6989423887673372\n",
      "Epoch 63/150, Loss: 0.6172795600609712\n",
      "Epoch 64/150, Loss: 0.5758764421943888\n",
      "Epoch 65/150, Loss: 0.5887808799393446\n",
      "Epoch 66/150, Loss: 0.6496932428660024\n",
      "Epoch 67/150, Loss: 0.6821572400277357\n",
      "Epoch 68/150, Loss: 0.5643704866321717\n",
      "Epoch 69/150, Loss: 0.524522828513566\n",
      "Epoch 70/150, Loss: 0.5687154966525043\n",
      "Epoch 71/150, Loss: 0.637347537878053\n",
      "Epoch 72/150, Loss: 0.6392659847780379\n",
      "Epoch 73/150, Loss: 0.6152523593299809\n",
      "Epoch 74/150, Loss: 0.7406966511641043\n",
      "Epoch 75/150, Loss: 0.6502233718212352\n",
      "Epoch 76/150, Loss: 0.5305944853483354\n",
      "Epoch 77/150, Loss: 0.5659025279528941\n",
      "Epoch 78/150, Loss: 0.46011968851286755\n",
      "Epoch 79/150, Loss: 0.7368903332726768\n",
      "Epoch 80/150, Loss: 0.5518571968338021\n",
      "Epoch 81/150, Loss: 0.5866331216451962\n",
      "Epoch 82/150, Loss: 0.5819056875742739\n",
      "Epoch 83/150, Loss: 0.6604909530345859\n",
      "Epoch 84/150, Loss: 0.5598824595399544\n",
      "Epoch 85/150, Loss: 0.548460729119308\n",
      "Epoch 86/150, Loss: 0.7388206532651151\n",
      "Epoch 87/150, Loss: 0.6812634041637239\n",
      "Epoch 88/150, Loss: 0.7558543142298286\n",
      "Epoch 89/150, Loss: 0.830876150166632\n",
      "Epoch 90/150, Loss: 0.8873874543331782\n",
      "Epoch 91/150, Loss: 0.5719251969561434\n",
      "Epoch 92/150, Loss: 0.7276143826944615\n",
      "Epoch 93/150, Loss: 0.5960786503447405\n",
      "Epoch 94/150, Loss: 0.6332695035722352\n",
      "Epoch 95/150, Loss: 0.7745077425032817\n",
      "Epoch 96/150, Loss: 0.8193677252314743\n",
      "Epoch 97/150, Loss: 0.7474329075755254\n",
      "Epoch 98/150, Loss: 0.64008892758197\n",
      "Epoch 99/150, Loss: 0.5001286229485794\n",
      "Epoch 100/150, Loss: 0.7065780925727572\n",
      "Epoch 101/150, Loss: 0.6928701734225668\n",
      "Epoch 102/150, Loss: 0.733431392345944\n",
      "Epoch 103/150, Loss: 0.6723679291922292\n",
      "Epoch 104/150, Loss: 0.5950909676925135\n",
      "Epoch 105/150, Loss: 0.6325601770210248\n",
      "Epoch 106/150, Loss: 0.6940165828017275\n",
      "Epoch 107/150, Loss: 0.5848694881449517\n",
      "Epoch 108/150, Loss: 0.7514800514041386\n",
      "Epoch 109/150, Loss: 0.5487142741786907\n",
      "Epoch 110/150, Loss: 0.7128559185864194\n",
      "Epoch 111/150, Loss: 0.6296668295974502\n",
      "Epoch 112/150, Loss: 0.6158925800042795\n",
      "Epoch 113/150, Loss: 0.582768222589966\n",
      "Epoch 114/150, Loss: 0.5983397617710903\n",
      "Epoch 115/150, Loss: 0.5084745304399305\n",
      "Epoch 116/150, Loss: 0.790555378836435\n",
      "Epoch 117/150, Loss: 0.7077514557510466\n",
      "Epoch 118/150, Loss: 0.6115513817407413\n",
      "Epoch 119/150, Loss: 0.4658827053991237\n",
      "Epoch 120/150, Loss: 0.624056299633742\n",
      "Epoch 121/150, Loss: 0.5837692589763301\n",
      "Epoch 122/150, Loss: 0.5467817557429396\n",
      "Epoch 123/150, Loss: 0.7196615098593807\n",
      "Epoch 124/150, Loss: 0.6361187398526746\n",
      "Epoch 125/150, Loss: 0.6550833745411859\n",
      "Epoch 126/150, Loss: 0.6751142550101173\n",
      "Epoch 127/150, Loss: 0.7641903080551391\n",
      "Epoch 128/150, Loss: 0.5582239974150416\n",
      "Epoch 129/150, Loss: 0.6979680494358315\n",
      "Epoch 130/150, Loss: 0.6125670530092658\n",
      "Epoch 131/150, Loss: 0.7258791568889149\n",
      "Epoch 132/150, Loss: 0.5644477810334405\n",
      "Epoch 133/150, Loss: 0.7263637718273602\n",
      "Epoch 134/150, Loss: 0.6129887664964145\n",
      "Epoch 135/150, Loss: 0.692497268693594\n",
      "Epoch 136/150, Loss: 0.47789386735804684\n",
      "Epoch 137/150, Loss: 0.5444755402646728\n",
      "Epoch 138/150, Loss: 0.7973233122087888\n",
      "Epoch 139/150, Loss: 0.539398807049671\n",
      "Epoch 140/150, Loss: 0.6178193283283568\n",
      "Epoch 141/150, Loss: 0.7726500839901944\n",
      "Epoch 142/150, Loss: 0.5814883635598985\n",
      "Epoch 143/150, Loss: 0.5362450845858128\n",
      "Epoch 144/150, Loss: 0.7935919785150917\n",
      "Epoch 145/150, Loss: 0.5925205901952685\n",
      "Epoch 146/150, Loss: 0.675300678389549\n",
      "Epoch 147/150, Loss: 0.449378218781155\n",
      "Epoch 148/150, Loss: 0.6812889480634421\n",
      "Epoch 149/150, Loss: 0.4371247404626082\n",
      "Epoch 150/150, Loss: 0.6443226544376607\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 82.99%'\n",
      "Epoch 1/50, Loss: 1.763484976048328\n",
      "Epoch 2/50, Loss: 1.4371618238669501\n",
      "Epoch 3/50, Loss: 1.357495736428529\n",
      "Epoch 4/50, Loss: 1.2349701014572703\n",
      "Epoch 5/50, Loss: 1.0621864019732354\n",
      "Epoch 6/50, Loss: 1.0269484579868584\n",
      "Epoch 7/50, Loss: 1.0420982564622625\n",
      "Epoch 8/50, Loss: 1.045117360524047\n",
      "Epoch 9/50, Loss: 1.0299489345253126\n",
      "Epoch 10/50, Loss: 1.036509882054808\n",
      "Epoch 11/50, Loss: 0.8191401715399966\n",
      "Epoch 12/50, Loss: 0.77674351407054\n",
      "Epoch 13/50, Loss: 0.8914742691269784\n",
      "Epoch 14/50, Loss: 0.8774642883206017\n",
      "Epoch 15/50, Loss: 0.8441857981351857\n",
      "Epoch 16/50, Loss: 0.8473986326221128\n",
      "Epoch 17/50, Loss: 0.7885531149873378\n",
      "Epoch 18/50, Loss: 0.7606470144755799\n",
      "Epoch 19/50, Loss: 0.7965503035242595\n",
      "Epoch 20/50, Loss: 0.8125020540580501\n",
      "Epoch 21/50, Loss: 0.7787094874220024\n",
      "Epoch 22/50, Loss: 0.8853985236234486\n",
      "Epoch 23/50, Loss: 0.8225485438499732\n",
      "Epoch 24/50, Loss: 0.8458735023365489\n",
      "Epoch 25/50, Loss: 0.784703377760855\n",
      "Epoch 26/50, Loss: 0.7842447650102363\n",
      "Epoch 27/50, Loss: 0.7947903933814638\n",
      "Epoch 28/50, Loss: 0.6979694192928825\n",
      "Epoch 29/50, Loss: 0.7091298349609849\n",
      "Epoch 30/50, Loss: 0.7114088944719803\n",
      "Epoch 31/50, Loss: 0.9018980730099618\n",
      "Epoch 32/50, Loss: 0.6664175865346426\n",
      "Epoch 33/50, Loss: 0.7066984675131792\n",
      "Epoch 34/50, Loss: 0.7388115648518583\n",
      "Epoch 35/50, Loss: 0.6286620049709096\n",
      "Epoch 36/50, Loss: 0.7045792429686963\n",
      "Epoch 37/50, Loss: 0.6467116690780769\n",
      "Epoch 38/50, Loss: 0.6958546403394258\n",
      "Epoch 39/50, Loss: 0.7014377738283752\n",
      "Epoch 40/50, Loss: 0.8179424382438422\n",
      "Epoch 41/50, Loss: 0.6945856405924602\n",
      "Epoch 42/50, Loss: 0.7338697503522049\n",
      "Epoch 43/50, Loss: 0.7690353479297765\n",
      "Epoch 44/50, Loss: 0.7703140287326157\n",
      "Epoch 45/50, Loss: 0.6476209620126814\n",
      "Epoch 46/50, Loss: 0.7804567221374262\n",
      "Epoch 47/50, Loss: 0.6701901336342692\n",
      "Epoch 48/50, Loss: 0.6074317101341289\n",
      "Epoch 49/50, Loss: 0.575095926010709\n",
      "Epoch 50/50, Loss: 0.755607291049301\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 79.64%'\n",
      "Epoch 1/100, Loss: 1.7251675319548148\n",
      "Epoch 2/100, Loss: 1.4637158102711432\n",
      "Epoch 3/100, Loss: 1.2532747504896389\n",
      "Epoch 4/100, Loss: 1.2105427640848296\n",
      "Epoch 5/100, Loss: 1.1195606173298382\n",
      "Epoch 6/100, Loss: 1.090944705017341\n",
      "Epoch 7/100, Loss: 0.8552038923025479\n",
      "Epoch 8/100, Loss: 0.8886732273730499\n",
      "Epoch 9/100, Loss: 0.860842466475901\n",
      "Epoch 10/100, Loss: 0.9264668027937139\n",
      "Epoch 11/100, Loss: 0.8975455771942862\n",
      "Epoch 12/100, Loss: 0.8664866546741294\n",
      "Epoch 13/100, Loss: 0.9200200262931154\n",
      "Epoch 14/100, Loss: 0.9385028462607274\n",
      "Epoch 15/100, Loss: 0.8017650308055476\n",
      "Epoch 16/100, Loss: 0.8000471905441061\n",
      "Epoch 17/100, Loss: 0.8264196815297665\n",
      "Epoch 18/100, Loss: 0.7724660288268542\n",
      "Epoch 19/100, Loss: 0.6920963303895322\n",
      "Epoch 20/100, Loss: 0.7729586690500688\n",
      "Epoch 21/100, Loss: 0.8570255571010648\n",
      "Epoch 22/100, Loss: 0.7609874470312261\n",
      "Epoch 23/100, Loss: 0.7961023055471266\n",
      "Epoch 24/100, Loss: 0.8411650041934148\n",
      "Epoch 25/100, Loss: 0.7593574727355011\n",
      "Epoch 26/100, Loss: 0.6959676607010327\n",
      "Epoch 27/100, Loss: 0.7947844704903121\n",
      "Epoch 28/100, Loss: 0.6647627251149807\n",
      "Epoch 29/100, Loss: 0.7340197539148645\n",
      "Epoch 30/100, Loss: 0.7618250434698477\n",
      "Epoch 31/100, Loss: 0.7161271076822028\n",
      "Epoch 32/100, Loss: 0.7515155884366123\n",
      "Epoch 33/100, Loss: 0.655084680637579\n",
      "Epoch 34/100, Loss: 0.6651203738007264\n",
      "Epoch 35/100, Loss: 0.7851288640347649\n",
      "Epoch 36/100, Loss: 0.7439912059865702\n",
      "Epoch 37/100, Loss: 0.6683990923791838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Loss: 0.681281605826537\n",
      "Epoch 39/100, Loss: 0.7346234397029672\n",
      "Epoch 40/100, Loss: 0.6877760963794066\n",
      "Epoch 41/100, Loss: 0.7673582927222028\n",
      "Epoch 42/100, Loss: 0.7263233227771748\n",
      "Epoch 43/100, Loss: 0.7171195696279704\n",
      "Epoch 44/100, Loss: 0.7423085614568428\n",
      "Epoch 45/100, Loss: 0.7854477950497356\n",
      "Epoch 46/100, Loss: 0.7092500758880841\n",
      "Epoch 47/100, Loss: 0.6981525364076315\n",
      "Epoch 48/100, Loss: 0.6819321137517558\n",
      "Epoch 49/100, Loss: 0.8120656550904435\n",
      "Epoch 50/100, Loss: 0.6333132220347178\n",
      "Epoch 51/100, Loss: 0.6906861535920124\n",
      "Epoch 52/100, Loss: 0.6805314891063771\n",
      "Epoch 53/100, Loss: 0.7615787971163979\n",
      "Epoch 54/100, Loss: 0.7988378297869205\n",
      "Epoch 55/100, Loss: 0.6718936553859481\n",
      "Epoch 56/100, Loss: 0.6515402324078259\n",
      "Epoch 57/100, Loss: 0.7277777758495623\n",
      "Epoch 58/100, Loss: 0.7565479069082708\n",
      "Epoch 59/100, Loss: 0.7141174162544708\n",
      "Epoch 60/100, Loss: 0.7429552205898726\n",
      "Epoch 61/100, Loss: 0.7713187251553081\n",
      "Epoch 62/100, Loss: 0.6376791206774522\n",
      "Epoch 63/100, Loss: 0.678184969504434\n",
      "Epoch 64/100, Loss: 0.7232821855827242\n",
      "Epoch 65/100, Loss: 0.6728033030382159\n",
      "Epoch 66/100, Loss: 0.8188131665403697\n",
      "Epoch 67/100, Loss: 0.7288614610308052\n",
      "Epoch 68/100, Loss: 0.6633750337414037\n",
      "Epoch 69/100, Loss: 0.6176516908683553\n",
      "Epoch 70/100, Loss: 0.5741218808815832\n",
      "Epoch 71/100, Loss: 0.7146967723432297\n",
      "Epoch 72/100, Loss: 0.7151505908400372\n",
      "Epoch 73/100, Loss: 0.5789355823182776\n",
      "Epoch 74/100, Loss: 0.6925784997954486\n",
      "Epoch 75/100, Loss: 0.5488188197236031\n",
      "Epoch 76/100, Loss: 0.6309647869108496\n",
      "Epoch 77/100, Loss: 0.7601205142305288\n",
      "Epoch 78/100, Loss: 0.7742399762497792\n",
      "Epoch 79/100, Loss: 0.615515259170126\n",
      "Epoch 80/100, Loss: 0.7350210760424979\n",
      "Epoch 81/100, Loss: 0.6537198498383185\n",
      "Epoch 82/100, Loss: 0.7271545242726263\n",
      "Epoch 83/100, Loss: 0.605357552506827\n",
      "Epoch 84/100, Loss: 0.6133952630423762\n",
      "Epoch 85/100, Loss: 0.7300787620983926\n",
      "Epoch 86/100, Loss: 0.6613306215219326\n",
      "Epoch 87/100, Loss: 0.6505489031282783\n",
      "Epoch 88/100, Loss: 0.5897019647837979\n",
      "Epoch 89/100, Loss: 0.695080830855048\n",
      "Epoch 90/100, Loss: 0.7018794299587595\n",
      "Epoch 91/100, Loss: 0.6511735750949297\n",
      "Epoch 92/100, Loss: 0.560131910266532\n",
      "Epoch 93/100, Loss: 0.6722133014261454\n",
      "Epoch 94/100, Loss: 0.733614521339603\n",
      "Epoch 95/100, Loss: 0.7319917401574962\n",
      "Epoch 96/100, Loss: 0.6393177815516924\n",
      "Epoch 97/100, Loss: 0.6706100951914916\n",
      "Epoch 98/100, Loss: 0.6364474217986723\n",
      "Epoch 99/100, Loss: 0.5435160614944992\n",
      "Epoch 100/100, Loss: 0.7695635597928303\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 81.26%'\n",
      "Epoch 1/150, Loss: 1.6696425660091538\n",
      "Epoch 2/150, Loss: 1.4262215738483284\n",
      "Epoch 3/150, Loss: 1.3121511229279965\n",
      "Epoch 4/150, Loss: 1.1462708252411151\n",
      "Epoch 5/150, Loss: 1.0881778737507395\n",
      "Epoch 6/150, Loss: 1.026179398618403\n",
      "Epoch 7/150, Loss: 0.9972715105305021\n",
      "Epoch 8/150, Loss: 1.001781077136746\n",
      "Epoch 9/150, Loss: 1.008430122478365\n",
      "Epoch 10/150, Loss: 0.9540758543439154\n",
      "Epoch 11/150, Loss: 0.8929070516388259\n",
      "Epoch 12/150, Loss: 0.7758623972466614\n",
      "Epoch 13/150, Loss: 0.9391786511749874\n",
      "Epoch 14/150, Loss: 0.9208127874215633\n",
      "Epoch 15/150, Loss: 0.8072440620904282\n",
      "Epoch 16/150, Loss: 0.8266744238587688\n",
      "Epoch 17/150, Loss: 0.8090888805173473\n",
      "Epoch 18/150, Loss: 0.812148366363855\n",
      "Epoch 19/150, Loss: 0.8382364961019143\n",
      "Epoch 20/150, Loss: 0.8444036141132202\n",
      "Epoch 21/150, Loss: 0.7286358948625344\n",
      "Epoch 22/150, Loss: 0.7441606377604876\n",
      "Epoch 23/150, Loss: 0.7268721305835859\n",
      "Epoch 24/150, Loss: 0.6817835781167603\n",
      "Epoch 25/150, Loss: 0.7849996050932423\n",
      "Epoch 26/150, Loss: 0.7787324665106702\n",
      "Epoch 27/150, Loss: 0.8148946931946291\n",
      "Epoch 28/150, Loss: 0.7825257576559651\n",
      "Epoch 29/150, Loss: 0.8554492952814414\n",
      "Epoch 30/150, Loss: 0.6752594342585203\n",
      "Epoch 31/150, Loss: 0.7974732421014293\n",
      "Epoch 32/150, Loss: 0.7960366600907164\n",
      "Epoch 33/150, Loss: 0.8537228898478625\n",
      "Epoch 34/150, Loss: 0.7437658464033472\n",
      "Epoch 35/150, Loss: 0.7517466479764198\n",
      "Epoch 36/150, Loss: 0.65592348097717\n",
      "Epoch 37/150, Loss: 0.6931952287567583\n",
      "Epoch 38/150, Loss: 0.6616778792948727\n",
      "Epoch 39/150, Loss: 0.724684338097185\n",
      "Epoch 40/150, Loss: 0.6862800898470297\n",
      "Epoch 41/150, Loss: 0.7321516567066182\n",
      "Epoch 42/150, Loss: 0.82026113052834\n",
      "Epoch 43/150, Loss: 0.7037221024565214\n",
      "Epoch 44/150, Loss: 0.7610119963802628\n",
      "Epoch 45/150, Loss: 0.7638432410308854\n",
      "Epoch 46/150, Loss: 0.748029998501524\n",
      "Epoch 47/150, Loss: 0.6898118127686755\n",
      "Epoch 48/150, Loss: 0.6359942993437042\n",
      "Epoch 49/150, Loss: 0.7844843754562827\n",
      "Epoch 50/150, Loss: 0.7479607703752809\n",
      "Epoch 51/150, Loss: 0.7257371444077497\n",
      "Epoch 52/150, Loss: 0.7606520429679418\n",
      "Epoch 53/150, Loss: 0.6208070654352076\n",
      "Epoch 54/150, Loss: 0.7248220058435815\n",
      "Epoch 55/150, Loss: 0.6618383004780857\n",
      "Epoch 56/150, Loss: 0.6657698660259976\n",
      "Epoch 57/150, Loss: 0.6230836946273766\n",
      "Epoch 58/150, Loss: 0.5756746415809174\n",
      "Epoch 59/150, Loss: 0.6631268802547265\n",
      "Epoch 60/150, Loss: 0.6405184568866045\n",
      "Epoch 61/150, Loss: 0.7888512245322782\n",
      "Epoch 62/150, Loss: 0.6843369235169201\n",
      "Epoch 63/150, Loss: 0.6865193845480017\n",
      "Epoch 64/150, Loss: 0.7625287387916426\n",
      "Epoch 65/150, Loss: 0.7217169087366294\n",
      "Epoch 66/150, Loss: 0.6627783085685791\n",
      "Epoch 67/150, Loss: 0.6278809162093903\n",
      "Epoch 68/150, Loss: 0.6372831165117909\n",
      "Epoch 69/150, Loss: 0.7110590049327707\n",
      "Epoch 70/150, Loss: 0.7142699792074813\n",
      "Epoch 71/150, Loss: 0.6340531041082607\n",
      "Epoch 72/150, Loss: 0.6343398587448108\n",
      "Epoch 73/150, Loss: 0.7424739956292189\n",
      "Epoch 74/150, Loss: 0.8256412904980194\n",
      "Epoch 75/150, Loss: 0.5921280651681602\n",
      "Epoch 76/150, Loss: 0.5928116017373796\n",
      "Epoch 77/150, Loss: 0.6464101469430789\n",
      "Epoch 78/150, Loss: 0.6632018369382394\n",
      "Epoch 79/150, Loss: 0.663976324558393\n",
      "Epoch 80/150, Loss: 0.7191679709461353\n",
      "Epoch 81/150, Loss: 0.5965791714345724\n",
      "Epoch 82/150, Loss: 0.8232301942265305\n",
      "Epoch 83/150, Loss: 0.6938898227341911\n",
      "Epoch 84/150, Loss: 0.5862434412617405\n",
      "Epoch 85/150, Loss: 0.6836687500433336\n",
      "Epoch 86/150, Loss: 0.7850523110093314\n",
      "Epoch 87/150, Loss: 0.608489323300988\n",
      "Epoch 88/150, Loss: 0.6719353563407693\n",
      "Epoch 89/150, Loss: 0.7640824455461688\n",
      "Epoch 90/150, Loss: 0.6559935703809825\n",
      "Epoch 91/150, Loss: 0.5317851812125006\n",
      "Epoch 92/150, Loss: 0.6398193423708058\n",
      "Epoch 93/150, Loss: 0.6264344276289142\n",
      "Epoch 94/150, Loss: 0.767951539883016\n",
      "Epoch 95/150, Loss: 0.7379768767399763\n",
      "Epoch 96/150, Loss: 0.6854764911366301\n",
      "Epoch 97/150, Loss: 0.7065602329915205\n",
      "Epoch 98/150, Loss: 0.7151075165823583\n",
      "Epoch 99/150, Loss: 0.6099164265571588\n",
      "Epoch 100/150, Loss: 0.6701281040299777\n",
      "Epoch 101/150, Loss: 0.6278246467948418\n",
      "Epoch 102/150, Loss: 0.5613015705720218\n",
      "Epoch 103/150, Loss: 0.5364855869934689\n",
      "Epoch 104/150, Loss: 0.6372203709729243\n",
      "Epoch 105/150, Loss: 0.5783585080150789\n",
      "Epoch 106/150, Loss: 0.5934301680591197\n",
      "Epoch 107/150, Loss: 0.6432041873458502\n",
      "Epoch 108/150, Loss: 0.585343146037091\n",
      "Epoch 109/150, Loss: 0.7868832805132244\n",
      "Epoch 110/150, Loss: 0.6497594336507537\n",
      "Epoch 111/150, Loss: 0.6915994495553607\n",
      "Epoch 112/150, Loss: 0.6741697430804517\n",
      "Epoch 113/150, Loss: 0.7073077960903956\n",
      "Epoch 114/150, Loss: 0.6096250287571032\n",
      "Epoch 115/150, Loss: 0.6579024915719632\n",
      "Epoch 116/150, Loss: 0.6954479254827146\n",
      "Epoch 117/150, Loss: 0.6241746254061592\n",
      "Epoch 118/150, Loss: 0.6714591687240551\n",
      "Epoch 119/150, Loss: 0.6235501476981474\n",
      "Epoch 120/150, Loss: 0.6707855902116042\n",
      "Epoch 121/150, Loss: 0.6320546990516044\n",
      "Epoch 122/150, Loss: 0.6463682673365597\n",
      "Epoch 123/150, Loss: 0.6204864708821364\n",
      "Epoch 124/150, Loss: 0.5286339710277437\n",
      "Epoch 125/150, Loss: 0.5976598332279114\n",
      "Epoch 126/150, Loss: 0.6923396476905757\n",
      "Epoch 127/150, Loss: 0.6205409269403707\n",
      "Epoch 128/150, Loss: 0.6924861968951144\n",
      "Epoch 129/150, Loss: 0.6613542092870733\n",
      "Epoch 130/150, Loss: 0.587000914367412\n",
      "Epoch 131/150, Loss: 0.6144037422175077\n",
      "Epoch 132/150, Loss: 0.7089388016536068\n",
      "Epoch 133/150, Loss: 0.6799730693841115\n",
      "Epoch 134/150, Loss: 0.5972441483893443\n",
      "Epoch 135/150, Loss: 0.5785304850789356\n",
      "Epoch 136/150, Loss: 0.6704322856574335\n",
      "Epoch 137/150, Loss: 0.6900879746085332\n",
      "Epoch 138/150, Loss: 0.6411543399473697\n",
      "Epoch 139/150, Loss: 0.509804344176071\n",
      "Epoch 140/150, Loss: 0.6462738153177746\n",
      "Epoch 141/150, Loss: 0.53644187619652\n",
      "Epoch 142/150, Loss: 0.7137214611898868\n",
      "Epoch 143/150, Loss: 0.7179314214730645\n",
      "Epoch 144/150, Loss: 0.6463444487093026\n",
      "Epoch 145/150, Loss: 0.5508439030844062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150, Loss: 0.6867540211530659\n",
      "Epoch 147/150, Loss: 0.5659690013699947\n",
      "Epoch 148/150, Loss: 0.6480630462897573\n",
      "Epoch 149/150, Loss: 0.6300698466972162\n",
      "Epoch 150/150, Loss: 0.5744832351224538\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.001, Alpha 0.01, f'Test accuracy: 82.07%'\n",
      "Epoch 1/50, Loss: 1.396606668293494\n",
      "Epoch 2/50, Loss: 1.0211662054417157\n",
      "Epoch 3/50, Loss: 1.3647667783393465\n",
      "Epoch 4/50, Loss: 1.2618881545281493\n",
      "Epoch 5/50, Loss: 0.9614577673772362\n",
      "Epoch 6/50, Loss: 0.9289285891579142\n",
      "Epoch 7/50, Loss: 1.0756628936546782\n",
      "Epoch 8/50, Loss: 0.9694905031885689\n",
      "Epoch 9/50, Loss: 0.9470050786064792\n",
      "Epoch 10/50, Loss: 1.2468808111996137\n",
      "Epoch 11/50, Loss: 1.1498165458364897\n",
      "Epoch 12/50, Loss: 0.9634213712981914\n",
      "Epoch 13/50, Loss: 1.0408672445174412\n",
      "Epoch 14/50, Loss: 1.143007929150849\n",
      "Epoch 15/50, Loss: 0.9460937313984974\n",
      "Epoch 16/50, Loss: 0.8463883901273968\n",
      "Epoch 17/50, Loss: 1.0220308253564205\n",
      "Epoch 18/50, Loss: 1.2251803616870591\n",
      "Epoch 19/50, Loss: 0.7720648583645081\n",
      "Epoch 20/50, Loss: 1.0628817351250661\n",
      "Epoch 21/50, Loss: 1.3319347119872953\n",
      "Epoch 22/50, Loss: 1.0424495976563284\n",
      "Epoch 23/50, Loss: 0.835825830423404\n",
      "Epoch 24/50, Loss: 1.1664499325593014\n",
      "Epoch 25/50, Loss: 1.097979512665667\n",
      "Epoch 26/50, Loss: 0.9862522026890488\n",
      "Epoch 27/50, Loss: 0.918228786977097\n",
      "Epoch 28/50, Loss: 0.9905178889063834\n",
      "Epoch 29/50, Loss: 0.9924245947972677\n",
      "Epoch 30/50, Loss: 0.8655330673725741\n",
      "Epoch 31/50, Loss: 1.1907953601121593\n",
      "Epoch 32/50, Loss: 0.7680442097861915\n",
      "Epoch 33/50, Loss: 1.1478008646594169\n",
      "Epoch 34/50, Loss: 1.1605274071473923\n",
      "Epoch 35/50, Loss: 0.9994177527801756\n",
      "Epoch 36/50, Loss: 1.0776306512903495\n",
      "Epoch 37/50, Loss: 1.037222800230539\n",
      "Epoch 38/50, Loss: 1.0029612150383078\n",
      "Epoch 39/50, Loss: 0.9964898950486304\n",
      "Epoch 40/50, Loss: 0.8803395724520451\n",
      "Epoch 41/50, Loss: 1.1530219797267443\n",
      "Epoch 42/50, Loss: 1.1715906387638764\n",
      "Epoch 43/50, Loss: 1.0718470523599275\n",
      "Epoch 44/50, Loss: 1.1865084864739737\n",
      "Epoch 45/50, Loss: 0.9386405567778352\n",
      "Epoch 46/50, Loss: 1.1797754588353837\n",
      "Epoch 47/50, Loss: 0.9968845557209587\n",
      "Epoch 48/50, Loss: 1.109052549418321\n",
      "Epoch 49/50, Loss: 0.9946744306663047\n",
      "Epoch 50/50, Loss: 0.9693437873282222\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.95%'\n",
      "Epoch 1/100, Loss: 1.2305162345682834\n",
      "Epoch 2/100, Loss: 1.195536163186128\n",
      "Epoch 3/100, Loss: 1.1244373974623891\n",
      "Epoch 4/100, Loss: 1.0398071631973105\n",
      "Epoch 5/100, Loss: 1.0763042230168511\n",
      "Epoch 6/100, Loss: 1.0746624233901043\n",
      "Epoch 7/100, Loss: 1.2694338972225054\n",
      "Epoch 8/100, Loss: 1.0569316036745\n",
      "Epoch 9/100, Loss: 1.1943568853365383\n",
      "Epoch 10/100, Loss: 1.3434367605776896\n",
      "Epoch 11/100, Loss: 0.9511812362119222\n",
      "Epoch 12/100, Loss: 1.2661303399746746\n",
      "Epoch 13/100, Loss: 1.0813337482493213\n",
      "Epoch 14/100, Loss: 1.0029712990650108\n",
      "Epoch 15/100, Loss: 0.9418265375536554\n",
      "Epoch 16/100, Loss: 1.1232045970384337\n",
      "Epoch 17/100, Loss: 1.0662310434659443\n",
      "Epoch 18/100, Loss: 0.8655876739437989\n",
      "Epoch 19/100, Loss: 1.2940304877097444\n",
      "Epoch 20/100, Loss: 1.0125259412345229\n",
      "Epoch 21/100, Loss: 0.9785804186992042\n",
      "Epoch 22/100, Loss: 1.0228964984503783\n",
      "Epoch 23/100, Loss: 1.005407489396856\n",
      "Epoch 24/100, Loss: 1.0054624558682237\n",
      "Epoch 25/100, Loss: 0.9382872543168704\n",
      "Epoch 26/100, Loss: 1.118561939803521\n",
      "Epoch 27/100, Loss: 1.0325895944932815\n",
      "Epoch 28/100, Loss: 1.0560883988041685\n",
      "Epoch 29/100, Loss: 0.96389525269577\n",
      "Epoch 30/100, Loss: 0.8436707706624623\n",
      "Epoch 31/100, Loss: 1.1166124653621918\n",
      "Epoch 32/100, Loss: 0.8040501142734511\n",
      "Epoch 33/100, Loss: 1.0916936567015578\n",
      "Epoch 34/100, Loss: 0.9918021960744516\n",
      "Epoch 35/100, Loss: 1.0623152288089963\n",
      "Epoch 36/100, Loss: 1.012592926039078\n",
      "Epoch 37/100, Loss: 0.9665126512067668\n",
      "Epoch 38/100, Loss: 1.1817941623936574\n",
      "Epoch 39/100, Loss: 1.0433009598062226\n",
      "Epoch 40/100, Loss: 1.0272344091785786\n",
      "Epoch 41/100, Loss: 1.242479581765141\n",
      "Epoch 42/100, Loss: 1.1421131000867735\n",
      "Epoch 43/100, Loss: 1.0328410754086064\n",
      "Epoch 44/100, Loss: 1.121064522766699\n",
      "Epoch 45/100, Loss: 0.9396006722940402\n",
      "Epoch 46/100, Loss: 0.975948797391013\n",
      "Epoch 47/100, Loss: 0.9734315775546393\n",
      "Epoch 48/100, Loss: 1.0773380357951894\n",
      "Epoch 49/100, Loss: 1.1630161860494512\n",
      "Epoch 50/100, Loss: 1.0125928299517915\n",
      "Epoch 51/100, Loss: 0.9805332883198951\n",
      "Epoch 52/100, Loss: 1.0513947631819667\n",
      "Epoch 53/100, Loss: 0.897071860797956\n",
      "Epoch 54/100, Loss: 1.0282398638535817\n",
      "Epoch 55/100, Loss: 0.9962090102413247\n",
      "Epoch 56/100, Loss: 0.862224309928647\n",
      "Epoch 57/100, Loss: 1.13536281014693\n",
      "Epoch 58/100, Loss: 1.0704479246134508\n",
      "Epoch 59/100, Loss: 0.8288706421506451\n",
      "Epoch 60/100, Loss: 0.9128858002555321\n",
      "Epoch 61/100, Loss: 0.9032528452205004\n",
      "Epoch 62/100, Loss: 1.005611025410086\n",
      "Epoch 63/100, Loss: 1.16289729968336\n",
      "Epoch 64/100, Loss: 1.220209657995197\n",
      "Epoch 65/100, Loss: 1.0319634865999738\n",
      "Epoch 66/100, Loss: 0.9806173066394002\n",
      "Epoch 67/100, Loss: 1.138661426862336\n",
      "Epoch 68/100, Loss: 0.8358926070390873\n",
      "Epoch 69/100, Loss: 1.0769666775039686\n",
      "Epoch 70/100, Loss: 0.989108422006166\n",
      "Epoch 71/100, Loss: 1.0487866197790083\n",
      "Epoch 72/100, Loss: 0.9223632378033627\n",
      "Epoch 73/100, Loss: 1.1964543669566856\n",
      "Epoch 74/100, Loss: 1.066012613174604\n",
      "Epoch 75/100, Loss: 1.1794208705590146\n",
      "Epoch 76/100, Loss: 1.1297568961782471\n",
      "Epoch 77/100, Loss: 1.0463396573335848\n",
      "Epoch 78/100, Loss: 1.0038771014486654\n",
      "Epoch 79/100, Loss: 0.9511891996994255\n",
      "Epoch 80/100, Loss: 0.7639499988447735\n",
      "Epoch 81/100, Loss: 0.9900017176050283\n",
      "Epoch 82/100, Loss: 0.9299409444795323\n",
      "Epoch 83/100, Loss: 0.8281241930038228\n",
      "Epoch 84/100, Loss: 0.9180155967893618\n",
      "Epoch 85/100, Loss: 1.040513629665765\n",
      "Epoch 86/100, Loss: 0.9138508655144706\n",
      "Epoch 87/100, Loss: 0.9294335822196936\n",
      "Epoch 88/100, Loss: 0.9365955502588501\n",
      "Epoch 89/100, Loss: 1.1695885870029894\n",
      "Epoch 90/100, Loss: 1.148478212696669\n",
      "Epoch 91/100, Loss: 1.149698991967346\n",
      "Epoch 92/100, Loss: 1.1237900573994812\n",
      "Epoch 93/100, Loss: 0.8251514685705207\n",
      "Epoch 94/100, Loss: 0.9290624510450639\n",
      "Epoch 95/100, Loss: 1.010463484152846\n",
      "Epoch 96/100, Loss: 0.9956677561711793\n",
      "Epoch 97/100, Loss: 1.1577452132006867\n",
      "Epoch 98/100, Loss: 0.9958625354539696\n",
      "Epoch 99/100, Loss: 0.8672788969291849\n",
      "Epoch 100/100, Loss: 1.188308303430918\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.03%'\n",
      "Epoch 1/150, Loss: 1.1304794281703987\n",
      "Epoch 2/150, Loss: 1.1850978345965468\n",
      "Epoch 3/150, Loss: 0.9812810260408431\n",
      "Epoch 4/150, Loss: 1.1164562760837746\n",
      "Epoch 5/150, Loss: 1.1301857450219253\n",
      "Epoch 6/150, Loss: 1.1429765368132658\n",
      "Epoch 7/150, Loss: 1.0771603127844762\n",
      "Epoch 8/150, Loss: 0.8196128637489216\n",
      "Epoch 9/150, Loss: 1.1136213724529014\n",
      "Epoch 10/150, Loss: 0.9264128252457959\n",
      "Epoch 11/150, Loss: 1.0617410679212582\n",
      "Epoch 12/150, Loss: 1.2145601800248196\n",
      "Epoch 13/150, Loss: 0.9950573292660939\n",
      "Epoch 14/150, Loss: 1.0407469661886748\n",
      "Epoch 15/150, Loss: 1.199043757249132\n",
      "Epoch 16/150, Loss: 0.7976766284445451\n",
      "Epoch 17/150, Loss: 0.9690898790356695\n",
      "Epoch 18/150, Loss: 1.0585529066127697\n",
      "Epoch 19/150, Loss: 0.9093586622542793\n",
      "Epoch 20/150, Loss: 1.0535484595815376\n",
      "Epoch 21/150, Loss: 0.9056379067878916\n",
      "Epoch 22/150, Loss: 1.0882804695507167\n",
      "Epoch 23/150, Loss: 1.1012257729902872\n",
      "Epoch 24/150, Loss: 0.9528973891450828\n",
      "Epoch 25/150, Loss: 1.2034951666777518\n",
      "Epoch 26/150, Loss: 1.245339360979687\n",
      "Epoch 27/150, Loss: 1.0560445492994461\n",
      "Epoch 28/150, Loss: 1.1090880551144928\n",
      "Epoch 29/150, Loss: 1.1663324764639738\n",
      "Epoch 30/150, Loss: 0.8858949781890431\n",
      "Epoch 31/150, Loss: 0.9285674626800189\n",
      "Epoch 32/150, Loss: 1.0258412834746773\n",
      "Epoch 33/150, Loss: 0.9605991900966521\n",
      "Epoch 34/150, Loss: 0.8946421765753108\n",
      "Epoch 35/150, Loss: 0.899819167302314\n",
      "Epoch 36/150, Loss: 0.9471514512441533\n",
      "Epoch 37/150, Loss: 1.0235097088587966\n",
      "Epoch 38/150, Loss: 1.087222779699233\n",
      "Epoch 39/150, Loss: 1.1570701572871296\n",
      "Epoch 40/150, Loss: 1.1262398474051285\n",
      "Epoch 41/150, Loss: 0.9271245667484269\n",
      "Epoch 42/150, Loss: 1.0137545173995675\n",
      "Epoch 43/150, Loss: 1.1512909136551845\n",
      "Epoch 44/150, Loss: 1.154927834838928\n",
      "Epoch 45/150, Loss: 0.9375745987439166\n",
      "Epoch 46/150, Loss: 0.9451931152812585\n",
      "Epoch 47/150, Loss: 1.0100875644239804\n",
      "Epoch 48/150, Loss: 0.9650831467697237\n",
      "Epoch 49/150, Loss: 1.0972554111995678\n",
      "Epoch 50/150, Loss: 1.177744682177634\n",
      "Epoch 51/150, Loss: 1.1745282791949785\n",
      "Epoch 52/150, Loss: 0.8644466914587421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150, Loss: 0.916006447335272\n",
      "Epoch 54/150, Loss: 1.0876775977661925\n",
      "Epoch 55/150, Loss: 0.9642139747627675\n",
      "Epoch 56/150, Loss: 1.0703287703505397\n",
      "Epoch 57/150, Loss: 1.1411191089541626\n",
      "Epoch 58/150, Loss: 1.1173650605835461\n",
      "Epoch 59/150, Loss: 0.9277337609851326\n",
      "Epoch 60/150, Loss: 1.1002379615866056\n",
      "Epoch 61/150, Loss: 0.8486322292430672\n",
      "Epoch 62/150, Loss: 1.0490302236736724\n",
      "Epoch 63/150, Loss: 0.9700090610975456\n",
      "Epoch 64/150, Loss: 1.0668589025974935\n",
      "Epoch 65/150, Loss: 0.9617277979155741\n",
      "Epoch 66/150, Loss: 1.0114958279152748\n",
      "Epoch 67/150, Loss: 0.8978876996869442\n",
      "Epoch 68/150, Loss: 0.8648031626466732\n",
      "Epoch 69/150, Loss: 1.1949555155076732\n",
      "Epoch 70/150, Loss: 0.9033743587612411\n",
      "Epoch 71/150, Loss: 0.948110917760234\n",
      "Epoch 72/150, Loss: 1.0171509666037448\n",
      "Epoch 73/150, Loss: 0.9831849734741982\n",
      "Epoch 74/150, Loss: 0.9701113910553791\n",
      "Epoch 75/150, Loss: 0.9531689229447198\n",
      "Epoch 76/150, Loss: 0.904648359493764\n",
      "Epoch 77/150, Loss: 0.9372952260344316\n",
      "Epoch 78/150, Loss: 1.0990528313035892\n",
      "Epoch 79/150, Loss: 0.9510898444133693\n",
      "Epoch 80/150, Loss: 1.0655060417941875\n",
      "Epoch 81/150, Loss: 0.9196030782473686\n",
      "Epoch 82/150, Loss: 1.1781039524970924\n",
      "Epoch 83/150, Loss: 0.9836028445353971\n",
      "Epoch 84/150, Loss: 0.8314119806688485\n",
      "Epoch 85/150, Loss: 0.9210176635794067\n",
      "Epoch 86/150, Loss: 0.992095633147278\n",
      "Epoch 87/150, Loss: 0.9807298199910546\n",
      "Epoch 88/150, Loss: 1.1596509532596626\n",
      "Epoch 89/150, Loss: 1.1416489511189776\n",
      "Epoch 90/150, Loss: 0.9348516831429152\n",
      "Epoch 91/150, Loss: 1.107581104399202\n",
      "Epoch 92/150, Loss: 0.9705086845641526\n",
      "Epoch 93/150, Loss: 0.9121489015660178\n",
      "Epoch 94/150, Loss: 1.0455941560754498\n",
      "Epoch 95/150, Loss: 1.021785800287609\n",
      "Epoch 96/150, Loss: 1.2471084333843634\n",
      "Epoch 97/150, Loss: 0.9415209649737704\n",
      "Epoch 98/150, Loss: 0.8104821753647278\n",
      "Epoch 99/150, Loss: 0.9026538814673055\n",
      "Epoch 100/150, Loss: 1.2157211241326258\n",
      "Epoch 101/150, Loss: 1.0902819213487676\n",
      "Epoch 102/150, Loss: 1.2367716046702373\n",
      "Epoch 103/150, Loss: 0.9865702210201114\n",
      "Epoch 104/150, Loss: 1.0086303907235035\n",
      "Epoch 105/150, Loss: 1.0714800947466077\n",
      "Epoch 106/150, Loss: 0.9900944118945294\n",
      "Epoch 107/150, Loss: 0.9874046801262668\n",
      "Epoch 108/150, Loss: 0.9072769638447871\n",
      "Epoch 109/150, Loss: 0.9086371633016423\n",
      "Epoch 110/150, Loss: 1.0460699963332507\n",
      "Epoch 111/150, Loss: 1.1482372969345829\n",
      "Epoch 112/150, Loss: 0.8364512482310126\n",
      "Epoch 113/150, Loss: 0.8408592228435415\n",
      "Epoch 114/150, Loss: 1.024281576645862\n",
      "Epoch 115/150, Loss: 1.0347665100354897\n",
      "Epoch 116/150, Loss: 0.8559130583669293\n",
      "Epoch 117/150, Loss: 1.0225535902320195\n",
      "Epoch 118/150, Loss: 0.9994456751106431\n",
      "Epoch 119/150, Loss: 0.9674249401856791\n",
      "Epoch 120/150, Loss: 0.9459626260048468\n",
      "Epoch 121/150, Loss: 0.9386586534482596\n",
      "Epoch 122/150, Loss: 1.0794244091841598\n",
      "Epoch 123/150, Loss: 0.9945211582810283\n",
      "Epoch 124/150, Loss: 0.8493555121574674\n",
      "Epoch 125/150, Loss: 0.9196345541503668\n",
      "Epoch 126/150, Loss: 1.3563747308429326\n",
      "Epoch 127/150, Loss: 1.0461910660903568\n",
      "Epoch 128/150, Loss: 1.199717925459371\n",
      "Epoch 129/150, Loss: 1.050691297337945\n",
      "Epoch 130/150, Loss: 0.9405739500563586\n",
      "Epoch 131/150, Loss: 0.9865131095109052\n",
      "Epoch 132/150, Loss: 0.9455480309661825\n",
      "Epoch 133/150, Loss: 0.9777341357295685\n",
      "Epoch 134/150, Loss: 0.7891845316339692\n",
      "Epoch 135/150, Loss: 0.8680055033055043\n",
      "Epoch 136/150, Loss: 0.9211509469763706\n",
      "Epoch 137/150, Loss: 0.9140484053408212\n",
      "Epoch 138/150, Loss: 0.87815170956402\n",
      "Epoch 139/150, Loss: 0.9892767142772975\n",
      "Epoch 140/150, Loss: 1.0021246349755477\n",
      "Epoch 141/150, Loss: 0.7619704647229915\n",
      "Epoch 142/150, Loss: 0.987597541216396\n",
      "Epoch 143/150, Loss: 0.9519721386154921\n",
      "Epoch 144/150, Loss: 0.9022827824898908\n",
      "Epoch 145/150, Loss: 1.1585426545286457\n",
      "Epoch 146/150, Loss: 0.8778876785765414\n",
      "Epoch 147/150, Loss: 1.0073167993153316\n",
      "Epoch 148/150, Loss: 0.8979771086676158\n",
      "Epoch 149/150, Loss: 1.1785421696591596\n",
      "Epoch 150/150, Loss: 1.023298813986897\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 77.85%'\n",
      "Epoch 1/50, Loss: 1.5953600945016078\n",
      "Epoch 2/50, Loss: 1.365865778092158\n",
      "Epoch 3/50, Loss: 1.190935600549766\n",
      "Epoch 4/50, Loss: 1.1447259770242022\n",
      "Epoch 5/50, Loss: 1.1238165502169477\n",
      "Epoch 6/50, Loss: 1.052385518567201\n",
      "Epoch 7/50, Loss: 1.189070258723784\n",
      "Epoch 8/50, Loss: 0.9555056022620441\n",
      "Epoch 9/50, Loss: 0.9829895547189371\n",
      "Epoch 10/50, Loss: 1.065330540846226\n",
      "Epoch 11/50, Loss: 0.9800580624721806\n",
      "Epoch 12/50, Loss: 0.9546460885872246\n",
      "Epoch 13/50, Loss: 1.0002428457540367\n",
      "Epoch 14/50, Loss: 1.021196539028934\n",
      "Epoch 15/50, Loss: 1.0650852456532371\n",
      "Epoch 16/50, Loss: 1.0644008256705177\n",
      "Epoch 17/50, Loss: 0.9985076440681386\n",
      "Epoch 18/50, Loss: 0.9846177361047639\n",
      "Epoch 19/50, Loss: 1.0479042057435795\n",
      "Epoch 20/50, Loss: 1.0720597963188567\n",
      "Epoch 21/50, Loss: 1.1452500677989914\n",
      "Epoch 22/50, Loss: 0.9942695473203403\n",
      "Epoch 23/50, Loss: 0.9093315001176204\n",
      "Epoch 24/50, Loss: 0.91228388818158\n",
      "Epoch 25/50, Loss: 0.9799338157031893\n",
      "Epoch 26/50, Loss: 1.0631024600875498\n",
      "Epoch 27/50, Loss: 1.062806476885736\n",
      "Epoch 28/50, Loss: 1.0713293496671659\n",
      "Epoch 29/50, Loss: 0.9813454085349106\n",
      "Epoch 30/50, Loss: 1.127829265812075\n",
      "Epoch 31/50, Loss: 1.0292300734395294\n",
      "Epoch 32/50, Loss: 1.065076460446331\n",
      "Epoch 33/50, Loss: 0.9299336564911089\n",
      "Epoch 34/50, Loss: 1.0943260533360104\n",
      "Epoch 35/50, Loss: 1.0122047666833978\n",
      "Epoch 36/50, Loss: 1.0104481665557974\n",
      "Epoch 37/50, Loss: 1.1213160498166816\n",
      "Epoch 38/50, Loss: 1.007140357106873\n",
      "Epoch 39/50, Loss: 0.9969864659483183\n",
      "Epoch 40/50, Loss: 0.9985468580839931\n",
      "Epoch 41/50, Loss: 1.141832995576912\n",
      "Epoch 42/50, Loss: 1.0573611957059008\n",
      "Epoch 43/50, Loss: 1.1417166345489085\n",
      "Epoch 44/50, Loss: 1.0613401028853482\n",
      "Epoch 45/50, Loss: 1.1149723321139242\n",
      "Epoch 46/50, Loss: 1.0683386379733757\n",
      "Epoch 47/50, Loss: 0.894173870151111\n",
      "Epoch 48/50, Loss: 0.9968916417846083\n",
      "Epoch 49/50, Loss: 1.0937115742178127\n",
      "Epoch 50/50, Loss: 0.9972344073175918\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.72%'\n",
      "Epoch 1/100, Loss: 1.5222401203751803\n",
      "Epoch 2/100, Loss: 1.2374796785020594\n",
      "Epoch 3/100, Loss: 1.2305877804322942\n",
      "Epoch 4/100, Loss: 1.218409673039139\n",
      "Epoch 5/100, Loss: 1.1031687163163235\n",
      "Epoch 6/100, Loss: 1.131843779164225\n",
      "Epoch 7/100, Loss: 1.137472677174466\n",
      "Epoch 8/100, Loss: 1.0877773229281962\n",
      "Epoch 9/100, Loss: 1.2380763805860322\n",
      "Epoch 10/100, Loss: 1.2459272624254727\n",
      "Epoch 11/100, Loss: 1.1409925414320823\n",
      "Epoch 12/100, Loss: 1.0966725600421916\n",
      "Epoch 13/100, Loss: 1.1434312360405465\n",
      "Epoch 14/100, Loss: 1.244605400451829\n",
      "Epoch 15/100, Loss: 0.9819709735360599\n",
      "Epoch 16/100, Loss: 0.9215416062773611\n",
      "Epoch 17/100, Loss: 1.0321909382161243\n",
      "Epoch 18/100, Loss: 1.1224010379963378\n",
      "Epoch 19/100, Loss: 1.0294608208745264\n",
      "Epoch 20/100, Loss: 1.1456208731543713\n",
      "Epoch 21/100, Loss: 1.1084507951228635\n",
      "Epoch 22/100, Loss: 1.0814762273419234\n",
      "Epoch 23/100, Loss: 1.033693877488168\n",
      "Epoch 24/100, Loss: 0.9794374128056695\n",
      "Epoch 25/100, Loss: 1.0751269040454197\n",
      "Epoch 26/100, Loss: 0.9668097871859136\n",
      "Epoch 27/100, Loss: 1.0064312786874425\n",
      "Epoch 28/100, Loss: 1.0650364227201294\n",
      "Epoch 29/100, Loss: 1.0150976868673234\n",
      "Epoch 30/100, Loss: 0.9859286062076462\n",
      "Epoch 31/100, Loss: 1.0569135435207246\n",
      "Epoch 32/100, Loss: 0.9191713966098443\n",
      "Epoch 33/100, Loss: 1.063592145614383\n",
      "Epoch 34/100, Loss: 1.0382941122160303\n",
      "Epoch 35/100, Loss: 0.9534316063540532\n",
      "Epoch 36/100, Loss: 1.0015902555942422\n",
      "Epoch 37/100, Loss: 1.1675081216474523\n",
      "Epoch 38/100, Loss: 1.065911666719781\n",
      "Epoch 39/100, Loss: 1.1381017854332547\n",
      "Epoch 40/100, Loss: 0.9445781548092138\n",
      "Epoch 41/100, Loss: 1.016769155296855\n",
      "Epoch 42/100, Loss: 0.8758940216191322\n",
      "Epoch 43/100, Loss: 1.027772551105091\n",
      "Epoch 44/100, Loss: 1.0503490234944133\n",
      "Epoch 45/100, Loss: 0.9809589130842965\n",
      "Epoch 46/100, Loss: 0.9204347979873655\n",
      "Epoch 47/100, Loss: 1.1318032154749733\n",
      "Epoch 48/100, Loss: 1.0724600719172253\n",
      "Epoch 49/100, Loss: 0.9819885442171848\n",
      "Epoch 50/100, Loss: 1.0242326202287813\n",
      "Epoch 51/100, Loss: 1.093884517726507\n",
      "Epoch 52/100, Loss: 0.9527677355683004\n",
      "Epoch 53/100, Loss: 1.1516851537059984\n",
      "Epoch 54/100, Loss: 1.2249986500884722\n",
      "Epoch 55/100, Loss: 1.068917548556085\n",
      "Epoch 56/100, Loss: 1.2252405089774423\n",
      "Epoch 57/100, Loss: 1.0092206868515783\n",
      "Epoch 58/100, Loss: 1.0441245195062132\n",
      "Epoch 59/100, Loss: 1.0510970921673852\n",
      "Epoch 60/100, Loss: 0.9581609873867339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Loss: 0.9897484748252086\n",
      "Epoch 62/100, Loss: 1.1177286100519686\n",
      "Epoch 63/100, Loss: 1.0368126967654439\n",
      "Epoch 64/100, Loss: 1.0931131193489243\n",
      "Epoch 65/100, Loss: 1.079251281965746\n",
      "Epoch 66/100, Loss: 0.9619222882020467\n",
      "Epoch 67/100, Loss: 1.0819525998685393\n",
      "Epoch 68/100, Loss: 0.9190299710526884\n",
      "Epoch 69/100, Loss: 0.9983294345254072\n",
      "Epoch 70/100, Loss: 0.9888063845581448\n",
      "Epoch 71/100, Loss: 0.9943093337444547\n",
      "Epoch 72/100, Loss: 0.991619264578165\n",
      "Epoch 73/100, Loss: 1.00488186481899\n",
      "Epoch 74/100, Loss: 1.0921211514619784\n",
      "Epoch 75/100, Loss: 1.0816231521317898\n",
      "Epoch 76/100, Loss: 0.973490274130999\n",
      "Epoch 77/100, Loss: 0.8887202513428449\n",
      "Epoch 78/100, Loss: 1.1780416936599871\n",
      "Epoch 79/100, Loss: 1.0299891833070407\n",
      "Epoch 80/100, Loss: 0.916508273428433\n",
      "Epoch 81/100, Loss: 0.9579377423024609\n",
      "Epoch 82/100, Loss: 1.0331495633580239\n",
      "Epoch 83/100, Loss: 0.910669501437311\n",
      "Epoch 84/100, Loss: 0.9360200118627505\n",
      "Epoch 85/100, Loss: 1.035029427325375\n",
      "Epoch 86/100, Loss: 0.9146742809812562\n",
      "Epoch 87/100, Loss: 1.0980941047893893\n",
      "Epoch 88/100, Loss: 1.1020805647746899\n",
      "Epoch 89/100, Loss: 0.9888584037659661\n",
      "Epoch 90/100, Loss: 0.8959852039695662\n",
      "Epoch 91/100, Loss: 0.9452553984770021\n",
      "Epoch 92/100, Loss: 1.111865085704596\n",
      "Epoch 93/100, Loss: 0.8790405959979167\n",
      "Epoch 94/100, Loss: 0.9975361090612676\n",
      "Epoch 95/100, Loss: 1.0425356703123578\n",
      "Epoch 96/100, Loss: 0.9320178537850562\n",
      "Epoch 97/100, Loss: 1.0027112077341516\n",
      "Epoch 98/100, Loss: 1.1102058483773922\n",
      "Epoch 99/100, Loss: 1.0372977687341516\n",
      "Epoch 100/100, Loss: 0.9220610911755368\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.87%'\n",
      "Epoch 1/150, Loss: 1.6183243137055563\n",
      "Epoch 2/150, Loss: 1.257437719709028\n",
      "Epoch 3/150, Loss: 1.0758215287665773\n",
      "Epoch 4/150, Loss: 1.1490544001456338\n",
      "Epoch 5/150, Loss: 1.1198208884601741\n",
      "Epoch 6/150, Loss: 1.0571947821747072\n",
      "Epoch 7/150, Loss: 1.135920281190917\n",
      "Epoch 8/150, Loss: 1.141438802420747\n",
      "Epoch 9/150, Loss: 1.1962783895472744\n",
      "Epoch 10/150, Loss: 1.141454317393331\n",
      "Epoch 11/150, Loss: 0.9847350260321392\n",
      "Epoch 12/150, Loss: 1.1267932581793816\n",
      "Epoch 13/150, Loss: 1.0537584448987456\n",
      "Epoch 14/150, Loss: 1.0878340859986626\n",
      "Epoch 15/150, Loss: 1.0786206728083103\n",
      "Epoch 16/150, Loss: 1.239525449995466\n",
      "Epoch 17/150, Loss: 1.0866301129831037\n",
      "Epoch 18/150, Loss: 1.136521542243728\n",
      "Epoch 19/150, Loss: 1.1040308554047997\n",
      "Epoch 20/150, Loss: 0.9195122060048966\n",
      "Epoch 21/150, Loss: 1.2485204645192138\n",
      "Epoch 22/150, Loss: 1.0153607048423274\n",
      "Epoch 23/150, Loss: 1.0112655693499888\n",
      "Epoch 24/150, Loss: 1.1372090820735128\n",
      "Epoch 25/150, Loss: 1.0626215718562628\n",
      "Epoch 26/150, Loss: 1.0990073245745673\n",
      "Epoch 27/150, Loss: 1.1221529800680374\n",
      "Epoch 28/150, Loss: 1.1606580733086467\n",
      "Epoch 29/150, Loss: 1.1279541504392185\n",
      "Epoch 30/150, Loss: 0.9536420817667384\n",
      "Epoch 31/150, Loss: 0.9364086804155028\n",
      "Epoch 32/150, Loss: 0.9716545617720924\n",
      "Epoch 33/150, Loss: 1.080517076771524\n",
      "Epoch 34/150, Loss: 1.0128647850530428\n",
      "Epoch 35/150, Loss: 1.0328208905596785\n",
      "Epoch 36/150, Loss: 1.1468468811676051\n",
      "Epoch 37/150, Loss: 1.0382697971672306\n",
      "Epoch 38/150, Loss: 1.0038176171350415\n",
      "Epoch 39/150, Loss: 0.9731181432220406\n",
      "Epoch 40/150, Loss: 1.0348876044793327\n",
      "Epoch 41/150, Loss: 0.9190260167424974\n",
      "Epoch 42/150, Loss: 1.060241508563628\n",
      "Epoch 43/150, Loss: 1.0513223287704376\n",
      "Epoch 44/150, Loss: 1.0346595406261943\n",
      "Epoch 45/150, Loss: 1.0617087256898283\n",
      "Epoch 46/150, Loss: 0.8967034246619678\n",
      "Epoch 47/150, Loss: 1.0323402686876737\n",
      "Epoch 48/150, Loss: 0.9958341300676301\n",
      "Epoch 49/150, Loss: 1.1607240869723252\n",
      "Epoch 50/150, Loss: 1.1859166510620702\n",
      "Epoch 51/150, Loss: 1.029585733235311\n",
      "Epoch 52/150, Loss: 1.0505582242022868\n",
      "Epoch 53/150, Loss: 0.9367481596914804\n",
      "Epoch 54/150, Loss: 0.9196276030147194\n",
      "Epoch 55/150, Loss: 1.0272008518723212\n",
      "Epoch 56/150, Loss: 1.165615244970311\n",
      "Epoch 57/150, Loss: 1.1075428169841195\n",
      "Epoch 58/150, Loss: 1.0706055765947253\n",
      "Epoch 59/150, Loss: 0.9032674875483641\n",
      "Epoch 60/150, Loss: 1.0019943784877494\n",
      "Epoch 61/150, Loss: 1.0366658311743358\n",
      "Epoch 62/150, Loss: 0.9335759450626455\n",
      "Epoch 63/150, Loss: 1.126620228871222\n",
      "Epoch 64/150, Loss: 1.1096498018065741\n",
      "Epoch 65/150, Loss: 0.939468864938428\n",
      "Epoch 66/150, Loss: 0.9142122621078874\n",
      "Epoch 67/150, Loss: 0.9999723912598806\n",
      "Epoch 68/150, Loss: 1.0570935706974927\n",
      "Epoch 69/150, Loss: 1.1149431579539988\n",
      "Epoch 70/150, Loss: 1.2411726045880438\n",
      "Epoch 71/150, Loss: 1.0799416492410092\n",
      "Epoch 72/150, Loss: 0.9241176854595292\n",
      "Epoch 73/150, Loss: 0.9493080549433832\n",
      "Epoch 74/150, Loss: 0.889308289754445\n",
      "Epoch 75/150, Loss: 1.061100429801908\n",
      "Epoch 76/150, Loss: 1.1237259030976554\n",
      "Epoch 77/150, Loss: 1.0422877289218344\n",
      "Epoch 78/150, Loss: 1.012523440875993\n",
      "Epoch 79/150, Loss: 1.009846839555582\n",
      "Epoch 80/150, Loss: 0.9881460421081465\n",
      "Epoch 81/150, Loss: 1.1089379494126679\n",
      "Epoch 82/150, Loss: 0.9736128323346557\n",
      "Epoch 83/150, Loss: 0.9833616705506276\n",
      "Epoch 84/150, Loss: 0.9573925528532194\n",
      "Epoch 85/150, Loss: 1.0315195332163907\n",
      "Epoch 86/150, Loss: 1.01071551021443\n",
      "Epoch 87/150, Loss: 1.0208554314920248\n",
      "Epoch 88/150, Loss: 0.8988426208124529\n",
      "Epoch 89/150, Loss: 0.9508395807428816\n",
      "Epoch 90/150, Loss: 1.016425119472968\n",
      "Epoch 91/150, Loss: 0.9860470269522932\n",
      "Epoch 92/150, Loss: 1.024525189786477\n",
      "Epoch 93/150, Loss: 0.9975946260685327\n",
      "Epoch 94/150, Loss: 0.9666655714667411\n",
      "Epoch 95/150, Loss: 0.9999001782756062\n",
      "Epoch 96/150, Loss: 0.8933852203838912\n",
      "Epoch 97/150, Loss: 1.0080351324880128\n",
      "Epoch 98/150, Loss: 0.9652928952431556\n",
      "Epoch 99/150, Loss: 0.8838972036304775\n",
      "Epoch 100/150, Loss: 1.0026017152782554\n",
      "Epoch 101/150, Loss: 0.9513230239770615\n",
      "Epoch 102/150, Loss: 0.9847473064186871\n",
      "Epoch 103/150, Loss: 1.0659499180273737\n",
      "Epoch 104/150, Loss: 1.109914819599698\n",
      "Epoch 105/150, Loss: 1.1080558348870064\n",
      "Epoch 106/150, Loss: 0.9463969369367413\n",
      "Epoch 107/150, Loss: 1.0691263151015415\n",
      "Epoch 108/150, Loss: 1.1073136216819897\n",
      "Epoch 109/150, Loss: 1.110398537982046\n",
      "Epoch 110/150, Loss: 1.0269465395799025\n",
      "Epoch 111/150, Loss: 0.9672114454897209\n",
      "Epoch 112/150, Loss: 0.9511895777364491\n",
      "Epoch 113/150, Loss: 0.8987394034720076\n",
      "Epoch 114/150, Loss: 0.948384097246343\n",
      "Epoch 115/150, Loss: 1.1020088176663967\n",
      "Epoch 116/150, Loss: 1.126374246392358\n",
      "Epoch 117/150, Loss: 1.1488243685946955\n",
      "Epoch 118/150, Loss: 0.9698578704184411\n",
      "Epoch 119/150, Loss: 1.0470105226277189\n",
      "Epoch 120/150, Loss: 1.2077411519659185\n",
      "Epoch 121/150, Loss: 0.9736338627319243\n",
      "Epoch 122/150, Loss: 0.91276855152711\n",
      "Epoch 123/150, Loss: 1.0856672883018952\n",
      "Epoch 124/150, Loss: 0.8982447041777931\n",
      "Epoch 125/150, Loss: 0.9108616602598814\n",
      "Epoch 126/150, Loss: 0.9831243728776902\n",
      "Epoch 127/150, Loss: 1.010118971439856\n",
      "Epoch 128/150, Loss: 1.116946970663157\n",
      "Epoch 129/150, Loss: 0.9290189299236966\n",
      "Epoch 130/150, Loss: 0.9226043142420015\n",
      "Epoch 131/150, Loss: 1.010495293481366\n",
      "Epoch 132/150, Loss: 1.0008342567735664\n",
      "Epoch 133/150, Loss: 0.974324078051424\n",
      "Epoch 134/150, Loss: 0.9031217883923344\n",
      "Epoch 135/150, Loss: 0.8753250927237819\n",
      "Epoch 136/150, Loss: 1.0095031996479722\n",
      "Epoch 137/150, Loss: 0.8640380561124819\n",
      "Epoch 138/150, Loss: 1.0495899597894645\n",
      "Epoch 139/150, Loss: 1.0306772121894983\n",
      "Epoch 140/150, Loss: 0.9729588508926958\n",
      "Epoch 141/150, Loss: 1.0372292967845347\n",
      "Epoch 142/150, Loss: 0.9864451035816172\n",
      "Epoch 143/150, Loss: 1.022882317855471\n",
      "Epoch 144/150, Loss: 0.9972438811819095\n",
      "Epoch 145/150, Loss: 1.0041772015523105\n",
      "Epoch 146/150, Loss: 0.9778786378775344\n",
      "Epoch 147/150, Loss: 1.097920408761753\n",
      "Epoch 148/150, Loss: 0.9847412631451932\n",
      "Epoch 149/150, Loss: 1.1105603555843029\n",
      "Epoch 150/150, Loss: 1.026245985444652\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.46%'\n",
      "Epoch 1/50, Loss: 1.7685294915747618\n",
      "Epoch 2/50, Loss: 1.593484746774934\n",
      "Epoch 3/50, Loss: 1.4555494763954528\n",
      "Epoch 4/50, Loss: 1.3050862361818814\n",
      "Epoch 5/50, Loss: 1.238542423415094\n",
      "Epoch 6/50, Loss: 1.395170702405767\n",
      "Epoch 7/50, Loss: 1.2308057454083692\n",
      "Epoch 8/50, Loss: 1.1901244483872342\n",
      "Epoch 9/50, Loss: 1.1677998875176283\n",
      "Epoch 10/50, Loss: 1.1348437272484102\n",
      "Epoch 11/50, Loss: 1.1140934474481403\n",
      "Epoch 12/50, Loss: 1.0931752128668684\n",
      "Epoch 13/50, Loss: 1.1088433597719223\n",
      "Epoch 14/50, Loss: 1.1692740447511056\n",
      "Epoch 15/50, Loss: 0.9759412898854195\n",
      "Epoch 16/50, Loss: 1.1208274633590678\n",
      "Epoch 17/50, Loss: 1.011034143442231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 1.077822307598686\n",
      "Epoch 19/50, Loss: 1.1302559284868603\n",
      "Epoch 20/50, Loss: 1.0996579661934796\n",
      "Epoch 21/50, Loss: 0.991854515372804\n",
      "Epoch 22/50, Loss: 1.081696220273858\n",
      "Epoch 23/50, Loss: 1.042366677769532\n",
      "Epoch 24/50, Loss: 0.9862756817217874\n",
      "Epoch 25/50, Loss: 1.0477301166509074\n",
      "Epoch 26/50, Loss: 0.9964537611513737\n",
      "Epoch 27/50, Loss: 1.0829703593686102\n",
      "Epoch 28/50, Loss: 1.096872363541754\n",
      "Epoch 29/50, Loss: 1.026222326751867\n",
      "Epoch 30/50, Loss: 1.0467608028405757\n",
      "Epoch 31/50, Loss: 0.9803027588164632\n",
      "Epoch 32/50, Loss: 1.1143628707596736\n",
      "Epoch 33/50, Loss: 1.078472791027758\n",
      "Epoch 34/50, Loss: 1.0714754494507872\n",
      "Epoch 35/50, Loss: 1.0841560824803227\n",
      "Epoch 36/50, Loss: 1.0555865294903934\n",
      "Epoch 37/50, Loss: 1.0988910206427813\n",
      "Epoch 38/50, Loss: 1.064182519026849\n",
      "Epoch 39/50, Loss: 1.0532905373292307\n",
      "Epoch 40/50, Loss: 1.0287811430887548\n",
      "Epoch 41/50, Loss: 1.040205961429809\n",
      "Epoch 42/50, Loss: 1.0481528396731878\n",
      "Epoch 43/50, Loss: 1.0410880538376928\n",
      "Epoch 44/50, Loss: 1.1018813616489118\n",
      "Epoch 45/50, Loss: 1.0274848291177305\n",
      "Epoch 46/50, Loss: 1.0369165095800512\n",
      "Epoch 47/50, Loss: 1.078149080826606\n",
      "Epoch 48/50, Loss: 1.1398191314985324\n",
      "Epoch 49/50, Loss: 1.0173572422464559\n",
      "Epoch 50/50, Loss: 1.0931301816967514\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 77.69%'\n",
      "Epoch 1/100, Loss: 1.7263857509696847\n",
      "Epoch 2/100, Loss: 1.5004038167581917\n",
      "Epoch 3/100, Loss: 1.3138636914216528\n",
      "Epoch 4/100, Loss: 1.3693209401483193\n",
      "Epoch 5/100, Loss: 1.2004374738794124\n",
      "Epoch 6/100, Loss: 1.1669660449054369\n",
      "Epoch 7/100, Loss: 1.1247049757029957\n",
      "Epoch 8/100, Loss: 1.1450869392059722\n",
      "Epoch 9/100, Loss: 1.104700222177207\n",
      "Epoch 10/100, Loss: 1.138280879264339\n",
      "Epoch 11/100, Loss: 1.16524913539381\n",
      "Epoch 12/100, Loss: 1.0973805887306707\n",
      "Epoch 13/100, Loss: 1.1142821576711115\n",
      "Epoch 14/100, Loss: 1.0706602353446508\n",
      "Epoch 15/100, Loss: 1.0957710379347556\n",
      "Epoch 16/100, Loss: 1.1323290110504196\n",
      "Epoch 17/100, Loss: 0.9583259682496928\n",
      "Epoch 18/100, Loss: 1.039370202554947\n",
      "Epoch 19/100, Loss: 1.0816776592049264\n",
      "Epoch 20/100, Loss: 0.9764617357124898\n",
      "Epoch 21/100, Loss: 1.0765283078573757\n",
      "Epoch 22/100, Loss: 0.9896677394395417\n",
      "Epoch 23/100, Loss: 1.1054206242861269\n",
      "Epoch 24/100, Loss: 0.9479571854716071\n",
      "Epoch 25/100, Loss: 0.9114935664213154\n",
      "Epoch 26/100, Loss: 1.0296411281114712\n",
      "Epoch 27/100, Loss: 1.1704403072379965\n",
      "Epoch 28/100, Loss: 1.1209600568862053\n",
      "Epoch 29/100, Loss: 1.1061757007687447\n",
      "Epoch 30/100, Loss: 1.0119497092165455\n",
      "Epoch 31/100, Loss: 1.1311525303396721\n",
      "Epoch 32/100, Loss: 0.9746108147590451\n",
      "Epoch 33/100, Loss: 1.1936842517399342\n",
      "Epoch 34/100, Loss: 1.0110383183902272\n",
      "Epoch 35/100, Loss: 0.9936575760005653\n",
      "Epoch 36/100, Loss: 0.9651897094984566\n",
      "Epoch 37/100, Loss: 1.0913350910666673\n",
      "Epoch 38/100, Loss: 1.006040456918395\n",
      "Epoch 39/100, Loss: 1.0467478398830257\n",
      "Epoch 40/100, Loss: 1.0203606265070744\n",
      "Epoch 41/100, Loss: 1.06379541206528\n",
      "Epoch 42/100, Loss: 1.0088144608348741\n",
      "Epoch 43/100, Loss: 1.0301805741717667\n",
      "Epoch 44/100, Loss: 1.0502570513537952\n",
      "Epoch 45/100, Loss: 1.028954709287366\n",
      "Epoch 46/100, Loss: 1.1562087563063883\n",
      "Epoch 47/100, Loss: 1.051978550649294\n",
      "Epoch 48/100, Loss: 1.023159421117951\n",
      "Epoch 49/100, Loss: 1.0957809468209716\n",
      "Epoch 50/100, Loss: 0.936665437214821\n",
      "Epoch 51/100, Loss: 1.0444487376110816\n",
      "Epoch 52/100, Loss: 1.0360307174586243\n",
      "Epoch 53/100, Loss: 1.0229798837827064\n",
      "Epoch 54/100, Loss: 1.1150926557744238\n",
      "Epoch 55/100, Loss: 0.9517244867153849\n",
      "Epoch 56/100, Loss: 0.973811800433094\n",
      "Epoch 57/100, Loss: 1.0624209724579692\n",
      "Epoch 58/100, Loss: 1.048263215469364\n",
      "Epoch 59/100, Loss: 0.9689968086011963\n",
      "Epoch 60/100, Loss: 1.0977436858736143\n",
      "Epoch 61/100, Loss: 1.0940142740569914\n",
      "Epoch 62/100, Loss: 1.040529099344306\n",
      "Epoch 63/100, Loss: 1.078386767479296\n",
      "Epoch 64/100, Loss: 0.9779050419915832\n",
      "Epoch 65/100, Loss: 1.0036039804283805\n",
      "Epoch 66/100, Loss: 1.0169435535372815\n",
      "Epoch 67/100, Loss: 1.045641032610736\n",
      "Epoch 68/100, Loss: 1.1536978187881979\n",
      "Epoch 69/100, Loss: 1.0353341848399649\n",
      "Epoch 70/100, Loss: 0.9744970400925319\n",
      "Epoch 71/100, Loss: 1.0198199304853302\n",
      "Epoch 72/100, Loss: 1.0932241218465104\n",
      "Epoch 73/100, Loss: 1.0410693211866289\n",
      "Epoch 74/100, Loss: 1.0656234748258506\n",
      "Epoch 75/100, Loss: 1.0871960515757042\n",
      "Epoch 76/100, Loss: 1.085478570600057\n",
      "Epoch 77/100, Loss: 1.0521280191456828\n",
      "Epoch 78/100, Loss: 1.0144952649670946\n",
      "Epoch 79/100, Loss: 1.034602822262073\n",
      "Epoch 80/100, Loss: 1.0373966640061272\n",
      "Epoch 81/100, Loss: 1.0743035933117484\n",
      "Epoch 82/100, Loss: 0.9800488758674787\n",
      "Epoch 83/100, Loss: 1.0295631424837717\n",
      "Epoch 84/100, Loss: 1.054769063464171\n",
      "Epoch 85/100, Loss: 0.9837741257141667\n",
      "Epoch 86/100, Loss: 1.031741203322632\n",
      "Epoch 87/100, Loss: 1.027926843843097\n",
      "Epoch 88/100, Loss: 0.9755900547015874\n",
      "Epoch 89/100, Loss: 0.9900257809203467\n",
      "Epoch 90/100, Loss: 0.9904297496713791\n",
      "Epoch 91/100, Loss: 1.02983142538005\n",
      "Epoch 92/100, Loss: 0.9645147124758147\n",
      "Epoch 93/100, Loss: 1.024601760113229\n",
      "Epoch 94/100, Loss: 1.026998682576796\n",
      "Epoch 95/100, Loss: 1.0071690116526844\n",
      "Epoch 96/100, Loss: 1.0142843743306136\n",
      "Epoch 97/100, Loss: 1.0472717614007192\n",
      "Epoch 98/100, Loss: 0.9716525208802553\n",
      "Epoch 99/100, Loss: 1.0449954239853023\n",
      "Epoch 100/100, Loss: 1.0448892672993493\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.63%'\n",
      "Epoch 1/150, Loss: 1.762098316941501\n",
      "Epoch 2/150, Loss: 1.5390938175425044\n",
      "Epoch 3/150, Loss: 1.444698129015273\n",
      "Epoch 4/150, Loss: 1.2777802000081462\n",
      "Epoch 5/150, Loss: 1.2398590796585514\n",
      "Epoch 6/150, Loss: 1.2485915973940687\n",
      "Epoch 7/150, Loss: 1.1573856387920118\n",
      "Epoch 8/150, Loss: 1.0920959922786497\n",
      "Epoch 9/150, Loss: 1.1865596670690985\n",
      "Epoch 10/150, Loss: 1.078147973485411\n",
      "Epoch 11/150, Loss: 1.0552035883390176\n",
      "Epoch 12/150, Loss: 1.1478986097186674\n",
      "Epoch 13/150, Loss: 1.0401430174770336\n",
      "Epoch 14/150, Loss: 1.1637695612112142\n",
      "Epoch 15/150, Loss: 1.0745230354608044\n",
      "Epoch 16/150, Loss: 0.9389459710022982\n",
      "Epoch 17/150, Loss: 1.0852503429023448\n",
      "Epoch 18/150, Loss: 1.0682655847439497\n",
      "Epoch 19/150, Loss: 1.0533628261621784\n",
      "Epoch 20/150, Loss: 1.0537469621012194\n",
      "Epoch 21/150, Loss: 1.151788748354947\n",
      "Epoch 22/150, Loss: 1.1428982887104526\n",
      "Epoch 23/150, Loss: 0.9550535165047807\n",
      "Epoch 24/150, Loss: 1.1377226053690905\n",
      "Epoch 25/150, Loss: 1.0616410178912945\n",
      "Epoch 26/150, Loss: 1.1317770894686439\n",
      "Epoch 27/150, Loss: 1.1141245866255378\n",
      "Epoch 28/150, Loss: 1.1490224475885298\n",
      "Epoch 29/150, Loss: 0.9801873543396382\n",
      "Epoch 30/150, Loss: 1.0831914171878598\n",
      "Epoch 31/150, Loss: 1.0137716456876507\n",
      "Epoch 32/150, Loss: 1.0424743987320808\n",
      "Epoch 33/150, Loss: 1.1000246270319485\n",
      "Epoch 34/150, Loss: 1.0720224003390146\n",
      "Epoch 35/150, Loss: 1.0558231169957604\n",
      "Epoch 36/150, Loss: 1.1560467315437621\n",
      "Epoch 37/150, Loss: 1.1531120941392796\n",
      "Epoch 38/150, Loss: 1.0526153856387006\n",
      "Epoch 39/150, Loss: 1.0873917649289224\n",
      "Epoch 40/150, Loss: 1.0853513821672107\n",
      "Epoch 41/150, Loss: 0.9775365583479332\n",
      "Epoch 42/150, Loss: 1.0269584172209625\n",
      "Epoch 43/150, Loss: 1.08038756820617\n",
      "Epoch 44/150, Loss: 1.0400525744263796\n",
      "Epoch 45/150, Loss: 1.033569163574014\n",
      "Epoch 46/150, Loss: 1.0164533720876394\n",
      "Epoch 47/150, Loss: 1.0985763352910949\n",
      "Epoch 48/150, Loss: 0.9394790112805607\n",
      "Epoch 49/150, Loss: 1.021519948891881\n",
      "Epoch 50/150, Loss: 1.1075140651477429\n",
      "Epoch 51/150, Loss: 1.0438253655078638\n",
      "Epoch 52/150, Loss: 0.9432989830489498\n",
      "Epoch 53/150, Loss: 1.0381654165694527\n",
      "Epoch 54/150, Loss: 1.0741922118850948\n",
      "Epoch 55/150, Loss: 1.0491445898102976\n",
      "Epoch 56/150, Loss: 1.0825597994796474\n",
      "Epoch 57/150, Loss: 1.0415654729419574\n",
      "Epoch 58/150, Loss: 0.9732233866880612\n",
      "Epoch 59/150, Loss: 0.9846226434188611\n",
      "Epoch 60/150, Loss: 1.083235858764637\n",
      "Epoch 61/150, Loss: 1.028550146546291\n",
      "Epoch 62/150, Loss: 0.9312824170928059\n",
      "Epoch 63/150, Loss: 1.0042895663205227\n",
      "Epoch 64/150, Loss: 0.97499754268848\n",
      "Epoch 65/150, Loss: 1.0176297599685598\n",
      "Epoch 66/150, Loss: 1.0681630475581052\n",
      "Epoch 67/150, Loss: 0.9849460264632114\n",
      "Epoch 68/150, Loss: 1.0184516266299435\n",
      "Epoch 69/150, Loss: 1.0605681827071807\n",
      "Epoch 70/150, Loss: 0.9917095835457738\n",
      "Epoch 71/150, Loss: 1.0753598610059607\n",
      "Epoch 72/150, Loss: 1.025897036468082\n",
      "Epoch 73/150, Loss: 1.0099041800609923\n",
      "Epoch 74/150, Loss: 0.9542088504655515\n",
      "Epoch 75/150, Loss: 1.0182327799285762\n",
      "Epoch 76/150, Loss: 1.0051468035490614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150, Loss: 0.9424956688254892\n",
      "Epoch 78/150, Loss: 0.9937674377433197\n",
      "Epoch 79/150, Loss: 0.9821832985673976\n",
      "Epoch 80/150, Loss: 1.0613892647077727\n",
      "Epoch 81/150, Loss: 1.0988005492922748\n",
      "Epoch 82/150, Loss: 1.1398020381487124\n",
      "Epoch 83/150, Loss: 1.093621703473707\n",
      "Epoch 84/150, Loss: 1.0329958387791862\n",
      "Epoch 85/150, Loss: 0.9808963802842197\n",
      "Epoch 86/150, Loss: 0.9688610048575595\n",
      "Epoch 87/150, Loss: 1.0452581699811334\n",
      "Epoch 88/150, Loss: 0.9640732010159015\n",
      "Epoch 89/150, Loss: 1.0237503177410856\n",
      "Epoch 90/150, Loss: 1.0555544289449137\n",
      "Epoch 91/150, Loss: 1.0078280503402226\n",
      "Epoch 92/150, Loss: 0.9630342793896517\n",
      "Epoch 93/150, Loss: 1.041343944055878\n",
      "Epoch 94/150, Loss: 1.0965335711999935\n",
      "Epoch 95/150, Loss: 1.0030275923546172\n",
      "Epoch 96/150, Loss: 0.978210880268694\n",
      "Epoch 97/150, Loss: 1.0041441682902534\n",
      "Epoch 98/150, Loss: 0.938176150301734\n",
      "Epoch 99/150, Loss: 1.1172533481577616\n",
      "Epoch 100/150, Loss: 1.0801415158786467\n",
      "Epoch 101/150, Loss: 1.0212904444621511\n",
      "Epoch 102/150, Loss: 1.120137579549025\n",
      "Epoch 103/150, Loss: 1.034262691874192\n",
      "Epoch 104/150, Loss: 1.0098351275127395\n",
      "Epoch 105/150, Loss: 1.03012905386125\n",
      "Epoch 106/150, Loss: 0.9767849858824476\n",
      "Epoch 107/150, Loss: 1.049158094785466\n",
      "Epoch 108/150, Loss: 0.9985163790488165\n",
      "Epoch 109/150, Loss: 1.0504399255706307\n",
      "Epoch 110/150, Loss: 1.0105419574655272\n",
      "Epoch 111/150, Loss: 1.022080064694426\n",
      "Epoch 112/150, Loss: 1.0367409653596749\n",
      "Epoch 113/150, Loss: 0.9985345367873437\n",
      "Epoch 114/150, Loss: 1.094731002517697\n",
      "Epoch 115/150, Loss: 1.0728626386884228\n",
      "Epoch 116/150, Loss: 1.0606935724783484\n",
      "Epoch 117/150, Loss: 1.0709585590490078\n",
      "Epoch 118/150, Loss: 1.0484080909275897\n",
      "Epoch 119/150, Loss: 1.100300272953689\n",
      "Epoch 120/150, Loss: 1.0168117606387035\n",
      "Epoch 121/150, Loss: 1.1082930079264703\n",
      "Epoch 122/150, Loss: 1.0008151008309558\n",
      "Epoch 123/150, Loss: 1.109366400349858\n",
      "Epoch 124/150, Loss: 1.013930552422401\n",
      "Epoch 125/150, Loss: 0.9782285223137237\n",
      "Epoch 126/150, Loss: 0.9882971445787244\n",
      "Epoch 127/150, Loss: 1.0848677829543474\n",
      "Epoch 128/150, Loss: 1.0797961433801657\n",
      "Epoch 129/150, Loss: 0.9739205587653417\n",
      "Epoch 130/150, Loss: 1.1046663393614784\n",
      "Epoch 131/150, Loss: 1.0627498500202446\n",
      "Epoch 132/150, Loss: 1.0298837190965187\n",
      "Epoch 133/150, Loss: 1.0636596414859385\n",
      "Epoch 134/150, Loss: 1.0275065689836909\n",
      "Epoch 135/150, Loss: 1.0517080162816104\n",
      "Epoch 136/150, Loss: 1.0933913581961974\n",
      "Epoch 137/150, Loss: 0.9895857668469027\n",
      "Epoch 138/150, Loss: 1.0263704250559182\n",
      "Epoch 139/150, Loss: 1.0073315735739619\n",
      "Epoch 140/150, Loss: 1.0330900496386652\n",
      "Epoch 141/150, Loss: 0.9788517228283948\n",
      "Epoch 142/150, Loss: 1.0080755610560723\n",
      "Epoch 143/150, Loss: 1.0785453228614081\n",
      "Epoch 144/150, Loss: 1.0199260550058757\n",
      "Epoch 145/150, Loss: 1.0697997565044717\n",
      "Epoch 146/150, Loss: 0.9790701816964723\n",
      "Epoch 147/150, Loss: 0.973775052340511\n",
      "Epoch 148/150, Loss: 0.9392062651670119\n",
      "Epoch 149/150, Loss: 1.0404765587129134\n",
      "Epoch 150/150, Loss: 1.0291406134286736\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.001, Alpha 0.1, f'Test accuracy: 78.77%'\n",
      "Epoch 1/50, Loss: 0.5925545416261353\n",
      "Epoch 2/50, Loss: 0.5440926757464207\n",
      "Epoch 3/50, Loss: 0.6169877836994845\n",
      "Epoch 4/50, Loss: 0.5739928908741256\n",
      "Epoch 5/50, Loss: 0.7940409980148047\n",
      "Epoch 6/50, Loss: 0.6535665177226553\n",
      "Epoch 7/50, Loss: 0.5981852375704408\n",
      "Epoch 8/50, Loss: 0.55484742017284\n",
      "Epoch 9/50, Loss: 0.5855089225689764\n",
      "Epoch 10/50, Loss: 0.912890553877976\n",
      "Epoch 11/50, Loss: 0.6262937338607593\n",
      "Epoch 12/50, Loss: 0.7630885747612319\n",
      "Epoch 13/50, Loss: 0.5410788073061135\n",
      "Epoch 14/50, Loss: 0.34915757104698364\n",
      "Epoch 15/50, Loss: 0.6423044248902164\n",
      "Epoch 16/50, Loss: 0.5542058470401569\n",
      "Epoch 17/50, Loss: 0.634308586610547\n",
      "Epoch 18/50, Loss: 0.5996165918908337\n",
      "Epoch 19/50, Loss: 0.5536716017644181\n",
      "Epoch 20/50, Loss: 0.5230006260230612\n",
      "Epoch 21/50, Loss: 0.6723311535406018\n",
      "Epoch 22/50, Loss: 0.6761184491189122\n",
      "Epoch 23/50, Loss: 0.47945687657586133\n",
      "Epoch 24/50, Loss: 0.7055595565218733\n",
      "Epoch 25/50, Loss: 0.7702498087103976\n",
      "Epoch 26/50, Loss: 0.6175831652084153\n",
      "Epoch 27/50, Loss: 0.6916446712773145\n",
      "Epoch 28/50, Loss: 0.5280380076372664\n",
      "Epoch 29/50, Loss: 0.5421682504432052\n",
      "Epoch 30/50, Loss: 0.747410872806607\n",
      "Epoch 31/50, Loss: 0.7435874869179571\n",
      "Epoch 32/50, Loss: 0.5248117657271765\n",
      "Epoch 33/50, Loss: 0.6903984775079735\n",
      "Epoch 34/50, Loss: 0.508194632959327\n",
      "Epoch 35/50, Loss: 0.638237203344918\n",
      "Epoch 36/50, Loss: 0.7454368338793266\n",
      "Epoch 37/50, Loss: 0.5072879613792903\n",
      "Epoch 38/50, Loss: 0.5427078138671172\n",
      "Epoch 39/50, Loss: 0.5623188725218834\n",
      "Epoch 40/50, Loss: 0.43724525741529335\n",
      "Epoch 41/50, Loss: 0.41864765968342366\n",
      "Epoch 42/50, Loss: 0.6031132077620524\n",
      "Epoch 43/50, Loss: 0.5403379912411924\n",
      "Epoch 44/50, Loss: 0.5848671047799067\n",
      "Epoch 45/50, Loss: 0.7064241355026586\n",
      "Epoch 46/50, Loss: 0.7611418469905238\n",
      "Epoch 47/50, Loss: 0.5896030478285991\n",
      "Epoch 48/50, Loss: 0.44240634792878364\n",
      "Epoch 49/50, Loss: 0.47076858076237893\n",
      "Epoch 50/50, Loss: 0.5137684526422251\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.81%'\n",
      "Epoch 1/100, Loss: 0.7329524656560638\n",
      "Epoch 2/100, Loss: 0.6253308271193272\n",
      "Epoch 3/100, Loss: 0.6391277174192538\n",
      "Epoch 4/100, Loss: 0.6210402404951444\n",
      "Epoch 5/100, Loss: 0.7221054993088416\n",
      "Epoch 6/100, Loss: 0.5077872970574588\n",
      "Epoch 7/100, Loss: 0.636876301424369\n",
      "Epoch 8/100, Loss: 0.5547464637263703\n",
      "Epoch 9/100, Loss: 0.6078818871448269\n",
      "Epoch 10/100, Loss: 0.4735045222279793\n",
      "Epoch 11/100, Loss: 0.6548662692759726\n",
      "Epoch 12/100, Loss: 0.5969788778021874\n",
      "Epoch 13/100, Loss: 0.578722816964506\n",
      "Epoch 14/100, Loss: 0.5762148790968524\n",
      "Epoch 15/100, Loss: 0.5177836772615217\n",
      "Epoch 16/100, Loss: 0.497395864524131\n",
      "Epoch 17/100, Loss: 0.6532336328721101\n",
      "Epoch 18/100, Loss: 0.71716487471643\n",
      "Epoch 19/100, Loss: 0.679720118742088\n",
      "Epoch 20/100, Loss: 0.5270435723807894\n",
      "Epoch 21/100, Loss: 0.8825423009270036\n",
      "Epoch 22/100, Loss: 0.6796540097033625\n",
      "Epoch 23/100, Loss: 0.7711117523961772\n",
      "Epoch 24/100, Loss: 0.718818264374985\n",
      "Epoch 25/100, Loss: 0.5133286122677096\n",
      "Epoch 26/100, Loss: 0.9195055112881855\n",
      "Epoch 27/100, Loss: 0.6548186039420174\n",
      "Epoch 28/100, Loss: 0.35593816999911676\n",
      "Epoch 29/100, Loss: 0.7184037076213414\n",
      "Epoch 30/100, Loss: 0.47085159451867936\n",
      "Epoch 31/100, Loss: 0.7040988681325163\n",
      "Epoch 32/100, Loss: 0.5726721658081693\n",
      "Epoch 33/100, Loss: 0.613840860080911\n",
      "Epoch 34/100, Loss: 0.7696799979773279\n",
      "Epoch 35/100, Loss: 0.7301138613971518\n",
      "Epoch 36/100, Loss: 0.5818351796432402\n",
      "Epoch 37/100, Loss: 0.5329696571323024\n",
      "Epoch 38/100, Loss: 0.65270859981573\n",
      "Epoch 39/100, Loss: 0.7428498229780567\n",
      "Epoch 40/100, Loss: 0.5286862361732069\n",
      "Epoch 41/100, Loss: 0.5959201829945981\n",
      "Epoch 42/100, Loss: 0.6218851816841483\n",
      "Epoch 43/100, Loss: 0.6096719907408448\n",
      "Epoch 44/100, Loss: 0.5755285170768506\n",
      "Epoch 45/100, Loss: 0.7684907203472918\n",
      "Epoch 46/100, Loss: 0.5572208462847819\n",
      "Epoch 47/100, Loss: 0.6748303399041269\n",
      "Epoch 48/100, Loss: 0.5920811999313748\n",
      "Epoch 49/100, Loss: 0.6274197218722442\n",
      "Epoch 50/100, Loss: 0.5106364792911714\n",
      "Epoch 51/100, Loss: 0.40930698409158406\n",
      "Epoch 52/100, Loss: 0.763250032528268\n",
      "Epoch 53/100, Loss: 0.7564500552320522\n",
      "Epoch 54/100, Loss: 0.7556495319368935\n",
      "Epoch 55/100, Loss: 0.8203084057169239\n",
      "Epoch 56/100, Loss: 0.8834853021404647\n",
      "Epoch 57/100, Loss: 0.6651887563354304\n",
      "Epoch 58/100, Loss: 0.6917758801580335\n",
      "Epoch 59/100, Loss: 0.8984313834232964\n",
      "Epoch 60/100, Loss: 0.6284225713924696\n",
      "Epoch 61/100, Loss: 0.5400149647151748\n",
      "Epoch 62/100, Loss: 0.5567736842085296\n",
      "Epoch 63/100, Loss: 0.6626460410131592\n",
      "Epoch 64/100, Loss: 0.6276341267421948\n",
      "Epoch 65/100, Loss: 0.5758053345339375\n",
      "Epoch 66/100, Loss: 0.42138519697921484\n",
      "Epoch 67/100, Loss: 0.6555794247663969\n",
      "Epoch 68/100, Loss: 0.5164120972213143\n",
      "Epoch 69/100, Loss: 0.7123938023470642\n",
      "Epoch 70/100, Loss: 0.641022819085414\n",
      "Epoch 71/100, Loss: 0.7835877081235599\n",
      "Epoch 72/100, Loss: 0.5877456719139442\n",
      "Epoch 73/100, Loss: 0.6459746957704551\n",
      "Epoch 74/100, Loss: 0.5517800593798675\n",
      "Epoch 75/100, Loss: 0.5826408872611845\n",
      "Epoch 76/100, Loss: 0.6396324078600577\n",
      "Epoch 77/100, Loss: 0.7852005094264353\n",
      "Epoch 78/100, Loss: 0.649680071064676\n",
      "Epoch 79/100, Loss: 0.4866755796422496\n",
      "Epoch 80/100, Loss: 0.5748336850618427\n",
      "Epoch 81/100, Loss: 0.5300923654257367\n",
      "Epoch 82/100, Loss: 0.7817869946275116\n",
      "Epoch 83/100, Loss: 0.659506336772593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Loss: 0.6649174547469324\n",
      "Epoch 85/100, Loss: 0.5523232436477777\n",
      "Epoch 86/100, Loss: 0.4540555754169474\n",
      "Epoch 87/100, Loss: 0.6496637630869077\n",
      "Epoch 88/100, Loss: 0.7055056705752527\n",
      "Epoch 89/100, Loss: 0.6819291079039911\n",
      "Epoch 90/100, Loss: 0.8470913626014811\n",
      "Epoch 91/100, Loss: 0.4746596229519846\n",
      "Epoch 92/100, Loss: 0.7353786663397492\n",
      "Epoch 93/100, Loss: 0.41060247872328215\n",
      "Epoch 94/100, Loss: 0.6727762308532274\n",
      "Epoch 95/100, Loss: 0.563740875619628\n",
      "Epoch 96/100, Loss: 0.5320132525129625\n",
      "Epoch 97/100, Loss: 0.6061444352167219\n",
      "Epoch 98/100, Loss: 0.6803943283902336\n",
      "Epoch 99/100, Loss: 0.6640989090439131\n",
      "Epoch 100/100, Loss: 0.6517928681634926\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.56%'\n",
      "Epoch 1/150, Loss: 0.6325503070719635\n",
      "Epoch 2/150, Loss: 0.49404818418487756\n",
      "Epoch 3/150, Loss: 0.8567274548801392\n",
      "Epoch 4/150, Loss: 0.681462800686277\n",
      "Epoch 5/150, Loss: 0.623168481616266\n",
      "Epoch 6/150, Loss: 0.5767175942396578\n",
      "Epoch 7/150, Loss: 0.5296669181883222\n",
      "Epoch 8/150, Loss: 0.5414821472770688\n",
      "Epoch 9/150, Loss: 0.6783060677220656\n",
      "Epoch 10/150, Loss: 0.6997787109270768\n",
      "Epoch 11/150, Loss: 0.5037070009022442\n",
      "Epoch 12/150, Loss: 0.7541774307271982\n",
      "Epoch 13/150, Loss: 0.715884998047954\n",
      "Epoch 14/150, Loss: 0.45317683802354175\n",
      "Epoch 15/150, Loss: 0.8075027467009889\n",
      "Epoch 16/150, Loss: 0.7720570367121143\n",
      "Epoch 17/150, Loss: 0.5945154155180628\n",
      "Epoch 18/150, Loss: 1.1053392840711895\n",
      "Epoch 19/150, Loss: 0.641830769784277\n",
      "Epoch 20/150, Loss: 0.5937147129635216\n",
      "Epoch 21/150, Loss: 0.8540580950986428\n",
      "Epoch 22/150, Loss: 0.5968718555875692\n",
      "Epoch 23/150, Loss: 0.8310260006225859\n",
      "Epoch 24/150, Loss: 0.7916521309674898\n",
      "Epoch 25/150, Loss: 0.587957297225873\n",
      "Epoch 26/150, Loss: 0.6527679568941864\n",
      "Epoch 27/150, Loss: 0.49304739345633397\n",
      "Epoch 28/150, Loss: 0.5992692102035928\n",
      "Epoch 29/150, Loss: 0.626354826989086\n",
      "Epoch 30/150, Loss: 0.7820546190173254\n",
      "Epoch 31/150, Loss: 0.7525824177560927\n",
      "Epoch 32/150, Loss: 0.4000056515676797\n",
      "Epoch 33/150, Loss: 0.6067895130644574\n",
      "Epoch 34/150, Loss: 0.4349862183584551\n",
      "Epoch 35/150, Loss: 0.7228737720616697\n",
      "Epoch 36/150, Loss: 0.46776558676739904\n",
      "Epoch 37/150, Loss: 0.6420619715282371\n",
      "Epoch 38/150, Loss: 0.6462997629893857\n",
      "Epoch 39/150, Loss: 0.5074220226846632\n",
      "Epoch 40/150, Loss: 0.6047181102703738\n",
      "Epoch 41/150, Loss: 0.715831143084475\n",
      "Epoch 42/150, Loss: 0.6291541013889282\n",
      "Epoch 43/150, Loss: 0.3704033702749349\n",
      "Epoch 44/150, Loss: 0.750656537271181\n",
      "Epoch 45/150, Loss: 0.5182714821095493\n",
      "Epoch 46/150, Loss: 0.5855953007019425\n",
      "Epoch 47/150, Loss: 0.6800234755446439\n",
      "Epoch 48/150, Loss: 0.6194828647034675\n",
      "Epoch 49/150, Loss: 0.4828271122645078\n",
      "Epoch 50/150, Loss: 0.4458333801553967\n",
      "Epoch 51/150, Loss: 0.7562589632690708\n",
      "Epoch 52/150, Loss: 0.6123519045493618\n",
      "Epoch 53/150, Loss: 0.815172080985348\n",
      "Epoch 54/150, Loss: 0.656324914415871\n",
      "Epoch 55/150, Loss: 0.6837416678472011\n",
      "Epoch 56/150, Loss: 0.5438475753797508\n",
      "Epoch 57/150, Loss: 0.6249121433917953\n",
      "Epoch 58/150, Loss: 0.6909687491548804\n",
      "Epoch 59/150, Loss: 0.6035179272199792\n",
      "Epoch 60/150, Loss: 0.6060582134984668\n",
      "Epoch 61/150, Loss: 0.5130256664459427\n",
      "Epoch 62/150, Loss: 0.5587327394773076\n",
      "Epoch 63/150, Loss: 0.6202089820797815\n",
      "Epoch 64/150, Loss: 0.6101734606700524\n",
      "Epoch 65/150, Loss: 0.5688969597642722\n",
      "Epoch 66/150, Loss: 0.544594409264508\n",
      "Epoch 67/150, Loss: 0.7384114162188622\n",
      "Epoch 68/150, Loss: 0.5880870424415223\n",
      "Epoch 69/150, Loss: 0.5247838845775195\n",
      "Epoch 70/150, Loss: 0.7099127342041539\n",
      "Epoch 71/150, Loss: 0.527302213100069\n",
      "Epoch 72/150, Loss: 0.5594124469844696\n",
      "Epoch 73/150, Loss: 0.7266589903973668\n",
      "Epoch 74/150, Loss: 0.5645099442682926\n",
      "Epoch 75/150, Loss: 0.5820504640262452\n",
      "Epoch 76/150, Loss: 0.5715500849629339\n",
      "Epoch 77/150, Loss: 0.4386672043519705\n",
      "Epoch 78/150, Loss: 0.46384288132884577\n",
      "Epoch 79/150, Loss: 0.49029745715467876\n",
      "Epoch 80/150, Loss: 0.8126949365965928\n",
      "Epoch 81/150, Loss: 0.5798119892158393\n",
      "Epoch 82/150, Loss: 0.6914827487865404\n",
      "Epoch 83/150, Loss: 0.6718850290562816\n",
      "Epoch 84/150, Loss: 0.9673782514751691\n",
      "Epoch 85/150, Loss: 0.6643716259700738\n",
      "Epoch 86/150, Loss: 0.6659196531685458\n",
      "Epoch 87/150, Loss: 0.729965876098376\n",
      "Epoch 88/150, Loss: 0.6014559448202591\n",
      "Epoch 89/150, Loss: 0.49016980280892297\n",
      "Epoch 90/150, Loss: 0.48871625219388515\n",
      "Epoch 91/150, Loss: 0.7757331462082843\n",
      "Epoch 92/150, Loss: 0.3836667452519481\n",
      "Epoch 93/150, Loss: 0.5613734622604778\n",
      "Epoch 94/150, Loss: 0.5640809919710803\n",
      "Epoch 95/150, Loss: 0.49385907977121685\n",
      "Epoch 96/150, Loss: 0.6230409219396541\n",
      "Epoch 97/150, Loss: 0.39655307792816785\n",
      "Epoch 98/150, Loss: 0.45824961781035534\n",
      "Epoch 99/150, Loss: 0.5549376008731614\n",
      "Epoch 100/150, Loss: 0.5301839273189143\n",
      "Epoch 101/150, Loss: 0.6098928273399937\n",
      "Epoch 102/150, Loss: 0.6756913278654132\n",
      "Epoch 103/150, Loss: 0.628097194224128\n",
      "Epoch 104/150, Loss: 0.6332876990483749\n",
      "Epoch 105/150, Loss: 0.576704241592072\n",
      "Epoch 106/150, Loss: 0.5593480985525054\n",
      "Epoch 107/150, Loss: 0.7410662272579144\n",
      "Epoch 108/150, Loss: 0.4938104662504005\n",
      "Epoch 109/150, Loss: 0.5378255612055878\n",
      "Epoch 110/150, Loss: 0.47343771158071585\n",
      "Epoch 111/150, Loss: 0.8518085279773647\n",
      "Epoch 112/150, Loss: 0.47877208332786525\n",
      "Epoch 113/150, Loss: 0.5544275360023861\n",
      "Epoch 114/150, Loss: 0.6189497241750298\n",
      "Epoch 115/150, Loss: 0.41916872176048403\n",
      "Epoch 116/150, Loss: 0.8620238279543028\n",
      "Epoch 117/150, Loss: 0.4805519531446697\n",
      "Epoch 118/150, Loss: 0.6054044665702933\n",
      "Epoch 119/150, Loss: 0.4688137805623132\n",
      "Epoch 120/150, Loss: 0.7028649313566634\n",
      "Epoch 121/150, Loss: 0.6179445038524953\n",
      "Epoch 122/150, Loss: 0.45130470368817965\n",
      "Epoch 123/150, Loss: 0.4980575486828441\n",
      "Epoch 124/150, Loss: 0.5351544825522446\n",
      "Epoch 125/150, Loss: 0.5195494742907971\n",
      "Epoch 126/150, Loss: 0.6217345106950515\n",
      "Epoch 127/150, Loss: 0.588475604081936\n",
      "Epoch 128/150, Loss: 0.7089726388791259\n",
      "Epoch 129/150, Loss: 0.572835511213329\n",
      "Epoch 130/150, Loss: 0.35691957543867053\n",
      "Epoch 131/150, Loss: 0.6363252146209561\n",
      "Epoch 132/150, Loss: 0.6847970641889845\n",
      "Epoch 133/150, Loss: 0.6211044811661227\n",
      "Epoch 134/150, Loss: 0.6329489773602293\n",
      "Epoch 135/150, Loss: 0.9044963035236327\n",
      "Epoch 136/150, Loss: 0.6421215426283229\n",
      "Epoch 137/150, Loss: 0.4453950454226717\n",
      "Epoch 138/150, Loss: 0.6932410648548\n",
      "Epoch 139/150, Loss: 0.9082568806621746\n",
      "Epoch 140/150, Loss: 0.5322963367599914\n",
      "Epoch 141/150, Loss: 0.757123561046984\n",
      "Epoch 142/150, Loss: 0.569169875093342\n",
      "Epoch 143/150, Loss: 0.7162336198151753\n",
      "Epoch 144/150, Loss: 0.5280701861276446\n",
      "Epoch 145/150, Loss: 0.6632333215298636\n",
      "Epoch 146/150, Loss: 0.6899532456758246\n",
      "Epoch 147/150, Loss: 0.539631759863362\n",
      "Epoch 148/150, Loss: 0.5175342520697521\n",
      "Epoch 149/150, Loss: 0.6208788201857306\n",
      "Epoch 150/150, Loss: 0.7101750067209671\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.63%'\n",
      "Epoch 1/50, Loss: 0.8536592911356429\n",
      "Epoch 2/50, Loss: 0.6283484251445905\n",
      "Epoch 3/50, Loss: 0.7792752012099061\n",
      "Epoch 4/50, Loss: 0.7096486309743845\n",
      "Epoch 5/50, Loss: 0.7171107033693149\n",
      "Epoch 6/50, Loss: 0.5176529142453568\n",
      "Epoch 7/50, Loss: 0.5322016903217042\n",
      "Epoch 8/50, Loss: 0.6661387942084863\n",
      "Epoch 9/50, Loss: 0.7363078027925398\n",
      "Epoch 10/50, Loss: 0.5594287824768345\n",
      "Epoch 11/50, Loss: 0.6983600876818187\n",
      "Epoch 12/50, Loss: 0.7406817455111853\n",
      "Epoch 13/50, Loss: 0.6774555264044526\n",
      "Epoch 14/50, Loss: 0.649158081832667\n",
      "Epoch 15/50, Loss: 0.5347767302624695\n",
      "Epoch 16/50, Loss: 0.6910383726929631\n",
      "Epoch 17/50, Loss: 0.6942539184257196\n",
      "Epoch 18/50, Loss: 0.677809294559273\n",
      "Epoch 19/50, Loss: 0.7029309491593377\n",
      "Epoch 20/50, Loss: 0.7725634403985684\n",
      "Epoch 21/50, Loss: 0.647703582911853\n",
      "Epoch 22/50, Loss: 0.683504914938012\n",
      "Epoch 23/50, Loss: 0.5191558121378987\n",
      "Epoch 24/50, Loss: 0.6261777817426417\n",
      "Epoch 25/50, Loss: 0.6200939785671311\n",
      "Epoch 26/50, Loss: 0.5529811059233883\n",
      "Epoch 27/50, Loss: 0.593428869926391\n",
      "Epoch 28/50, Loss: 0.5217553862482117\n",
      "Epoch 29/50, Loss: 0.5651865159613866\n",
      "Epoch 30/50, Loss: 0.6333845206474654\n",
      "Epoch 31/50, Loss: 0.5771546451035087\n",
      "Epoch 32/50, Loss: 0.5286394100052153\n",
      "Epoch 33/50, Loss: 0.553701006365803\n",
      "Epoch 34/50, Loss: 0.5141974557211663\n",
      "Epoch 35/50, Loss: 0.5096189927473651\n",
      "Epoch 36/50, Loss: 0.5115350797363969\n",
      "Epoch 37/50, Loss: 0.46704113985479556\n",
      "Epoch 38/50, Loss: 0.6457048769183048\n",
      "Epoch 39/50, Loss: 0.6060401632299134\n",
      "Epoch 40/50, Loss: 0.5441147978848757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.531858573394758\n",
      "Epoch 42/50, Loss: 0.4042370761400639\n",
      "Epoch 43/50, Loss: 0.593835360865325\n",
      "Epoch 44/50, Loss: 0.6917430426144648\n",
      "Epoch 45/50, Loss: 0.6968180894370962\n",
      "Epoch 46/50, Loss: 0.6104499512004931\n",
      "Epoch 47/50, Loss: 0.7265149165952197\n",
      "Epoch 48/50, Loss: 0.45161348310332916\n",
      "Epoch 49/50, Loss: 0.6507055288530652\n",
      "Epoch 50/50, Loss: 0.6181577137586904\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.95%'\n",
      "Epoch 1/100, Loss: 0.8126364020380515\n",
      "Epoch 2/100, Loss: 0.6026091684505421\n",
      "Epoch 3/100, Loss: 0.7356350539081088\n",
      "Epoch 4/100, Loss: 0.7378888680961719\n",
      "Epoch 5/100, Loss: 0.8731106389079224\n",
      "Epoch 6/100, Loss: 0.7515953548728435\n",
      "Epoch 7/100, Loss: 0.6229451043534863\n",
      "Epoch 8/100, Loss: 0.7282976141938307\n",
      "Epoch 9/100, Loss: 0.8680689022670844\n",
      "Epoch 10/100, Loss: 0.6713155207657423\n",
      "Epoch 11/100, Loss: 0.5359983757820529\n",
      "Epoch 12/100, Loss: 0.6097931963049932\n",
      "Epoch 13/100, Loss: 0.5945126928998528\n",
      "Epoch 14/100, Loss: 0.615354686419356\n",
      "Epoch 15/100, Loss: 0.5754294629361422\n",
      "Epoch 16/100, Loss: 0.5797463212986106\n",
      "Epoch 17/100, Loss: 0.6560013725316703\n",
      "Epoch 18/100, Loss: 0.6101642135518828\n",
      "Epoch 19/100, Loss: 0.5475818546767873\n",
      "Epoch 20/100, Loss: 0.5760876912409004\n",
      "Epoch 21/100, Loss: 0.7044272696500142\n",
      "Epoch 22/100, Loss: 0.6093557188470988\n",
      "Epoch 23/100, Loss: 0.5271102130885875\n",
      "Epoch 24/100, Loss: 0.6729008035771504\n",
      "Epoch 25/100, Loss: 0.6574768121997847\n",
      "Epoch 26/100, Loss: 0.7057824822617289\n",
      "Epoch 27/100, Loss: 0.7548531706421794\n",
      "Epoch 28/100, Loss: 0.6510622747235429\n",
      "Epoch 29/100, Loss: 0.6644186951745181\n",
      "Epoch 30/100, Loss: 0.6979098555152229\n",
      "Epoch 31/100, Loss: 0.5085550039098053\n",
      "Epoch 32/100, Loss: 0.5708504882755709\n",
      "Epoch 33/100, Loss: 0.7237269386656688\n",
      "Epoch 34/100, Loss: 0.7962667044299045\n",
      "Epoch 35/100, Loss: 0.591374559619033\n",
      "Epoch 36/100, Loss: 0.6174014136950591\n",
      "Epoch 37/100, Loss: 0.6078687125187059\n",
      "Epoch 38/100, Loss: 0.7135964788477953\n",
      "Epoch 39/100, Loss: 0.5568394439700752\n",
      "Epoch 40/100, Loss: 0.5949495758715624\n",
      "Epoch 41/100, Loss: 0.6615495430479187\n",
      "Epoch 42/100, Loss: 0.6290655064704765\n",
      "Epoch 43/100, Loss: 0.38630324007901023\n",
      "Epoch 44/100, Loss: 0.5100187756395079\n",
      "Epoch 45/100, Loss: 0.6470750109996907\n",
      "Epoch 46/100, Loss: 0.5779486713528668\n",
      "Epoch 47/100, Loss: 0.6243645113842989\n",
      "Epoch 48/100, Loss: 0.5985708511275556\n",
      "Epoch 49/100, Loss: 0.6297094952648237\n",
      "Epoch 50/100, Loss: 0.4855556191095801\n",
      "Epoch 51/100, Loss: 0.46322949496860466\n",
      "Epoch 52/100, Loss: 0.6719567542001944\n",
      "Epoch 53/100, Loss: 0.6487232298489718\n",
      "Epoch 54/100, Loss: 0.5321749654320256\n",
      "Epoch 55/100, Loss: 0.6719697008852732\n",
      "Epoch 56/100, Loss: 0.5326352587052315\n",
      "Epoch 57/100, Loss: 0.5880780325985056\n",
      "Epoch 58/100, Loss: 0.6757227406375481\n",
      "Epoch 59/100, Loss: 0.5728170634699143\n",
      "Epoch 60/100, Loss: 0.599270879253605\n",
      "Epoch 61/100, Loss: 0.6181428228598692\n",
      "Epoch 62/100, Loss: 0.4114124627101912\n",
      "Epoch 63/100, Loss: 0.6146156833084077\n",
      "Epoch 64/100, Loss: 0.8105936544016064\n",
      "Epoch 65/100, Loss: 0.6934518667842947\n",
      "Epoch 66/100, Loss: 0.5547151538183003\n",
      "Epoch 67/100, Loss: 0.6755173539205183\n",
      "Epoch 68/100, Loss: 0.5316709523122942\n",
      "Epoch 69/100, Loss: 0.5488253675518038\n",
      "Epoch 70/100, Loss: 0.70486205696579\n",
      "Epoch 71/100, Loss: 0.6075638735076839\n",
      "Epoch 72/100, Loss: 0.7627577960233793\n",
      "Epoch 73/100, Loss: 0.993266340769658\n",
      "Epoch 74/100, Loss: 0.5279282054125713\n",
      "Epoch 75/100, Loss: 0.5519586564937092\n",
      "Epoch 76/100, Loss: 0.6692569690432907\n",
      "Epoch 77/100, Loss: 0.5826446426417626\n",
      "Epoch 78/100, Loss: 0.6495058135040673\n",
      "Epoch 79/100, Loss: 0.61019695495125\n",
      "Epoch 80/100, Loss: 0.6050323924058897\n",
      "Epoch 81/100, Loss: 0.49617239295130156\n",
      "Epoch 82/100, Loss: 0.5862173982744044\n",
      "Epoch 83/100, Loss: 0.8644417385717618\n",
      "Epoch 84/100, Loss: 0.6324515008968055\n",
      "Epoch 85/100, Loss: 0.7361645760107401\n",
      "Epoch 86/100, Loss: 0.5734183427262729\n",
      "Epoch 87/100, Loss: 0.5875374798322259\n",
      "Epoch 88/100, Loss: 0.6823330756938546\n",
      "Epoch 89/100, Loss: 0.6588323258586264\n",
      "Epoch 90/100, Loss: 0.5775129796114225\n",
      "Epoch 91/100, Loss: 0.7407765073074363\n",
      "Epoch 92/100, Loss: 0.5775145072746418\n",
      "Epoch 93/100, Loss: 0.7125420057683471\n",
      "Epoch 94/100, Loss: 0.505995670386072\n",
      "Epoch 95/100, Loss: 0.47816104759281125\n",
      "Epoch 96/100, Loss: 0.7282136874598193\n",
      "Epoch 97/100, Loss: 0.6500573741832564\n",
      "Epoch 98/100, Loss: 0.5033366666714416\n",
      "Epoch 99/100, Loss: 0.5763977887634317\n",
      "Epoch 100/100, Loss: 0.833897677329734\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.76%'\n",
      "Epoch 1/150, Loss: 0.9732433298536285\n",
      "Epoch 2/150, Loss: 0.7156087086746525\n",
      "Epoch 3/150, Loss: 0.5935768127750038\n",
      "Epoch 4/150, Loss: 0.6400273077734004\n",
      "Epoch 5/150, Loss: 0.8850822293185487\n",
      "Epoch 6/150, Loss: 0.7738795397186438\n",
      "Epoch 7/150, Loss: 0.7514871287880379\n",
      "Epoch 8/150, Loss: 0.5463249860219453\n",
      "Epoch 9/150, Loss: 0.6569323009735806\n",
      "Epoch 10/150, Loss: 0.6321463736444421\n",
      "Epoch 11/150, Loss: 0.5805421285787036\n",
      "Epoch 12/150, Loss: 0.7010723846043667\n",
      "Epoch 13/150, Loss: 0.6127475288627781\n",
      "Epoch 14/150, Loss: 0.6716447588653826\n",
      "Epoch 15/150, Loss: 0.5739435808217428\n",
      "Epoch 16/150, Loss: 0.6439719241735518\n",
      "Epoch 17/150, Loss: 0.6214765642217093\n",
      "Epoch 18/150, Loss: 0.7866350752227977\n",
      "Epoch 19/150, Loss: 0.4834733507137603\n",
      "Epoch 20/150, Loss: 0.6680723091635018\n",
      "Epoch 21/150, Loss: 0.5979619254845959\n",
      "Epoch 22/150, Loss: 0.5654186717692602\n",
      "Epoch 23/150, Loss: 0.6057963184209176\n",
      "Epoch 24/150, Loss: 0.6424166065395855\n",
      "Epoch 25/150, Loss: 0.4445295473736509\n",
      "Epoch 26/150, Loss: 0.6217647387119732\n",
      "Epoch 27/150, Loss: 0.7690834893238823\n",
      "Epoch 28/150, Loss: 0.6724621049954183\n",
      "Epoch 29/150, Loss: 0.6018013724623708\n",
      "Epoch 30/150, Loss: 0.7625798133673235\n",
      "Epoch 31/150, Loss: 0.7684301793338991\n",
      "Epoch 32/150, Loss: 0.6865089847165078\n",
      "Epoch 33/150, Loss: 0.45958955264937773\n",
      "Epoch 34/150, Loss: 0.45143561926691367\n",
      "Epoch 35/150, Loss: 0.6214973782597911\n",
      "Epoch 36/150, Loss: 0.663790757120047\n",
      "Epoch 37/150, Loss: 0.5562705791020452\n",
      "Epoch 38/150, Loss: 0.4264945942251613\n",
      "Epoch 39/150, Loss: 0.633359236450942\n",
      "Epoch 40/150, Loss: 0.4647806479043174\n",
      "Epoch 41/150, Loss: 0.6910208451999305\n",
      "Epoch 42/150, Loss: 0.5354683933057234\n",
      "Epoch 43/150, Loss: 0.4626957151762442\n",
      "Epoch 44/150, Loss: 0.48616655592288\n",
      "Epoch 45/150, Loss: 0.4689793235881164\n",
      "Epoch 46/150, Loss: 0.7459317445664815\n",
      "Epoch 47/150, Loss: 0.7694195788265197\n",
      "Epoch 48/150, Loss: 0.6669648989403373\n",
      "Epoch 49/150, Loss: 0.5834951339038678\n",
      "Epoch 50/150, Loss: 0.5834019544942842\n",
      "Epoch 51/150, Loss: 0.6476236986944389\n",
      "Epoch 52/150, Loss: 0.8155319856356762\n",
      "Epoch 53/150, Loss: 0.5390541485665261\n",
      "Epoch 54/150, Loss: 0.5575105335501414\n",
      "Epoch 55/150, Loss: 0.5895791255525352\n",
      "Epoch 56/150, Loss: 0.6350410172422687\n",
      "Epoch 57/150, Loss: 0.577240403638017\n",
      "Epoch 58/150, Loss: 0.7432114268486018\n",
      "Epoch 59/150, Loss: 0.6151748640299711\n",
      "Epoch 60/150, Loss: 0.5687393873296855\n",
      "Epoch 61/150, Loss: 0.6315092549615006\n",
      "Epoch 62/150, Loss: 0.5173820334933508\n",
      "Epoch 63/150, Loss: 0.675613217164585\n",
      "Epoch 64/150, Loss: 0.5269879616073265\n",
      "Epoch 65/150, Loss: 0.5922760270223362\n",
      "Epoch 66/150, Loss: 0.6340483363646492\n",
      "Epoch 67/150, Loss: 0.5878090034666543\n",
      "Epoch 68/150, Loss: 0.5979553787386183\n",
      "Epoch 69/150, Loss: 0.47819150151492484\n",
      "Epoch 70/150, Loss: 0.5136670347724542\n",
      "Epoch 71/150, Loss: 0.5405446063763801\n",
      "Epoch 72/150, Loss: 0.6269650273610261\n",
      "Epoch 73/150, Loss: 0.5174352818855927\n",
      "Epoch 74/150, Loss: 0.6271549504748186\n",
      "Epoch 75/150, Loss: 0.6327662676526025\n",
      "Epoch 76/150, Loss: 0.45707920189185164\n",
      "Epoch 77/150, Loss: 0.6920107786603095\n",
      "Epoch 78/150, Loss: 0.5066188335237432\n",
      "Epoch 79/150, Loss: 0.5842815856065251\n",
      "Epoch 80/150, Loss: 0.5779126863693189\n",
      "Epoch 81/150, Loss: 0.6366860725447896\n",
      "Epoch 82/150, Loss: 0.6637397795414989\n",
      "Epoch 83/150, Loss: 0.46889713134799044\n",
      "Epoch 84/150, Loss: 0.561804549873162\n",
      "Epoch 85/150, Loss: 0.6027819556624167\n",
      "Epoch 86/150, Loss: 0.556641682232661\n",
      "Epoch 87/150, Loss: 0.8203700650942678\n",
      "Epoch 88/150, Loss: 0.6768580982417863\n",
      "Epoch 89/150, Loss: 0.5678146151829155\n",
      "Epoch 90/150, Loss: 0.5285111279421557\n",
      "Epoch 91/150, Loss: 0.600259999894035\n",
      "Epoch 92/150, Loss: 0.5393756717286726\n",
      "Epoch 93/150, Loss: 0.5262092669373698\n",
      "Epoch 94/150, Loss: 0.643088392975947\n",
      "Epoch 95/150, Loss: 0.6434775615103787\n",
      "Epoch 96/150, Loss: 0.6475650667692339\n",
      "Epoch 97/150, Loss: 0.6443512854866702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150, Loss: 0.5624055425877565\n",
      "Epoch 99/150, Loss: 0.6096423366123526\n",
      "Epoch 100/150, Loss: 0.5665281434617274\n",
      "Epoch 101/150, Loss: 0.5649855528736758\n",
      "Epoch 102/150, Loss: 0.5838034689129581\n",
      "Epoch 103/150, Loss: 0.7414894169192313\n",
      "Epoch 104/150, Loss: 0.702035362342473\n",
      "Epoch 105/150, Loss: 0.6762881958904919\n",
      "Epoch 106/150, Loss: 0.6210901361435919\n",
      "Epoch 107/150, Loss: 0.754098578437138\n",
      "Epoch 108/150, Loss: 0.6917521282061154\n",
      "Epoch 109/150, Loss: 0.5700981953088027\n",
      "Epoch 110/150, Loss: 0.7542114102913045\n",
      "Epoch 111/150, Loss: 0.4659162951216665\n",
      "Epoch 112/150, Loss: 0.8798221410106165\n",
      "Epoch 113/150, Loss: 0.5977473851167201\n",
      "Epoch 114/150, Loss: 0.7248563435089346\n",
      "Epoch 115/150, Loss: 0.7381877050214853\n",
      "Epoch 116/150, Loss: 0.6212388751070519\n",
      "Epoch 117/150, Loss: 0.5810839955589678\n",
      "Epoch 118/150, Loss: 0.6522441531983216\n",
      "Epoch 119/150, Loss: 0.6728639179130561\n",
      "Epoch 120/150, Loss: 0.6335769864551555\n",
      "Epoch 121/150, Loss: 0.7760454671866613\n",
      "Epoch 122/150, Loss: 0.5307154527678707\n",
      "Epoch 123/150, Loss: 0.6666315471300857\n",
      "Epoch 124/150, Loss: 0.5677244023656541\n",
      "Epoch 125/150, Loss: 0.7121463466737963\n",
      "Epoch 126/150, Loss: 0.6435104651991536\n",
      "Epoch 127/150, Loss: 0.5788806280724692\n",
      "Epoch 128/150, Loss: 0.664881034522698\n",
      "Epoch 129/150, Loss: 0.477229330745466\n",
      "Epoch 130/150, Loss: 0.7197982607050909\n",
      "Epoch 131/150, Loss: 0.5818627385121252\n",
      "Epoch 132/150, Loss: 0.5009105813795917\n",
      "Epoch 133/150, Loss: 0.6486311860130515\n",
      "Epoch 134/150, Loss: 0.6618082420637432\n",
      "Epoch 135/150, Loss: 0.5806980689719294\n",
      "Epoch 136/150, Loss: 0.5175339781598524\n",
      "Epoch 137/150, Loss: 0.42891439011164617\n",
      "Epoch 138/150, Loss: 0.7241560189175427\n",
      "Epoch 139/150, Loss: 0.8208453891353034\n",
      "Epoch 140/150, Loss: 0.5760339272804043\n",
      "Epoch 141/150, Loss: 0.664643974447139\n",
      "Epoch 142/150, Loss: 0.7103594010251089\n",
      "Epoch 143/150, Loss: 0.6433246223910525\n",
      "Epoch 144/150, Loss: 0.6200004994962037\n",
      "Epoch 145/150, Loss: 0.6525157364056284\n",
      "Epoch 146/150, Loss: 0.5990799910214895\n",
      "Epoch 147/150, Loss: 0.5987541232826061\n",
      "Epoch 148/150, Loss: 0.5436619706224181\n",
      "Epoch 149/150, Loss: 0.5671418142566435\n",
      "Epoch 150/150, Loss: 0.705723503625454\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.84%'\n",
      "Epoch 1/50, Loss: 0.9654870377423602\n",
      "Epoch 2/50, Loss: 0.8138021384917117\n",
      "Epoch 3/50, Loss: 0.7111564876307683\n",
      "Epoch 4/50, Loss: 0.7213594629198687\n",
      "Epoch 5/50, Loss: 0.5814287712845139\n",
      "Epoch 6/50, Loss: 0.6304227730826425\n",
      "Epoch 7/50, Loss: 0.6009357605297332\n",
      "Epoch 8/50, Loss: 0.588627149336544\n",
      "Epoch 9/50, Loss: 0.6487150414736486\n",
      "Epoch 10/50, Loss: 0.6154332989083114\n",
      "Epoch 11/50, Loss: 0.6636037225194668\n",
      "Epoch 12/50, Loss: 0.6563040588102408\n",
      "Epoch 13/50, Loss: 0.5624514675583815\n",
      "Epoch 14/50, Loss: 0.6195696151349996\n",
      "Epoch 15/50, Loss: 0.6259465297875346\n",
      "Epoch 16/50, Loss: 0.6609170148285448\n",
      "Epoch 17/50, Loss: 0.6786234607759838\n",
      "Epoch 18/50, Loss: 0.608199010051667\n",
      "Epoch 19/50, Loss: 0.7453688811081891\n",
      "Epoch 20/50, Loss: 0.7118881021657091\n",
      "Epoch 21/50, Loss: 0.6552644572933094\n",
      "Epoch 22/50, Loss: 0.6464148013281532\n",
      "Epoch 23/50, Loss: 0.6537296387322281\n",
      "Epoch 24/50, Loss: 0.5571410906724358\n",
      "Epoch 25/50, Loss: 0.6810375433099577\n",
      "Epoch 26/50, Loss: 0.563680502638114\n",
      "Epoch 27/50, Loss: 0.6602626613185444\n",
      "Epoch 28/50, Loss: 0.6626937347023659\n",
      "Epoch 29/50, Loss: 0.5857183010125812\n",
      "Epoch 30/50, Loss: 0.7329832835325614\n",
      "Epoch 31/50, Loss: 0.6119144637008218\n",
      "Epoch 32/50, Loss: 0.6219115150050994\n",
      "Epoch 33/50, Loss: 0.6813763466513981\n",
      "Epoch 34/50, Loss: 0.6020944108113462\n",
      "Epoch 35/50, Loss: 0.5115539388736434\n",
      "Epoch 36/50, Loss: 0.6499151803455402\n",
      "Epoch 37/50, Loss: 0.5540054641192154\n",
      "Epoch 38/50, Loss: 0.5808819275712368\n",
      "Epoch 39/50, Loss: 0.6535964436682568\n",
      "Epoch 40/50, Loss: 0.6219313565014838\n",
      "Epoch 41/50, Loss: 0.6132162264310208\n",
      "Epoch 42/50, Loss: 0.6541208857963988\n",
      "Epoch 43/50, Loss: 0.628379842088207\n",
      "Epoch 44/50, Loss: 0.5038585216697109\n",
      "Epoch 45/50, Loss: 0.6559705001293276\n",
      "Epoch 46/50, Loss: 0.7173292136603777\n",
      "Epoch 47/50, Loss: 0.5562099313881163\n",
      "Epoch 48/50, Loss: 0.5630107886323972\n",
      "Epoch 49/50, Loss: 0.7250468660184916\n",
      "Epoch 50/50, Loss: 0.6294676089084277\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 83.08%'\n",
      "Epoch 1/100, Loss: 0.9631482128060507\n",
      "Epoch 2/100, Loss: 0.6942844759971586\n",
      "Epoch 3/100, Loss: 0.7480651801064453\n",
      "Epoch 4/100, Loss: 0.8551962532145493\n",
      "Epoch 5/100, Loss: 0.737687944218087\n",
      "Epoch 6/100, Loss: 0.74821658950278\n",
      "Epoch 7/100, Loss: 0.6007196096678185\n",
      "Epoch 8/100, Loss: 0.7199114044779267\n",
      "Epoch 9/100, Loss: 0.7008370435890041\n",
      "Epoch 10/100, Loss: 0.6601670996870264\n",
      "Epoch 11/100, Loss: 0.6413844681850346\n",
      "Epoch 12/100, Loss: 0.6091153132806428\n",
      "Epoch 13/100, Loss: 0.7583292283450744\n",
      "Epoch 14/100, Loss: 0.5689378821290104\n",
      "Epoch 15/100, Loss: 0.6566085014667624\n",
      "Epoch 16/100, Loss: 0.6611624070430444\n",
      "Epoch 17/100, Loss: 0.7472051206739436\n",
      "Epoch 18/100, Loss: 0.6297572652693448\n",
      "Epoch 19/100, Loss: 0.6145408555929202\n",
      "Epoch 20/100, Loss: 0.6825194852796803\n",
      "Epoch 21/100, Loss: 0.676204478622774\n",
      "Epoch 22/100, Loss: 0.67044752933658\n",
      "Epoch 23/100, Loss: 0.5853207111630367\n",
      "Epoch 24/100, Loss: 0.6523989110824611\n",
      "Epoch 25/100, Loss: 0.6361903173386385\n",
      "Epoch 26/100, Loss: 0.67278367768139\n",
      "Epoch 27/100, Loss: 0.5542974588929007\n",
      "Epoch 28/100, Loss: 0.5794593893683204\n",
      "Epoch 29/100, Loss: 0.6085482350639677\n",
      "Epoch 30/100, Loss: 0.705209952474673\n",
      "Epoch 31/100, Loss: 0.6718311734281887\n",
      "Epoch 32/100, Loss: 0.6244406363177757\n",
      "Epoch 33/100, Loss: 0.6992401469200191\n",
      "Epoch 34/100, Loss: 0.7569770111495648\n",
      "Epoch 35/100, Loss: 0.7693613847583228\n",
      "Epoch 36/100, Loss: 0.5920888089787937\n",
      "Epoch 37/100, Loss: 0.6771274186555736\n",
      "Epoch 38/100, Loss: 0.6491561655559951\n",
      "Epoch 39/100, Loss: 0.7390700930767666\n",
      "Epoch 40/100, Loss: 0.6969350306752549\n",
      "Epoch 41/100, Loss: 0.5106051010471137\n",
      "Epoch 42/100, Loss: 0.6531159921998981\n",
      "Epoch 43/100, Loss: 0.6733901401841977\n",
      "Epoch 44/100, Loss: 0.5826913133737053\n",
      "Epoch 45/100, Loss: 0.6014467556127957\n",
      "Epoch 46/100, Loss: 0.6539504144654757\n",
      "Epoch 47/100, Loss: 0.5036174259447538\n",
      "Epoch 48/100, Loss: 0.6808053225033844\n",
      "Epoch 49/100, Loss: 0.608177646285867\n",
      "Epoch 50/100, Loss: 0.5781864958217127\n",
      "Epoch 51/100, Loss: 0.5588470847892272\n",
      "Epoch 52/100, Loss: 0.6146903628083066\n",
      "Epoch 53/100, Loss: 0.6516399869599951\n",
      "Epoch 54/100, Loss: 0.5499751158012123\n",
      "Epoch 55/100, Loss: 0.6970763009022294\n",
      "Epoch 56/100, Loss: 0.6087376823739272\n",
      "Epoch 57/100, Loss: 0.688925891854464\n",
      "Epoch 58/100, Loss: 0.5497521104936934\n",
      "Epoch 59/100, Loss: 0.7303712157725388\n",
      "Epoch 60/100, Loss: 0.5707688141266495\n",
      "Epoch 61/100, Loss: 0.6313616444839013\n",
      "Epoch 62/100, Loss: 0.59453905448332\n",
      "Epoch 63/100, Loss: 0.6803028579996184\n",
      "Epoch 64/100, Loss: 0.6143779050461814\n",
      "Epoch 65/100, Loss: 0.6668092134691953\n",
      "Epoch 66/100, Loss: 0.5016888951591267\n",
      "Epoch 67/100, Loss: 0.5184690574475782\n",
      "Epoch 68/100, Loss: 0.7019915791823732\n",
      "Epoch 69/100, Loss: 0.5347069296165765\n",
      "Epoch 70/100, Loss: 0.6730101796190405\n",
      "Epoch 71/100, Loss: 0.5439401211135194\n",
      "Epoch 72/100, Loss: 0.5358448954240362\n",
      "Epoch 73/100, Loss: 0.6383281109992275\n",
      "Epoch 74/100, Loss: 0.6180457682586812\n",
      "Epoch 75/100, Loss: 0.6442625015215513\n",
      "Epoch 76/100, Loss: 0.6967609192983252\n",
      "Epoch 77/100, Loss: 0.6436016914937075\n",
      "Epoch 78/100, Loss: 0.6744307515980453\n",
      "Epoch 79/100, Loss: 0.6639207895723613\n",
      "Epoch 80/100, Loss: 0.6662912383368296\n",
      "Epoch 81/100, Loss: 0.7099715385396677\n",
      "Epoch 82/100, Loss: 0.6021034000287214\n",
      "Epoch 83/100, Loss: 0.6161383269638235\n",
      "Epoch 84/100, Loss: 0.6428559424807087\n",
      "Epoch 85/100, Loss: 0.5681062176897109\n",
      "Epoch 86/100, Loss: 0.6405637014427483\n",
      "Epoch 87/100, Loss: 0.5897530805649887\n",
      "Epoch 88/100, Loss: 0.737740433274551\n",
      "Epoch 89/100, Loss: 0.5599408157885218\n",
      "Epoch 90/100, Loss: 0.6150585978379087\n",
      "Epoch 91/100, Loss: 0.5743171355845101\n",
      "Epoch 92/100, Loss: 0.544977678671577\n",
      "Epoch 93/100, Loss: 0.5391797266781768\n",
      "Epoch 94/100, Loss: 0.5883329344843838\n",
      "Epoch 95/100, Loss: 0.6002458424457023\n",
      "Epoch 96/100, Loss: 0.6152707509865578\n",
      "Epoch 97/100, Loss: 0.6362178788637376\n",
      "Epoch 98/100, Loss: 0.5783253517472591\n",
      "Epoch 99/100, Loss: 0.5917101235449868\n",
      "Epoch 100/100, Loss: 0.586541446168846\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 83.03%'\n",
      "Epoch 1/150, Loss: 0.9137392105364983\n",
      "Epoch 2/150, Loss: 0.8038279209385927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150, Loss: 0.713702182480724\n",
      "Epoch 4/150, Loss: 0.6455495326585374\n",
      "Epoch 5/150, Loss: 0.6350176179850333\n",
      "Epoch 6/150, Loss: 0.6353951021881534\n",
      "Epoch 7/150, Loss: 0.6158911117695683\n",
      "Epoch 8/150, Loss: 0.7657839091858683\n",
      "Epoch 9/150, Loss: 0.6535233743383595\n",
      "Epoch 10/150, Loss: 0.5465254521313411\n",
      "Epoch 11/150, Loss: 0.5518061234705712\n",
      "Epoch 12/150, Loss: 0.6104371015567606\n",
      "Epoch 13/150, Loss: 0.6989460919850824\n",
      "Epoch 14/150, Loss: 0.6931302384786268\n",
      "Epoch 15/150, Loss: 0.47881039904068246\n",
      "Epoch 16/150, Loss: 0.6514520174268732\n",
      "Epoch 17/150, Loss: 0.7107391114420973\n",
      "Epoch 18/150, Loss: 0.7323657879256366\n",
      "Epoch 19/150, Loss: 0.6512888246152044\n",
      "Epoch 20/150, Loss: 0.7087084410388218\n",
      "Epoch 21/150, Loss: 0.6156592922851917\n",
      "Epoch 22/150, Loss: 0.5698591955543971\n",
      "Epoch 23/150, Loss: 0.6882969507921373\n",
      "Epoch 24/150, Loss: 0.6554196116304591\n",
      "Epoch 25/150, Loss: 0.6290887781604602\n",
      "Epoch 26/150, Loss: 0.6067619619291302\n",
      "Epoch 27/150, Loss: 0.6862066556963783\n",
      "Epoch 28/150, Loss: 0.5296146877833801\n",
      "Epoch 29/150, Loss: 0.8323129850190256\n",
      "Epoch 30/150, Loss: 0.7042749606814454\n",
      "Epoch 31/150, Loss: 0.5166350438975847\n",
      "Epoch 32/150, Loss: 0.6659197952136372\n",
      "Epoch 33/150, Loss: 0.6873222191966804\n",
      "Epoch 34/150, Loss: 0.5932393958072827\n",
      "Epoch 35/150, Loss: 0.7084659031347339\n",
      "Epoch 36/150, Loss: 0.6917009394839431\n",
      "Epoch 37/150, Loss: 0.8328288820480229\n",
      "Epoch 38/150, Loss: 0.6284147023205402\n",
      "Epoch 39/150, Loss: 0.6016254199475365\n",
      "Epoch 40/150, Loss: 0.6234953626987699\n",
      "Epoch 41/150, Loss: 0.77553010478233\n",
      "Epoch 42/150, Loss: 0.6754940940145446\n",
      "Epoch 43/150, Loss: 0.6756046276414546\n",
      "Epoch 44/150, Loss: 0.6401622427258628\n",
      "Epoch 45/150, Loss: 0.6130131267506765\n",
      "Epoch 46/150, Loss: 0.7051283141440648\n",
      "Epoch 47/150, Loss: 0.6442539009906468\n",
      "Epoch 48/150, Loss: 0.558183912173912\n",
      "Epoch 49/150, Loss: 0.5223789575231278\n",
      "Epoch 50/150, Loss: 0.6112226120006325\n",
      "Epoch 51/150, Loss: 0.6245121437232082\n",
      "Epoch 52/150, Loss: 0.6231891109537706\n",
      "Epoch 53/150, Loss: 0.6277337492301114\n",
      "Epoch 54/150, Loss: 0.5961053410537758\n",
      "Epoch 55/150, Loss: 0.6127194538244141\n",
      "Epoch 56/150, Loss: 0.5783846500739264\n",
      "Epoch 57/150, Loss: 0.7094295500451472\n",
      "Epoch 58/150, Loss: 0.5939186449456981\n",
      "Epoch 59/150, Loss: 0.6235552309809936\n",
      "Epoch 60/150, Loss: 0.7522579792806018\n",
      "Epoch 61/150, Loss: 0.6197445082540645\n",
      "Epoch 62/150, Loss: 0.5762302121886207\n",
      "Epoch 63/150, Loss: 0.6081446006057257\n",
      "Epoch 64/150, Loss: 0.6669794919042039\n",
      "Epoch 65/150, Loss: 0.6199344175738416\n",
      "Epoch 66/150, Loss: 0.6755248085663096\n",
      "Epoch 67/150, Loss: 0.6468831092247521\n",
      "Epoch 68/150, Loss: 0.5410350185197514\n",
      "Epoch 69/150, Loss: 0.7018534433972121\n",
      "Epoch 70/150, Loss: 0.6592409015583707\n",
      "Epoch 71/150, Loss: 0.7271240849831535\n",
      "Epoch 72/150, Loss: 0.6377004029033876\n",
      "Epoch 73/150, Loss: 0.6097424256520827\n",
      "Epoch 74/150, Loss: 0.5446643836698395\n",
      "Epoch 75/150, Loss: 0.6763379442077259\n",
      "Epoch 76/150, Loss: 0.5502838646336923\n",
      "Epoch 77/150, Loss: 0.589188449826044\n",
      "Epoch 78/150, Loss: 0.650707145682259\n",
      "Epoch 79/150, Loss: 0.5968365339599109\n",
      "Epoch 80/150, Loss: 0.6731185367466239\n",
      "Epoch 81/150, Loss: 0.5553855777331864\n",
      "Epoch 82/150, Loss: 0.6845534823173042\n",
      "Epoch 83/150, Loss: 0.5640671937668202\n",
      "Epoch 84/150, Loss: 0.5173879854451913\n",
      "Epoch 85/150, Loss: 0.5668634796772495\n",
      "Epoch 86/150, Loss: 0.6886385510847628\n",
      "Epoch 87/150, Loss: 0.6344315666348688\n",
      "Epoch 88/150, Loss: 0.6032443445253957\n",
      "Epoch 89/150, Loss: 0.6823063235755924\n",
      "Epoch 90/150, Loss: 0.6603204869505823\n",
      "Epoch 91/150, Loss: 0.5607731623564541\n",
      "Epoch 92/150, Loss: 0.6063502778064676\n",
      "Epoch 93/150, Loss: 0.5869233786988156\n",
      "Epoch 94/150, Loss: 0.6697559775978053\n",
      "Epoch 95/150, Loss: 0.6658435225769874\n",
      "Epoch 96/150, Loss: 0.6384604898290677\n",
      "Epoch 97/150, Loss: 0.7093123902877345\n",
      "Epoch 98/150, Loss: 0.6743450527633668\n",
      "Epoch 99/150, Loss: 0.6476409128794028\n",
      "Epoch 100/150, Loss: 0.6726652656261118\n",
      "Epoch 101/150, Loss: 0.6598326793018378\n",
      "Epoch 102/150, Loss: 0.6632750863827759\n",
      "Epoch 103/150, Loss: 0.5189645763963896\n",
      "Epoch 104/150, Loss: 0.5744242192695981\n",
      "Epoch 105/150, Loss: 0.5805651504391834\n",
      "Epoch 106/150, Loss: 0.6507195159118704\n",
      "Epoch 107/150, Loss: 0.7100418529058704\n",
      "Epoch 108/150, Loss: 0.6585252641149325\n",
      "Epoch 109/150, Loss: 0.5922899649917478\n",
      "Epoch 110/150, Loss: 0.6035759957004807\n",
      "Epoch 111/150, Loss: 0.5680633864600102\n",
      "Epoch 112/150, Loss: 0.5735500850569968\n",
      "Epoch 113/150, Loss: 0.6538751653529636\n",
      "Epoch 114/150, Loss: 0.6284852587157557\n",
      "Epoch 115/150, Loss: 0.6151071781824856\n",
      "Epoch 116/150, Loss: 0.6243302399351119\n",
      "Epoch 117/150, Loss: 0.7216952167072246\n",
      "Epoch 118/150, Loss: 0.7665670912105518\n",
      "Epoch 119/150, Loss: 0.6132856410249974\n",
      "Epoch 120/150, Loss: 0.5835052788093538\n",
      "Epoch 121/150, Loss: 0.6349979776614277\n",
      "Epoch 122/150, Loss: 0.7377905333834381\n",
      "Epoch 123/150, Loss: 0.5387218447268403\n",
      "Epoch 124/150, Loss: 0.5932327306005245\n",
      "Epoch 125/150, Loss: 0.6396857172394972\n",
      "Epoch 126/150, Loss: 0.5545193734994402\n",
      "Epoch 127/150, Loss: 0.6689710430888527\n",
      "Epoch 128/150, Loss: 0.6886523029626899\n",
      "Epoch 129/150, Loss: 0.6194634776567013\n",
      "Epoch 130/150, Loss: 0.5151652605264609\n",
      "Epoch 131/150, Loss: 0.6975933970658963\n",
      "Epoch 132/150, Loss: 0.6821922996958621\n",
      "Epoch 133/150, Loss: 0.6356698523731816\n",
      "Epoch 134/150, Loss: 0.5874767225043791\n",
      "Epoch 135/150, Loss: 0.46613141813681624\n",
      "Epoch 136/150, Loss: 0.6115993099818066\n",
      "Epoch 137/150, Loss: 0.5331162927341878\n",
      "Epoch 138/150, Loss: 0.6280085342348155\n",
      "Epoch 139/150, Loss: 0.7699197727597442\n",
      "Epoch 140/150, Loss: 0.7043820417715434\n",
      "Epoch 141/150, Loss: 0.5478293704213657\n",
      "Epoch 142/150, Loss: 0.670710686647159\n",
      "Epoch 143/150, Loss: 0.6399624293255896\n",
      "Epoch 144/150, Loss: 0.5850040566590947\n",
      "Epoch 145/150, Loss: 0.530229823629999\n",
      "Epoch 146/150, Loss: 0.5788483563228739\n",
      "Epoch 147/150, Loss: 0.7745543720941673\n",
      "Epoch 148/150, Loss: 0.5537538969145188\n",
      "Epoch 149/150, Loss: 0.5785904878568554\n",
      "Epoch 150/150, Loss: 0.569519103686131\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.01, Alpha 0.01, f'Test accuracy: 82.93%'\n",
      "Epoch 1/50, Loss: 0.9859902429706682\n",
      "Epoch 2/50, Loss: 1.0533183158409303\n",
      "Epoch 3/50, Loss: 1.0263937816398945\n",
      "Epoch 4/50, Loss: 1.0755819408635066\n",
      "Epoch 5/50, Loss: 1.0561921940938368\n",
      "Epoch 6/50, Loss: 0.8733441636236172\n",
      "Epoch 7/50, Loss: 0.8899776122673345\n",
      "Epoch 8/50, Loss: 1.196451353249822\n",
      "Epoch 9/50, Loss: 0.9697749829479041\n",
      "Epoch 10/50, Loss: 1.0301023752254574\n",
      "Epoch 11/50, Loss: 0.7653881768121943\n",
      "Epoch 12/50, Loss: 0.9234562791399876\n",
      "Epoch 13/50, Loss: 1.1415887553937312\n",
      "Epoch 14/50, Loss: 0.9181224316621828\n",
      "Epoch 15/50, Loss: 1.0355201950987272\n",
      "Epoch 16/50, Loss: 0.755481708866723\n",
      "Epoch 17/50, Loss: 0.9164968467052221\n",
      "Epoch 18/50, Loss: 1.2591638394451428\n",
      "Epoch 19/50, Loss: 0.9090209860015179\n",
      "Epoch 20/50, Loss: 1.0452579201983556\n",
      "Epoch 21/50, Loss: 0.8651903154890996\n",
      "Epoch 22/50, Loss: 0.952628593120717\n",
      "Epoch 23/50, Loss: 1.0372674331246121\n",
      "Epoch 24/50, Loss: 0.9185897552052442\n",
      "Epoch 25/50, Loss: 1.0335602732194789\n",
      "Epoch 26/50, Loss: 1.130816594839456\n",
      "Epoch 27/50, Loss: 1.0135187155629968\n",
      "Epoch 28/50, Loss: 1.1162826249996305\n",
      "Epoch 29/50, Loss: 1.0252258013337345\n",
      "Epoch 30/50, Loss: 1.1005276615819681\n",
      "Epoch 31/50, Loss: 1.0838621678203149\n",
      "Epoch 32/50, Loss: 0.8484010781262101\n",
      "Epoch 33/50, Loss: 1.027775484058321\n",
      "Epoch 34/50, Loss: 0.9912757991192493\n",
      "Epoch 35/50, Loss: 1.0670526265307125\n",
      "Epoch 36/50, Loss: 1.0201761642657905\n",
      "Epoch 37/50, Loss: 0.9390383324878668\n",
      "Epoch 38/50, Loss: 1.0780780405899735\n",
      "Epoch 39/50, Loss: 0.9552695008182301\n",
      "Epoch 40/50, Loss: 0.7899429332706343\n",
      "Epoch 41/50, Loss: 0.9250531245504761\n",
      "Epoch 42/50, Loss: 0.9006591057198279\n",
      "Epoch 43/50, Loss: 0.9423435849141503\n",
      "Epoch 44/50, Loss: 1.0362765287154665\n",
      "Epoch 45/50, Loss: 0.8545331936580796\n",
      "Epoch 46/50, Loss: 0.834469932269269\n",
      "Epoch 47/50, Loss: 1.043962208149643\n",
      "Epoch 48/50, Loss: 1.0346727535614948\n",
      "Epoch 49/50, Loss: 0.9831296333432629\n",
      "Epoch 50/50, Loss: 1.2394247486761627\n",
      "Num_Epoch 50, Batch_size 32, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.19%'\n",
      "Epoch 1/100, Loss: 1.1344099503679321\n",
      "Epoch 2/100, Loss: 1.1473320991061913\n",
      "Epoch 3/100, Loss: 1.1256460900721552\n",
      "Epoch 4/100, Loss: 1.1003184669516384\n",
      "Epoch 5/100, Loss: 0.9303474519594881\n",
      "Epoch 6/100, Loss: 1.072906492122303\n",
      "Epoch 7/100, Loss: 1.1242603706645906\n",
      "Epoch 8/100, Loss: 1.0001924628877228\n",
      "Epoch 9/100, Loss: 0.825504515509566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.9147994288530193\n",
      "Epoch 11/100, Loss: 1.146671434381139\n",
      "Epoch 12/100, Loss: 0.9226602162438431\n",
      "Epoch 13/100, Loss: 0.9739005158281945\n",
      "Epoch 14/100, Loss: 0.9206849152759796\n",
      "Epoch 15/100, Loss: 1.15458549405318\n",
      "Epoch 16/100, Loss: 1.204318022376815\n",
      "Epoch 17/100, Loss: 1.0515339230222143\n",
      "Epoch 18/100, Loss: 0.8269607585820533\n",
      "Epoch 19/100, Loss: 1.2065814243855966\n",
      "Epoch 20/100, Loss: 0.9650444531396585\n",
      "Epoch 21/100, Loss: 1.1109932454943832\n",
      "Epoch 22/100, Loss: 1.184537210222449\n",
      "Epoch 23/100, Loss: 1.0187642886563704\n",
      "Epoch 24/100, Loss: 1.077490509187996\n",
      "Epoch 25/100, Loss: 0.8845507841606303\n",
      "Epoch 26/100, Loss: 0.8867844314961361\n",
      "Epoch 27/100, Loss: 1.033915481324279\n",
      "Epoch 28/100, Loss: 0.9530856111154649\n",
      "Epoch 29/100, Loss: 1.024160347625235\n",
      "Epoch 30/100, Loss: 1.0129632798896497\n",
      "Epoch 31/100, Loss: 0.8638041216158387\n",
      "Epoch 32/100, Loss: 1.0005496624597683\n",
      "Epoch 33/100, Loss: 0.8523643563473221\n",
      "Epoch 34/100, Loss: 1.0266853316837972\n",
      "Epoch 35/100, Loss: 0.9164962069868554\n",
      "Epoch 36/100, Loss: 1.0782048057187363\n",
      "Epoch 37/100, Loss: 1.054962616371575\n",
      "Epoch 38/100, Loss: 1.29027494948108\n",
      "Epoch 39/100, Loss: 0.8146711478285273\n",
      "Epoch 40/100, Loss: 0.9077437082579287\n",
      "Epoch 41/100, Loss: 0.8412988468649089\n",
      "Epoch 42/100, Loss: 0.8472697106121577\n",
      "Epoch 43/100, Loss: 1.0446840650867084\n",
      "Epoch 44/100, Loss: 0.9207500184582311\n",
      "Epoch 45/100, Loss: 1.072778976758111\n",
      "Epoch 46/100, Loss: 1.011859590022637\n",
      "Epoch 47/100, Loss: 0.8052463832505597\n",
      "Epoch 48/100, Loss: 0.9469904549280408\n",
      "Epoch 49/100, Loss: 0.8787212678901851\n",
      "Epoch 50/100, Loss: 1.2739897329411582\n",
      "Epoch 51/100, Loss: 0.9801350442086318\n",
      "Epoch 52/100, Loss: 0.905028530495766\n",
      "Epoch 53/100, Loss: 1.3670529096446855\n",
      "Epoch 54/100, Loss: 0.7242792463154526\n",
      "Epoch 55/100, Loss: 0.9402075280748301\n",
      "Epoch 56/100, Loss: 1.0121274679333685\n",
      "Epoch 57/100, Loss: 1.0240474433758404\n",
      "Epoch 58/100, Loss: 1.0259234031010158\n",
      "Epoch 59/100, Loss: 1.0313561828076545\n",
      "Epoch 60/100, Loss: 0.8453671026238246\n",
      "Epoch 61/100, Loss: 0.8604410864999016\n",
      "Epoch 62/100, Loss: 0.9494909818951369\n",
      "Epoch 63/100, Loss: 0.9151293560470846\n",
      "Epoch 64/100, Loss: 0.9272362417795206\n",
      "Epoch 65/100, Loss: 1.11387457524224\n",
      "Epoch 66/100, Loss: 1.2108852355738924\n",
      "Epoch 67/100, Loss: 1.0054130638024137\n",
      "Epoch 68/100, Loss: 0.830789683272167\n",
      "Epoch 69/100, Loss: 1.0393813595234755\n",
      "Epoch 70/100, Loss: 0.9999413856813617\n",
      "Epoch 71/100, Loss: 1.1813343578354625\n",
      "Epoch 72/100, Loss: 0.8403051182937401\n",
      "Epoch 73/100, Loss: 0.792212388817071\n",
      "Epoch 74/100, Loss: 1.044131311206401\n",
      "Epoch 75/100, Loss: 0.7820408577503847\n",
      "Epoch 76/100, Loss: 1.0921572074447599\n",
      "Epoch 77/100, Loss: 1.1709472607785387\n",
      "Epoch 78/100, Loss: 0.9154260987314536\n",
      "Epoch 79/100, Loss: 1.0630307729515622\n",
      "Epoch 80/100, Loss: 1.0048245046587354\n",
      "Epoch 81/100, Loss: 1.0378960071445233\n",
      "Epoch 82/100, Loss: 0.8589224645125172\n",
      "Epoch 83/100, Loss: 1.2928748345934333\n",
      "Epoch 84/100, Loss: 1.092387260813278\n",
      "Epoch 85/100, Loss: 0.9279836661626774\n",
      "Epoch 86/100, Loss: 0.9333530615866947\n",
      "Epoch 87/100, Loss: 0.9279309928868857\n",
      "Epoch 88/100, Loss: 0.8892517300491715\n",
      "Epoch 89/100, Loss: 1.1515875436023657\n",
      "Epoch 90/100, Loss: 0.8595242893127613\n",
      "Epoch 91/100, Loss: 0.7999170393008069\n",
      "Epoch 92/100, Loss: 0.8939067834508669\n",
      "Epoch 93/100, Loss: 0.9805249132211871\n",
      "Epoch 94/100, Loss: 0.9203347807935085\n",
      "Epoch 95/100, Loss: 0.7814607753936513\n",
      "Epoch 96/100, Loss: 0.861853688131592\n",
      "Epoch 97/100, Loss: 1.1191494077982151\n",
      "Epoch 98/100, Loss: 0.9362173232158356\n",
      "Epoch 99/100, Loss: 1.1092805602183042\n",
      "Epoch 100/100, Loss: 0.9509278127865494\n",
      "Num_Epoch 100, Batch_size 32, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.23%'\n",
      "Epoch 1/150, Loss: 0.9485794745424909\n",
      "Epoch 2/150, Loss: 0.8617032317236679\n",
      "Epoch 3/150, Loss: 1.1436528833136674\n",
      "Epoch 4/150, Loss: 1.0261888575388216\n",
      "Epoch 5/150, Loss: 0.9351522527287092\n",
      "Epoch 6/150, Loss: 1.1139279189824456\n",
      "Epoch 7/150, Loss: 1.025233841322086\n",
      "Epoch 8/150, Loss: 0.7968351801856592\n",
      "Epoch 9/150, Loss: 1.080718021164149\n",
      "Epoch 10/150, Loss: 1.0592598736523529\n",
      "Epoch 11/150, Loss: 1.0642959378615404\n",
      "Epoch 12/150, Loss: 1.2046648860034828\n",
      "Epoch 13/150, Loss: 1.106878916743532\n",
      "Epoch 14/150, Loss: 1.1678061335027483\n",
      "Epoch 15/150, Loss: 1.0076760558100557\n",
      "Epoch 16/150, Loss: 0.8961203294492038\n",
      "Epoch 17/150, Loss: 0.803030278012921\n",
      "Epoch 18/150, Loss: 1.1164092252421045\n",
      "Epoch 19/150, Loss: 0.876027518757105\n",
      "Epoch 20/150, Loss: 0.901552863156017\n",
      "Epoch 21/150, Loss: 1.1711468962203397\n",
      "Epoch 22/150, Loss: 0.9898730575080542\n",
      "Epoch 23/150, Loss: 1.023856665183142\n",
      "Epoch 24/150, Loss: 0.9898330769309779\n",
      "Epoch 25/150, Loss: 0.8521061679505922\n",
      "Epoch 26/150, Loss: 1.1731453414776678\n",
      "Epoch 27/150, Loss: 0.9595298643644574\n",
      "Epoch 28/150, Loss: 0.95916385364315\n",
      "Epoch 29/150, Loss: 0.9959047531047365\n",
      "Epoch 30/150, Loss: 1.2891408932874784\n",
      "Epoch 31/150, Loss: 0.8802932629502085\n",
      "Epoch 32/150, Loss: 1.0695045265243963\n",
      "Epoch 33/150, Loss: 1.0219602450714003\n",
      "Epoch 34/150, Loss: 1.1497847590301233\n",
      "Epoch 35/150, Loss: 0.7711624165287135\n",
      "Epoch 36/150, Loss: 1.4520970134068252\n",
      "Epoch 37/150, Loss: 1.0330236386920555\n",
      "Epoch 38/150, Loss: 0.8680458368728323\n",
      "Epoch 39/150, Loss: 0.9160296300569646\n",
      "Epoch 40/150, Loss: 1.012265458114006\n",
      "Epoch 41/150, Loss: 1.0178081139769204\n",
      "Epoch 42/150, Loss: 0.9080253962001025\n",
      "Epoch 43/150, Loss: 0.9672966537461937\n",
      "Epoch 44/150, Loss: 0.9187705359590904\n",
      "Epoch 45/150, Loss: 0.997004671964769\n",
      "Epoch 46/150, Loss: 0.7546482823608329\n",
      "Epoch 47/150, Loss: 1.1324583523757408\n",
      "Epoch 48/150, Loss: 0.9201615607596243\n",
      "Epoch 49/150, Loss: 1.0619301155845031\n",
      "Epoch 50/150, Loss: 0.9927804278454456\n",
      "Epoch 51/150, Loss: 1.0255081265923085\n",
      "Epoch 52/150, Loss: 0.8564490167344725\n",
      "Epoch 53/150, Loss: 0.9429010754394679\n",
      "Epoch 54/150, Loss: 1.174643266540611\n",
      "Epoch 55/150, Loss: 1.1558188142364845\n",
      "Epoch 56/150, Loss: 0.8985776910811873\n",
      "Epoch 57/150, Loss: 0.9172018944598724\n",
      "Epoch 58/150, Loss: 1.0751019407211537\n",
      "Epoch 59/150, Loss: 0.9661131242289566\n",
      "Epoch 60/150, Loss: 1.0148886093015625\n",
      "Epoch 61/150, Loss: 0.9994079724843169\n",
      "Epoch 62/150, Loss: 1.1820015229308312\n",
      "Epoch 63/150, Loss: 0.9914935880648446\n",
      "Epoch 64/150, Loss: 1.3486211744460452\n",
      "Epoch 65/150, Loss: 0.8385951423902626\n",
      "Epoch 66/150, Loss: 1.0864043935004202\n",
      "Epoch 67/150, Loss: 0.9033227352700214\n",
      "Epoch 68/150, Loss: 1.0685886545777135\n",
      "Epoch 69/150, Loss: 0.9978558032031177\n",
      "Epoch 70/150, Loss: 1.0331413725827223\n",
      "Epoch 71/150, Loss: 1.0668733921339735\n",
      "Epoch 72/150, Loss: 0.7824424957837384\n",
      "Epoch 73/150, Loss: 0.8690659971374719\n",
      "Epoch 74/150, Loss: 1.357794102534337\n",
      "Epoch 75/150, Loss: 0.8338770550864326\n",
      "Epoch 76/150, Loss: 1.161452728657077\n",
      "Epoch 77/150, Loss: 1.0218678949991395\n",
      "Epoch 78/150, Loss: 1.0638693475062708\n",
      "Epoch 79/150, Loss: 1.0291581024396736\n",
      "Epoch 80/150, Loss: 1.0350901204469607\n",
      "Epoch 81/150, Loss: 0.9738113937750267\n",
      "Epoch 82/150, Loss: 1.0517853719873869\n",
      "Epoch 83/150, Loss: 0.9705022606676372\n",
      "Epoch 84/150, Loss: 1.1560398006184038\n",
      "Epoch 85/150, Loss: 1.1253151875902703\n",
      "Epoch 86/150, Loss: 1.0733479896510096\n",
      "Epoch 87/150, Loss: 1.1368278798622726\n",
      "Epoch 88/150, Loss: 1.267363022561617\n",
      "Epoch 89/150, Loss: 1.022562430380007\n",
      "Epoch 90/150, Loss: 0.9391540976287395\n",
      "Epoch 91/150, Loss: 1.077092432405659\n",
      "Epoch 92/150, Loss: 0.907247491209366\n",
      "Epoch 93/150, Loss: 0.9383179133452704\n",
      "Epoch 94/150, Loss: 0.8898752968298895\n",
      "Epoch 95/150, Loss: 1.1336185605976765\n",
      "Epoch 96/150, Loss: 0.8866568966240534\n",
      "Epoch 97/150, Loss: 0.9746760288498837\n",
      "Epoch 98/150, Loss: 0.932941812865526\n",
      "Epoch 99/150, Loss: 0.9649877543156632\n",
      "Epoch 100/150, Loss: 0.8682236674019252\n",
      "Epoch 101/150, Loss: 0.9147728477568833\n",
      "Epoch 102/150, Loss: 1.0128802392649547\n",
      "Epoch 103/150, Loss: 1.0311045893044848\n",
      "Epoch 104/150, Loss: 1.1019952680126406\n",
      "Epoch 105/150, Loss: 1.096768755763743\n",
      "Epoch 106/150, Loss: 1.0543016132636014\n",
      "Epoch 107/150, Loss: 0.9379657018861953\n",
      "Epoch 108/150, Loss: 0.8444031952570571\n",
      "Epoch 109/150, Loss: 0.8404744259827492\n",
      "Epoch 110/150, Loss: 1.0376724057955518\n",
      "Epoch 111/150, Loss: 1.0525798424131974\n",
      "Epoch 112/150, Loss: 1.1739139075221745\n",
      "Epoch 113/150, Loss: 0.8783762612045232\n",
      "Epoch 114/150, Loss: 1.0563050829545353\n",
      "Epoch 115/150, Loss: 1.3403967106964527\n",
      "Epoch 116/150, Loss: 0.8309957071262797\n",
      "Epoch 117/150, Loss: 0.867990060796656\n",
      "Epoch 118/150, Loss: 0.903882295378567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150, Loss: 1.0269349411125308\n",
      "Epoch 120/150, Loss: 0.8365554311882205\n",
      "Epoch 121/150, Loss: 1.1338367684867645\n",
      "Epoch 122/150, Loss: 0.8964782731490654\n",
      "Epoch 123/150, Loss: 0.9022883146789714\n",
      "Epoch 124/150, Loss: 0.9931576208342098\n",
      "Epoch 125/150, Loss: 0.875089242767912\n",
      "Epoch 126/150, Loss: 0.9139291903422787\n",
      "Epoch 127/150, Loss: 0.9774576391212265\n",
      "Epoch 128/150, Loss: 0.9816300438784225\n",
      "Epoch 129/150, Loss: 0.829535830704019\n",
      "Epoch 130/150, Loss: 1.0469296559960792\n",
      "Epoch 131/150, Loss: 1.0309649496790254\n",
      "Epoch 132/150, Loss: 1.0769653428599981\n",
      "Epoch 133/150, Loss: 1.0530663327351093\n",
      "Epoch 134/150, Loss: 0.9527638200948852\n",
      "Epoch 135/150, Loss: 1.005925074027045\n",
      "Epoch 136/150, Loss: 0.9006025883932294\n",
      "Epoch 137/150, Loss: 0.9637940335392539\n",
      "Epoch 138/150, Loss: 1.1476139749181513\n",
      "Epoch 139/150, Loss: 0.9147209670889503\n",
      "Epoch 140/150, Loss: 1.0743768943601448\n",
      "Epoch 141/150, Loss: 0.9255157009214108\n",
      "Epoch 142/150, Loss: 1.094292690312157\n",
      "Epoch 143/150, Loss: 1.220073292863255\n",
      "Epoch 144/150, Loss: 0.7555214562272239\n",
      "Epoch 145/150, Loss: 0.7325154830585382\n",
      "Epoch 146/150, Loss: 0.9400441365961387\n",
      "Epoch 147/150, Loss: 1.0442910985046783\n",
      "Epoch 148/150, Loss: 0.8478694463028961\n",
      "Epoch 149/150, Loss: 0.930322657842365\n",
      "Epoch 150/150, Loss: 0.8988358571566426\n",
      "Num_Epoch 150, Batch_size 32, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.41%'\n",
      "Epoch 1/50, Loss: 0.9953584326050909\n",
      "Epoch 2/50, Loss: 1.0377163616227536\n",
      "Epoch 3/50, Loss: 1.0935559261081627\n",
      "Epoch 4/50, Loss: 1.1584282954235923\n",
      "Epoch 5/50, Loss: 1.117775347902219\n",
      "Epoch 6/50, Loss: 0.9741843476461515\n",
      "Epoch 7/50, Loss: 1.0836447258753426\n",
      "Epoch 8/50, Loss: 0.9591327536462078\n",
      "Epoch 9/50, Loss: 1.0406147044391818\n",
      "Epoch 10/50, Loss: 1.012597138792704\n",
      "Epoch 11/50, Loss: 0.9593623692448054\n",
      "Epoch 12/50, Loss: 1.0180969893933063\n",
      "Epoch 13/50, Loss: 1.077970251112138\n",
      "Epoch 14/50, Loss: 1.0453471092599655\n",
      "Epoch 15/50, Loss: 1.1466464588160967\n",
      "Epoch 16/50, Loss: 0.9989062789869038\n",
      "Epoch 17/50, Loss: 0.9999581573535952\n",
      "Epoch 18/50, Loss: 1.0202361425360424\n",
      "Epoch 19/50, Loss: 1.054787998696784\n",
      "Epoch 20/50, Loss: 0.9113714708624714\n",
      "Epoch 21/50, Loss: 1.0779157210273032\n",
      "Epoch 22/50, Loss: 0.9860241102431876\n",
      "Epoch 23/50, Loss: 0.9905090557423302\n",
      "Epoch 24/50, Loss: 1.013449883115902\n",
      "Epoch 25/50, Loss: 1.0543993313833937\n",
      "Epoch 26/50, Loss: 1.0849216819736314\n",
      "Epoch 27/50, Loss: 0.9730897827259687\n",
      "Epoch 28/50, Loss: 0.9529313554562115\n",
      "Epoch 29/50, Loss: 0.9364326523845723\n",
      "Epoch 30/50, Loss: 1.0700219638280806\n",
      "Epoch 31/50, Loss: 0.9069386234886117\n",
      "Epoch 32/50, Loss: 1.0980390933505961\n",
      "Epoch 33/50, Loss: 0.884198857758197\n",
      "Epoch 34/50, Loss: 0.8682624555138074\n",
      "Epoch 35/50, Loss: 1.0305480455028284\n",
      "Epoch 36/50, Loss: 0.9536848709659544\n",
      "Epoch 37/50, Loss: 1.0330089223123442\n",
      "Epoch 38/50, Loss: 0.8153211137332259\n",
      "Epoch 39/50, Loss: 1.082702481907127\n",
      "Epoch 40/50, Loss: 1.2064502197761104\n",
      "Epoch 41/50, Loss: 0.9763314135527448\n",
      "Epoch 42/50, Loss: 1.0200569327056572\n",
      "Epoch 43/50, Loss: 0.9987224903606138\n",
      "Epoch 44/50, Loss: 1.0331469156206237\n",
      "Epoch 45/50, Loss: 1.0396815982144705\n",
      "Epoch 46/50, Loss: 0.9440522043095217\n",
      "Epoch 47/50, Loss: 0.9564563089431789\n",
      "Epoch 48/50, Loss: 1.0119035005867345\n",
      "Epoch 49/50, Loss: 0.9333984171263965\n",
      "Epoch 50/50, Loss: 1.060770051619292\n",
      "Num_Epoch 50, Batch_size 64, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.16%'\n",
      "Epoch 1/100, Loss: 1.0538827968519358\n",
      "Epoch 2/100, Loss: 1.0837080306515476\n",
      "Epoch 3/100, Loss: 1.0519615584025503\n",
      "Epoch 4/100, Loss: 1.0107758932396393\n",
      "Epoch 5/100, Loss: 0.9529526179509283\n",
      "Epoch 6/100, Loss: 0.9692770572889494\n",
      "Epoch 7/100, Loss: 1.1321036283212433\n",
      "Epoch 8/100, Loss: 0.9342231038454285\n",
      "Epoch 9/100, Loss: 1.0908111177205115\n",
      "Epoch 10/100, Loss: 1.1317397215599367\n",
      "Epoch 11/100, Loss: 1.0510632831934936\n",
      "Epoch 12/100, Loss: 1.0884238931454995\n",
      "Epoch 13/100, Loss: 0.8557582176658279\n",
      "Epoch 14/100, Loss: 0.9568373333197479\n",
      "Epoch 15/100, Loss: 0.8897711161277443\n",
      "Epoch 16/100, Loss: 0.9332502100380697\n",
      "Epoch 17/100, Loss: 1.0975072167661695\n",
      "Epoch 18/100, Loss: 0.9697363244736908\n",
      "Epoch 19/100, Loss: 1.0385323036395517\n",
      "Epoch 20/100, Loss: 0.9971527051533057\n",
      "Epoch 21/100, Loss: 0.9524192245420431\n",
      "Epoch 22/100, Loss: 0.9269599312995447\n",
      "Epoch 23/100, Loss: 1.028292541043356\n",
      "Epoch 24/100, Loss: 0.9965449606674065\n",
      "Epoch 25/100, Loss: 1.091021646524649\n",
      "Epoch 26/100, Loss: 1.0872811117906613\n",
      "Epoch 27/100, Loss: 1.0133284888716032\n",
      "Epoch 28/100, Loss: 1.0587337840350521\n",
      "Epoch 29/100, Loss: 0.9278139480195516\n",
      "Epoch 30/100, Loss: 0.9769255293421908\n",
      "Epoch 31/100, Loss: 1.0360873726308872\n",
      "Epoch 32/100, Loss: 0.9474395155035557\n",
      "Epoch 33/100, Loss: 0.9707615605486813\n",
      "Epoch 34/100, Loss: 1.0162822967799807\n",
      "Epoch 35/100, Loss: 1.095603287405324\n",
      "Epoch 36/100, Loss: 0.9809343958530696\n",
      "Epoch 37/100, Loss: 1.118325035704014\n",
      "Epoch 38/100, Loss: 1.0418250385127035\n",
      "Epoch 39/100, Loss: 0.9497380403794964\n",
      "Epoch 40/100, Loss: 0.948500519034157\n",
      "Epoch 41/100, Loss: 1.1441018876257267\n",
      "Epoch 42/100, Loss: 0.9689533139479365\n",
      "Epoch 43/100, Loss: 1.091937486839862\n",
      "Epoch 44/100, Loss: 0.875156299696487\n",
      "Epoch 45/100, Loss: 1.0687303478804573\n",
      "Epoch 46/100, Loss: 0.9458529760598606\n",
      "Epoch 47/100, Loss: 0.9907612549391547\n",
      "Epoch 48/100, Loss: 1.0463798777999187\n",
      "Epoch 49/100, Loss: 1.023704798416334\n",
      "Epoch 50/100, Loss: 0.8763998085148699\n",
      "Epoch 51/100, Loss: 0.9225775719589213\n",
      "Epoch 52/100, Loss: 1.0377161846916327\n",
      "Epoch 53/100, Loss: 1.1031268888419543\n",
      "Epoch 54/100, Loss: 1.0416251773026715\n",
      "Epoch 55/100, Loss: 1.074846939656298\n",
      "Epoch 56/100, Loss: 1.0821139640135873\n",
      "Epoch 57/100, Loss: 0.8698244819363496\n",
      "Epoch 58/100, Loss: 1.0407934049136\n",
      "Epoch 59/100, Loss: 0.9412910790392925\n",
      "Epoch 60/100, Loss: 1.195779064481226\n",
      "Epoch 61/100, Loss: 0.9710051475863672\n",
      "Epoch 62/100, Loss: 0.9844583866344173\n",
      "Epoch 63/100, Loss: 0.9560963205525034\n",
      "Epoch 64/100, Loss: 1.0282633675192083\n",
      "Epoch 65/100, Loss: 0.9636577678954443\n",
      "Epoch 66/100, Loss: 1.1134098655480331\n",
      "Epoch 67/100, Loss: 0.9446547197617541\n",
      "Epoch 68/100, Loss: 0.9910454774243922\n",
      "Epoch 69/100, Loss: 0.9820624479531\n",
      "Epoch 70/100, Loss: 1.0251247661079843\n",
      "Epoch 71/100, Loss: 1.014477661035659\n",
      "Epoch 72/100, Loss: 1.0071740661217454\n",
      "Epoch 73/100, Loss: 1.0661309414619689\n",
      "Epoch 74/100, Loss: 0.9607258083005833\n",
      "Epoch 75/100, Loss: 0.830899358374197\n",
      "Epoch 76/100, Loss: 1.062414038267778\n",
      "Epoch 77/100, Loss: 1.0462256013981617\n",
      "Epoch 78/100, Loss: 0.9725147866785876\n",
      "Epoch 79/100, Loss: 0.9191704427745876\n",
      "Epoch 80/100, Loss: 1.0261132816405878\n",
      "Epoch 81/100, Loss: 0.9631547643109011\n",
      "Epoch 82/100, Loss: 1.0073489396733688\n",
      "Epoch 83/100, Loss: 0.9053291026759213\n",
      "Epoch 84/100, Loss: 1.0714974747168091\n",
      "Epoch 85/100, Loss: 1.0212770991091564\n",
      "Epoch 86/100, Loss: 0.9765939961973761\n",
      "Epoch 87/100, Loss: 1.014441929326849\n",
      "Epoch 88/100, Loss: 0.9996599368178186\n",
      "Epoch 89/100, Loss: 0.9782628721428339\n",
      "Epoch 90/100, Loss: 1.0439043658388012\n",
      "Epoch 91/100, Loss: 1.2205260576094878\n",
      "Epoch 92/100, Loss: 0.9671265013069255\n",
      "Epoch 93/100, Loss: 0.9267774006375828\n",
      "Epoch 94/100, Loss: 0.9362513731728302\n",
      "Epoch 95/100, Loss: 1.2075372709920187\n",
      "Epoch 96/100, Loss: 1.1742890283622864\n",
      "Epoch 97/100, Loss: 0.9051976540306201\n",
      "Epoch 98/100, Loss: 0.8890930732080818\n",
      "Epoch 99/100, Loss: 0.9990626273231962\n",
      "Epoch 100/100, Loss: 0.9067860258236647\n",
      "Num_Epoch 100, Batch_size 64, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 76.70%'\n",
      "Epoch 1/150, Loss: 1.0272624723764587\n",
      "Epoch 2/150, Loss: 1.0122934324005601\n",
      "Epoch 3/150, Loss: 1.1157803202220844\n",
      "Epoch 4/150, Loss: 0.9682876271565993\n",
      "Epoch 5/150, Loss: 1.0692165098102366\n",
      "Epoch 6/150, Loss: 0.8752462971250006\n",
      "Epoch 7/150, Loss: 1.0655529606707503\n",
      "Epoch 8/150, Loss: 1.0155407846430897\n",
      "Epoch 9/150, Loss: 1.0742617490470836\n",
      "Epoch 10/150, Loss: 0.9018601149915978\n",
      "Epoch 11/150, Loss: 0.962835550918713\n",
      "Epoch 12/150, Loss: 1.0174807341452472\n",
      "Epoch 13/150, Loss: 0.9793089237489834\n",
      "Epoch 14/150, Loss: 1.047595251315148\n",
      "Epoch 15/150, Loss: 1.1794254627689014\n",
      "Epoch 16/150, Loss: 1.0417012662208933\n",
      "Epoch 17/150, Loss: 1.1322492446025272\n",
      "Epoch 18/150, Loss: 1.12700164739147\n",
      "Epoch 19/150, Loss: 0.9124300168691376\n",
      "Epoch 20/150, Loss: 0.930486682947145\n",
      "Epoch 21/150, Loss: 0.9680020158459202\n",
      "Epoch 22/150, Loss: 1.1151518862897831\n",
      "Epoch 23/150, Loss: 1.0683254159853037\n",
      "Epoch 24/150, Loss: 1.015070813494964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150, Loss: 0.9213994748749004\n",
      "Epoch 26/150, Loss: 0.9886030077157457\n",
      "Epoch 27/150, Loss: 0.9271072474051649\n",
      "Epoch 28/150, Loss: 0.845469959599476\n",
      "Epoch 29/150, Loss: 1.040876748475982\n",
      "Epoch 30/150, Loss: 1.0754911903157287\n",
      "Epoch 31/150, Loss: 1.0389218592630955\n",
      "Epoch 32/150, Loss: 0.9459335814828027\n",
      "Epoch 33/150, Loss: 0.9586363240974203\n",
      "Epoch 34/150, Loss: 1.0293862667612639\n",
      "Epoch 35/150, Loss: 0.8449917190740184\n",
      "Epoch 36/150, Loss: 1.049532371722648\n",
      "Epoch 37/150, Loss: 0.8753307534301386\n",
      "Epoch 38/150, Loss: 1.020380476355849\n",
      "Epoch 39/150, Loss: 1.0198492479255878\n",
      "Epoch 40/150, Loss: 0.9926858533408551\n",
      "Epoch 41/150, Loss: 1.0934983880137639\n",
      "Epoch 42/150, Loss: 1.0413692106292782\n",
      "Epoch 43/150, Loss: 0.9197935990210105\n",
      "Epoch 44/150, Loss: 1.025597998713689\n",
      "Epoch 45/150, Loss: 0.9156088820704078\n",
      "Epoch 46/150, Loss: 1.01338345622074\n",
      "Epoch 47/150, Loss: 1.0447296893450893\n",
      "Epoch 48/150, Loss: 0.9412246310790575\n",
      "Epoch 49/150, Loss: 0.9192481065136617\n",
      "Epoch 50/150, Loss: 0.8778689066833597\n",
      "Epoch 51/150, Loss: 1.0855012631645422\n",
      "Epoch 52/150, Loss: 0.9454364081256887\n",
      "Epoch 53/150, Loss: 1.0646712501759543\n",
      "Epoch 54/150, Loss: 0.9641189325977725\n",
      "Epoch 55/150, Loss: 1.0671071108644006\n",
      "Epoch 56/150, Loss: 0.8799446951509353\n",
      "Epoch 57/150, Loss: 0.9893446382545399\n",
      "Epoch 58/150, Loss: 0.9938466866859532\n",
      "Epoch 59/150, Loss: 0.9854980766858219\n",
      "Epoch 60/150, Loss: 0.9297155380274251\n",
      "Epoch 61/150, Loss: 0.8692106612836049\n",
      "Epoch 62/150, Loss: 1.1982891019378177\n",
      "Epoch 63/150, Loss: 1.1092026154225172\n",
      "Epoch 64/150, Loss: 0.9770326420153862\n",
      "Epoch 65/150, Loss: 1.040686830944279\n",
      "Epoch 66/150, Loss: 1.048223324615503\n",
      "Epoch 67/150, Loss: 1.1172450236389888\n",
      "Epoch 68/150, Loss: 1.0501490083992375\n",
      "Epoch 69/150, Loss: 0.9033071997107854\n",
      "Epoch 70/150, Loss: 0.8662906915418965\n",
      "Epoch 71/150, Loss: 0.93275347891301\n",
      "Epoch 72/150, Loss: 1.0371111220468179\n",
      "Epoch 73/150, Loss: 1.0322587482400536\n",
      "Epoch 74/150, Loss: 1.0066727701028506\n",
      "Epoch 75/150, Loss: 1.0879993042200784\n",
      "Epoch 76/150, Loss: 0.8226473355558496\n",
      "Epoch 77/150, Loss: 1.131961025971911\n",
      "Epoch 78/150, Loss: 1.1541601472196212\n",
      "Epoch 79/150, Loss: 1.1142880033524976\n",
      "Epoch 80/150, Loss: 0.9024102216609923\n",
      "Epoch 81/150, Loss: 0.8851269632449418\n",
      "Epoch 82/150, Loss: 1.0225598143762324\n",
      "Epoch 83/150, Loss: 1.024896185284199\n",
      "Epoch 84/150, Loss: 0.8983823724751071\n",
      "Epoch 85/150, Loss: 0.9488836474688631\n",
      "Epoch 86/150, Loss: 1.0510105921052457\n",
      "Epoch 87/150, Loss: 1.0501164351080126\n",
      "Epoch 88/150, Loss: 0.976927902102005\n",
      "Epoch 89/150, Loss: 1.0032491246040265\n",
      "Epoch 90/150, Loss: 0.9699999774465164\n",
      "Epoch 91/150, Loss: 0.9464125132277154\n",
      "Epoch 92/150, Loss: 1.004089090839906\n",
      "Epoch 93/150, Loss: 1.0565535833026614\n",
      "Epoch 94/150, Loss: 1.0263117564086004\n",
      "Epoch 95/150, Loss: 0.9644741576960127\n",
      "Epoch 96/150, Loss: 0.966349270159772\n",
      "Epoch 97/150, Loss: 0.9799946810222976\n",
      "Epoch 98/150, Loss: 1.06913304063793\n",
      "Epoch 99/150, Loss: 0.9004771332831134\n",
      "Epoch 100/150, Loss: 0.9104904583389681\n",
      "Epoch 101/150, Loss: 1.0551244112132319\n",
      "Epoch 102/150, Loss: 0.9239540408615319\n",
      "Epoch 103/150, Loss: 1.0713012017014107\n",
      "Epoch 104/150, Loss: 1.1047730964250122\n",
      "Epoch 105/150, Loss: 1.0062510994016782\n",
      "Epoch 106/150, Loss: 1.048825832412092\n",
      "Epoch 107/150, Loss: 0.8619235898946688\n",
      "Epoch 108/150, Loss: 1.0947592261336445\n",
      "Epoch 109/150, Loss: 0.9515290447071791\n",
      "Epoch 110/150, Loss: 0.9976147888558595\n",
      "Epoch 111/150, Loss: 1.1222572713508057\n",
      "Epoch 112/150, Loss: 1.169639414388006\n",
      "Epoch 113/150, Loss: 1.0999593747493221\n",
      "Epoch 114/150, Loss: 1.0737033373153881\n",
      "Epoch 115/150, Loss: 1.042096078758438\n",
      "Epoch 116/150, Loss: 0.9591443447979461\n",
      "Epoch 117/150, Loss: 1.059225338398377\n",
      "Epoch 118/150, Loss: 0.8791740632214621\n",
      "Epoch 119/150, Loss: 0.9940052293793764\n",
      "Epoch 120/150, Loss: 1.004736223529559\n",
      "Epoch 121/150, Loss: 1.04423379760436\n",
      "Epoch 122/150, Loss: 1.0075731289063208\n",
      "Epoch 123/150, Loss: 0.8871517735778413\n",
      "Epoch 124/150, Loss: 1.0065048841098498\n",
      "Epoch 125/150, Loss: 0.7975117205299831\n",
      "Epoch 126/150, Loss: 0.9527620742747921\n",
      "Epoch 127/150, Loss: 1.0969681167645102\n",
      "Epoch 128/150, Loss: 1.0339124145542558\n",
      "Epoch 129/150, Loss: 0.9514265103330277\n",
      "Epoch 130/150, Loss: 1.1140326576505992\n",
      "Epoch 131/150, Loss: 0.7948497405610911\n",
      "Epoch 132/150, Loss: 1.177335532002905\n",
      "Epoch 133/150, Loss: 1.0200070982792546\n",
      "Epoch 134/150, Loss: 0.8983090316856028\n",
      "Epoch 135/150, Loss: 0.8721404167203036\n",
      "Epoch 136/150, Loss: 0.9727734673463297\n",
      "Epoch 137/150, Loss: 0.8869248851421427\n",
      "Epoch 138/150, Loss: 0.9904034372986493\n",
      "Epoch 139/150, Loss: 1.1091381157818265\n",
      "Epoch 140/150, Loss: 1.0463385726207963\n",
      "Epoch 141/150, Loss: 0.8887812985605884\n",
      "Epoch 142/150, Loss: 1.035850977598099\n",
      "Epoch 143/150, Loss: 1.0594303247867762\n",
      "Epoch 144/150, Loss: 1.084745000905475\n",
      "Epoch 145/150, Loss: 1.105003626381554\n",
      "Epoch 146/150, Loss: 1.0476669807115742\n",
      "Epoch 147/150, Loss: 0.8708080640757506\n",
      "Epoch 148/150, Loss: 0.952615561089393\n",
      "Epoch 149/150, Loss: 0.9870261284954096\n",
      "Epoch 150/150, Loss: 1.0441095160988776\n",
      "Num_Epoch 150, Batch_size 64, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.12%'\n",
      "Epoch 1/50, Loss: 1.0735688488684743\n",
      "Epoch 2/50, Loss: 1.0734929339709178\n",
      "Epoch 3/50, Loss: 1.0067943910997792\n",
      "Epoch 4/50, Loss: 0.9838391274031675\n",
      "Epoch 5/50, Loss: 1.05251552910936\n",
      "Epoch 6/50, Loss: 1.053781152637781\n",
      "Epoch 7/50, Loss: 1.0211246151832452\n",
      "Epoch 8/50, Loss: 1.1169790674927982\n",
      "Epoch 9/50, Loss: 1.0690029729327688\n",
      "Epoch 10/50, Loss: 0.9832357775001667\n",
      "Epoch 11/50, Loss: 1.0207174674548334\n",
      "Epoch 12/50, Loss: 1.1285976545428213\n",
      "Epoch 13/50, Loss: 0.9797333850365552\n",
      "Epoch 14/50, Loss: 1.0154565076216273\n",
      "Epoch 15/50, Loss: 1.0059423848179418\n",
      "Epoch 16/50, Loss: 0.9287986207214685\n",
      "Epoch 17/50, Loss: 1.0595027029776836\n",
      "Epoch 18/50, Loss: 1.0271463826930867\n",
      "Epoch 19/50, Loss: 1.0925235871461576\n",
      "Epoch 20/50, Loss: 0.9702140111207912\n",
      "Epoch 21/50, Loss: 0.9813255729295711\n",
      "Epoch 22/50, Loss: 0.9564120216319372\n",
      "Epoch 23/50, Loss: 1.0039444455935427\n",
      "Epoch 24/50, Loss: 1.0637816748286248\n",
      "Epoch 25/50, Loss: 1.0332827531576574\n",
      "Epoch 26/50, Loss: 0.8883775520363034\n",
      "Epoch 27/50, Loss: 1.0400729696688922\n",
      "Epoch 28/50, Loss: 1.0342062698268946\n",
      "Epoch 29/50, Loss: 1.090504633394962\n",
      "Epoch 30/50, Loss: 1.0238873024802388\n",
      "Epoch 31/50, Loss: 1.0672700853371917\n",
      "Epoch 32/50, Loss: 1.0304797914659363\n",
      "Epoch 33/50, Loss: 1.0539553287155543\n",
      "Epoch 34/50, Loss: 1.0354005719363757\n",
      "Epoch 35/50, Loss: 0.9945754013694244\n",
      "Epoch 36/50, Loss: 0.9545049597425498\n",
      "Epoch 37/50, Loss: 1.0892220404542434\n",
      "Epoch 38/50, Loss: 1.0269620310110632\n",
      "Epoch 39/50, Loss: 1.0675594485977922\n",
      "Epoch 40/50, Loss: 0.9843165584967869\n",
      "Epoch 41/50, Loss: 0.9126238943633099\n",
      "Epoch 42/50, Loss: 0.9212097428281185\n",
      "Epoch 43/50, Loss: 1.1181366735367524\n",
      "Epoch 44/50, Loss: 0.9437771849191352\n",
      "Epoch 45/50, Loss: 0.9512071941376705\n",
      "Epoch 46/50, Loss: 0.9531684942259\n",
      "Epoch 47/50, Loss: 1.0795591381349479\n",
      "Epoch 48/50, Loss: 1.0001718927755148\n",
      "Epoch 49/50, Loss: 1.0135512117769947\n",
      "Epoch 50/50, Loss: 1.10425317051223\n",
      "Num_Epoch 50, Batch_size 128, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.86%'\n",
      "Epoch 1/100, Loss: 1.0381722440988321\n",
      "Epoch 2/100, Loss: 1.1089747497831652\n",
      "Epoch 3/100, Loss: 1.0305482840250275\n",
      "Epoch 4/100, Loss: 1.0019064635315509\n",
      "Epoch 5/100, Loss: 1.1071576797695042\n",
      "Epoch 6/100, Loss: 0.9307372450182508\n",
      "Epoch 7/100, Loss: 0.9851047401600654\n",
      "Epoch 8/100, Loss: 1.001643278361108\n",
      "Epoch 9/100, Loss: 1.036693746092924\n",
      "Epoch 10/100, Loss: 0.9903156553956676\n",
      "Epoch 11/100, Loss: 1.11429400001329\n",
      "Epoch 12/100, Loss: 1.0301401446394947\n",
      "Epoch 13/100, Loss: 1.028891633473963\n",
      "Epoch 14/100, Loss: 1.039916235265243\n",
      "Epoch 15/100, Loss: 1.0565296877830779\n",
      "Epoch 16/100, Loss: 1.026232970490153\n",
      "Epoch 17/100, Loss: 1.048183618883449\n",
      "Epoch 18/100, Loss: 1.0360582563156713\n",
      "Epoch 19/100, Loss: 1.0306988483359654\n",
      "Epoch 20/100, Loss: 1.0463874810165863\n",
      "Epoch 21/100, Loss: 1.006449442650452\n",
      "Epoch 22/100, Loss: 1.0293904043056168\n",
      "Epoch 23/100, Loss: 1.066430444714273\n",
      "Epoch 24/100, Loss: 0.9692276207085934\n",
      "Epoch 25/100, Loss: 0.933466891056348\n",
      "Epoch 26/100, Loss: 0.9182622637072604\n",
      "Epoch 27/100, Loss: 0.9924284670207094\n",
      "Epoch 28/100, Loss: 1.020535578548902\n",
      "Epoch 29/100, Loss: 1.1163948339582432\n",
      "Epoch 30/100, Loss: 0.9348068942473309\n",
      "Epoch 31/100, Loss: 0.9665266355246196\n",
      "Epoch 32/100, Loss: 0.9986713696289031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Loss: 0.9746065871763664\n",
      "Epoch 34/100, Loss: 0.9801964470494288\n",
      "Epoch 35/100, Loss: 0.9976017926587739\n",
      "Epoch 36/100, Loss: 0.9851631372419989\n",
      "Epoch 37/100, Loss: 1.013593605091358\n",
      "Epoch 38/100, Loss: 1.1247235889141014\n",
      "Epoch 39/100, Loss: 0.9537083712266469\n",
      "Epoch 40/100, Loss: 1.0806423293368956\n",
      "Epoch 41/100, Loss: 0.9938716195079096\n",
      "Epoch 42/100, Loss: 1.098082618128152\n",
      "Epoch 43/100, Loss: 1.0217670932725877\n",
      "Epoch 44/100, Loss: 0.9807192431564771\n",
      "Epoch 45/100, Loss: 1.0435687565801153\n",
      "Epoch 46/100, Loss: 0.8788935767886453\n",
      "Epoch 47/100, Loss: 0.9469021358489751\n",
      "Epoch 48/100, Loss: 0.8962475814636341\n",
      "Epoch 49/100, Loss: 0.9906004969438722\n",
      "Epoch 50/100, Loss: 1.0364732885010195\n",
      "Epoch 51/100, Loss: 1.0657024422886896\n",
      "Epoch 52/100, Loss: 1.0031490742393\n",
      "Epoch 53/100, Loss: 0.9873908814927944\n",
      "Epoch 54/100, Loss: 0.9458224527376837\n",
      "Epoch 55/100, Loss: 1.0304490059210332\n",
      "Epoch 56/100, Loss: 0.9990407075745066\n",
      "Epoch 57/100, Loss: 1.0296081586800698\n",
      "Epoch 58/100, Loss: 1.0586013372076164\n",
      "Epoch 59/100, Loss: 1.0739828646878622\n",
      "Epoch 60/100, Loss: 0.9125297590756951\n",
      "Epoch 61/100, Loss: 1.0888509667536022\n",
      "Epoch 62/100, Loss: 1.1354699641960315\n",
      "Epoch 63/100, Loss: 0.9305684095989287\n",
      "Epoch 64/100, Loss: 1.0682545275074182\n",
      "Epoch 65/100, Loss: 0.9529749068383183\n",
      "Epoch 66/100, Loss: 0.9699692017453252\n",
      "Epoch 67/100, Loss: 0.9304459888984151\n",
      "Epoch 68/100, Loss: 1.090670728420556\n",
      "Epoch 69/100, Loss: 1.0417370646106954\n",
      "Epoch 70/100, Loss: 1.0125287377384382\n",
      "Epoch 71/100, Loss: 1.0403172248415038\n",
      "Epoch 72/100, Loss: 0.9637873013630156\n",
      "Epoch 73/100, Loss: 0.9591970747901376\n",
      "Epoch 74/100, Loss: 0.8701076740745944\n",
      "Epoch 75/100, Loss: 0.968251063561018\n",
      "Epoch 76/100, Loss: 0.9805433957659728\n",
      "Epoch 77/100, Loss: 1.1065928112142818\n",
      "Epoch 78/100, Loss: 1.0504136053215203\n",
      "Epoch 79/100, Loss: 1.0388911353578365\n",
      "Epoch 80/100, Loss: 0.9564012394290455\n",
      "Epoch 81/100, Loss: 0.9895765903290038\n",
      "Epoch 82/100, Loss: 0.9647324840297422\n",
      "Epoch 83/100, Loss: 1.04492930075619\n",
      "Epoch 84/100, Loss: 0.8909707443649173\n",
      "Epoch 85/100, Loss: 1.0927076693809383\n",
      "Epoch 86/100, Loss: 0.9536757831891866\n",
      "Epoch 87/100, Loss: 0.9955113365730384\n",
      "Epoch 88/100, Loss: 1.0388921344857365\n",
      "Epoch 89/100, Loss: 0.9001175495580958\n",
      "Epoch 90/100, Loss: 0.9320125962656244\n",
      "Epoch 91/100, Loss: 1.1070853276275816\n",
      "Epoch 92/100, Loss: 0.9939756400002654\n",
      "Epoch 93/100, Loss: 1.0720318051697766\n",
      "Epoch 94/100, Loss: 0.9406163515947045\n",
      "Epoch 95/100, Loss: 0.9932870482641056\n",
      "Epoch 96/100, Loss: 0.9205903719144031\n",
      "Epoch 97/100, Loss: 1.0273346753615216\n",
      "Epoch 98/100, Loss: 1.009087119493549\n",
      "Epoch 99/100, Loss: 1.0039549356589141\n",
      "Epoch 100/100, Loss: 0.9691142379979693\n",
      "Num_Epoch 100, Batch_size 128, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.53%'\n",
      "Epoch 1/150, Loss: 1.0741274582809641\n",
      "Epoch 2/150, Loss: 1.0646225389463622\n",
      "Epoch 3/150, Loss: 0.9987687750003785\n",
      "Epoch 4/150, Loss: 1.0662851422793\n",
      "Epoch 5/150, Loss: 1.130054456663426\n",
      "Epoch 6/150, Loss: 0.9380138644849678\n",
      "Epoch 7/150, Loss: 1.034503935218284\n",
      "Epoch 8/150, Loss: 1.04555368771499\n",
      "Epoch 9/150, Loss: 1.0555324493177092\n",
      "Epoch 10/150, Loss: 1.222911953312003\n",
      "Epoch 11/150, Loss: 1.015155630147238\n",
      "Epoch 12/150, Loss: 0.990926991648634\n",
      "Epoch 13/150, Loss: 1.018802652308341\n",
      "Epoch 14/150, Loss: 1.059176075102496\n",
      "Epoch 15/150, Loss: 0.9948210038526197\n",
      "Epoch 16/150, Loss: 1.0157564260258511\n",
      "Epoch 17/150, Loss: 1.0321164692405518\n",
      "Epoch 18/150, Loss: 0.9447934750318718\n",
      "Epoch 19/150, Loss: 1.0605624056062173\n",
      "Epoch 20/150, Loss: 1.071478575338935\n",
      "Epoch 21/150, Loss: 1.0440223243109719\n",
      "Epoch 22/150, Loss: 1.056579589869921\n",
      "Epoch 23/150, Loss: 1.008516337102118\n",
      "Epoch 24/150, Loss: 0.9679978399662241\n",
      "Epoch 25/150, Loss: 0.9076094393578757\n",
      "Epoch 26/150, Loss: 1.0639568842786207\n",
      "Epoch 27/150, Loss: 0.9580348364028697\n",
      "Epoch 28/150, Loss: 0.9908228711002657\n",
      "Epoch 29/150, Loss: 0.8747089981056623\n",
      "Epoch 30/150, Loss: 1.0527621047186004\n",
      "Epoch 31/150, Loss: 0.9915097355897501\n",
      "Epoch 32/150, Loss: 0.9378406278972108\n",
      "Epoch 33/150, Loss: 1.0143013607839038\n",
      "Epoch 34/150, Loss: 1.025433171033546\n",
      "Epoch 35/150, Loss: 0.9908941503997091\n",
      "Epoch 36/150, Loss: 1.060956061474033\n",
      "Epoch 37/150, Loss: 0.9301494210949435\n",
      "Epoch 38/150, Loss: 1.0653369772497487\n",
      "Epoch 39/150, Loss: 1.020739867741718\n",
      "Epoch 40/150, Loss: 0.9800362826660057\n",
      "Epoch 41/150, Loss: 0.9822328739901062\n",
      "Epoch 42/150, Loss: 0.8995173900094943\n",
      "Epoch 43/150, Loss: 1.0027030862363366\n",
      "Epoch 44/150, Loss: 1.0071104237929376\n",
      "Epoch 45/150, Loss: 1.0540512047763841\n",
      "Epoch 46/150, Loss: 1.1149789523773295\n",
      "Epoch 47/150, Loss: 0.935929447665633\n",
      "Epoch 48/150, Loss: 0.9975824143572983\n",
      "Epoch 49/150, Loss: 0.9696928501265648\n",
      "Epoch 50/150, Loss: 0.9699978024656578\n",
      "Epoch 51/150, Loss: 0.962280625418116\n",
      "Epoch 52/150, Loss: 1.0516602873002114\n",
      "Epoch 53/150, Loss: 0.9861268174441452\n",
      "Epoch 54/150, Loss: 0.9837688571667468\n",
      "Epoch 55/150, Loss: 1.0756552328201388\n",
      "Epoch 56/150, Loss: 0.9080994497027894\n",
      "Epoch 57/150, Loss: 0.9564870898600071\n",
      "Epoch 58/150, Loss: 1.0959250700374157\n",
      "Epoch 59/150, Loss: 1.0838687920295136\n",
      "Epoch 60/150, Loss: 1.0771396540062692\n",
      "Epoch 61/150, Loss: 0.9971722811543374\n",
      "Epoch 62/150, Loss: 0.962474584845371\n",
      "Epoch 63/150, Loss: 0.9673492385803724\n",
      "Epoch 64/150, Loss: 0.9900596299101196\n",
      "Epoch 65/150, Loss: 0.910320153085197\n",
      "Epoch 66/150, Loss: 0.9375075719770787\n",
      "Epoch 67/150, Loss: 1.073034716852404\n",
      "Epoch 68/150, Loss: 1.0143905828472244\n",
      "Epoch 69/150, Loss: 1.0318704715568185\n",
      "Epoch 70/150, Loss: 1.041498442043716\n",
      "Epoch 71/150, Loss: 0.9466632703383708\n",
      "Epoch 72/150, Loss: 0.9772335521097231\n",
      "Epoch 73/150, Loss: 0.9163548260503557\n",
      "Epoch 74/150, Loss: 0.9676918258860281\n",
      "Epoch 75/150, Loss: 1.0173412211172437\n",
      "Epoch 76/150, Loss: 1.0264404720353504\n",
      "Epoch 77/150, Loss: 1.0069690667861861\n",
      "Epoch 78/150, Loss: 1.0949198055073301\n",
      "Epoch 79/150, Loss: 1.0085962033588691\n",
      "Epoch 80/150, Loss: 1.037899628683125\n",
      "Epoch 81/150, Loss: 0.8966782912322695\n",
      "Epoch 82/150, Loss: 0.9488744183695761\n",
      "Epoch 83/150, Loss: 1.0559531968922082\n",
      "Epoch 84/150, Loss: 0.9166870333607836\n",
      "Epoch 85/150, Loss: 1.0747377298025724\n",
      "Epoch 86/150, Loss: 0.9738976824929647\n",
      "Epoch 87/150, Loss: 0.8948507240104886\n",
      "Epoch 88/150, Loss: 0.9631529557403775\n",
      "Epoch 89/150, Loss: 0.9388896080476854\n",
      "Epoch 90/150, Loss: 1.0075333546233252\n",
      "Epoch 91/150, Loss: 1.0280641043125853\n",
      "Epoch 92/150, Loss: 0.8200728006596474\n",
      "Epoch 93/150, Loss: 0.9446121682713212\n",
      "Epoch 94/150, Loss: 1.0307771264351506\n",
      "Epoch 95/150, Loss: 1.0020444924783776\n",
      "Epoch 96/150, Loss: 1.0214603091676138\n",
      "Epoch 97/150, Loss: 0.9712580779793085\n",
      "Epoch 98/150, Loss: 0.9812562844169608\n",
      "Epoch 99/150, Loss: 1.0221640701717511\n",
      "Epoch 100/150, Loss: 1.0018069072468743\n",
      "Epoch 101/150, Loss: 0.934043108686106\n",
      "Epoch 102/150, Loss: 1.014270667732734\n",
      "Epoch 103/150, Loss: 0.9927319409458214\n",
      "Epoch 104/150, Loss: 1.0176266354051204\n",
      "Epoch 105/150, Loss: 1.101694677551561\n",
      "Epoch 106/150, Loss: 0.9730419234330827\n",
      "Epoch 107/150, Loss: 1.011283304399973\n",
      "Epoch 108/150, Loss: 1.006751171229838\n",
      "Epoch 109/150, Loss: 1.0180326604435126\n",
      "Epoch 110/150, Loss: 1.0590728364520317\n",
      "Epoch 111/150, Loss: 0.9433944104246179\n",
      "Epoch 112/150, Loss: 1.0305790013885925\n",
      "Epoch 113/150, Loss: 0.9537490891056176\n",
      "Epoch 114/150, Loss: 0.969704998783595\n",
      "Epoch 115/150, Loss: 0.9463338874260179\n",
      "Epoch 116/150, Loss: 1.01796309264159\n",
      "Epoch 117/150, Loss: 0.9693298287870307\n",
      "Epoch 118/150, Loss: 1.1153382566403196\n",
      "Epoch 119/150, Loss: 0.995129032196852\n",
      "Epoch 120/150, Loss: 0.9809764353317907\n",
      "Epoch 121/150, Loss: 0.9729767087560115\n",
      "Epoch 122/150, Loss: 1.0899583368507126\n",
      "Epoch 123/150, Loss: 0.8894539204875886\n",
      "Epoch 124/150, Loss: 0.932120477423044\n",
      "Epoch 125/150, Loss: 0.9874899695902497\n",
      "Epoch 126/150, Loss: 0.9377493718252415\n",
      "Epoch 127/150, Loss: 0.8870067251258426\n",
      "Epoch 128/150, Loss: 1.0490777934564346\n",
      "Epoch 129/150, Loss: 1.0269239964216665\n",
      "Epoch 130/150, Loss: 1.077884856312143\n",
      "Epoch 131/150, Loss: 0.9809168714610931\n",
      "Epoch 132/150, Loss: 0.9428371661281922\n",
      "Epoch 133/150, Loss: 1.0117288349841913\n",
      "Epoch 134/150, Loss: 0.9625457235644246\n",
      "Epoch 135/150, Loss: 0.9612711228423929\n",
      "Epoch 136/150, Loss: 0.9719985920575713\n",
      "Epoch 137/150, Loss: 1.0042766992279735\n",
      "Epoch 138/150, Loss: 0.9759611811220773\n",
      "Epoch 139/150, Loss: 0.9935590032967232\n",
      "Epoch 140/150, Loss: 0.9991819946190404\n",
      "Epoch 141/150, Loss: 0.9928085468181571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150, Loss: 0.9392894346300795\n",
      "Epoch 143/150, Loss: 1.0314271318357966\n",
      "Epoch 144/150, Loss: 1.0616821536377947\n",
      "Epoch 145/150, Loss: 1.0140703616826252\n",
      "Epoch 146/150, Loss: 0.9413903599467979\n",
      "Epoch 147/150, Loss: 0.9900870686404954\n",
      "Epoch 148/150, Loss: 1.0572082103426106\n",
      "Epoch 149/150, Loss: 0.9369052854320185\n",
      "Epoch 150/150, Loss: 1.1260390148074344\n",
      "Num_Epoch 150, Batch_size 128, Learning_rate 0.01, Alpha 0.1, f'Test accuracy: 77.36%'\n"
     ]
    }
   ],
   "source": [
    "best_hyp,best_weights,best_bias,best_acc= validation(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184f3cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8248/2504081545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_weights3.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_bias3.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_hyperparameter3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_hyp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_weights' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(\"best_model_weights3.npy\", best_weights)\n",
    "np.save(\"best_model_bias3.npy\", best_bias)\n",
    "np.save(\"best_model_hyperparameter3\",best_hyp)\n",
    "np.save(\"best_model_accuracy\",best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6262d382",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model_hyperparameter3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8248/3888175927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_bias3.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbest_hyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model_hyperparameter3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model_hyperparameter3'"
     ]
    }
   ],
   "source": [
    "test_weights = np.load(\"best_model_weights3.npy\")\n",
    "test_bias = np.load(\"best_model_bias3.npy\")\n",
    "\n",
    "best_hyp = np.load(\"best_model_hyperparameter3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5843634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 82.33%\n"
     ]
    }
   ],
   "source": [
    "def test(X,W,B):\n",
    "    Z = np.dot(X, W) + B\n",
    "    A = softmax(Z)\n",
    "    return np.argmax(A, axis=1)\n",
    "\n",
    "X_test = testing_data / 255.0\n",
    "y_test = testing_labels\n",
    "y_pred = test(X_test,test_weights,test_bias)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets tune our hyperparameters  - unregularized\n",
    "\n",
    "def validation(X_train,y_train,X_val,y_val):\n",
    "    \n",
    "    learning_rates = [1e-4,1e-3,1e-2] \n",
    "    mini_batch_sizes = [32, 64,128]\n",
    "    num_epochs_testing = [50, 100,150]\n",
    "    \n",
    "    \n",
    "    best_accuracy = 0  # setting mse to positive infinity to ensure the first mse calculated becomes the default best value after first iteration and gets updated in the process\n",
    "    best_hyperparams = {}   # dictionary to store the three HP parameters\n",
    "    best_weights, best_bias = None, None\n",
    "    \n",
    "    for rate in learning_rates:\n",
    "            for batch in mini_batch_sizes:\n",
    "                for epoch in num_epochs_testing:\n",
    "                    \n",
    "                    weights, bias = train_softmax(X_train,y_train,epoch,batch,rate,a)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    Z = np.dot(X_val, weights) + bias\n",
    "                    A = softmax(Z)\n",
    "                    y_pred = np.argmax(A, axis=1)\n",
    "                    \n",
    "                    accuracy = np.mean(y_pred == y_val)\n",
    "                        \n",
    "                    print(f\"Num_Epoch {epoch}, Batch_size {batch}, Learning_rate {rate}, Alpha {a}, f'Test accuracy: {accuracy * 100:.2f}%'\")\n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_hyperparameters = {'num_epochs': epoch,'learning_rate': rate,'mini_batch': batch, 'Alpha': {a}}\n",
    "                        best_weights,best_bias = weights,bias\n",
    "                        \n",
    "    return best_hyperparameters,best_weights,best_bias,best_accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
